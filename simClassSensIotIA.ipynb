{"cells":[{"cell_type":"code","execution_count":61,"id":"1bdd0d69","metadata":{"id":"1bdd0d69","executionInfo":{"status":"ok","timestamp":1747531419448,"user_tz":180,"elapsed":20,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}}},"outputs":[],"source":["import os\n","import json\n","import numpy as np\n","import pandas as pd\n","import re\n","from google.colab import drive, userdata\n","import google.generativeai as genai\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Inicializar config_data com configuração padrão\n","config_data = {\n","    \"project_base_dir\": os.path.abspath('SimClasIotIA/'),\n","    \"feature_columns\": [\"distancia_cm\", \"velocidade_cm_s\"],\n","    \"label_column\": \"tipo_obstaculo\",\n","    \"obstacle_types\": [\"Pessoa\", \"Parede\", \"Objeto Pequeno\", \"Vazio\"]\n","}\n","# Exemplo de configuração JSON para salvar em arquivo\n","example_config = {\n","    \"project_base_dir\": os.path.abspath('MyDrive/'),\n","    \"feature_columns\": [\"distancia_cm\", \"velocidade_cm_s\"],\n","    \"label_column\": \"tipo_obstaculo\",\n","    \"obstacle_types\": [\"Pessoa\", \"Parede\", \"Objeto Pequeno\", \"Vazio\"]\n","}\n","\n","# Para salvar este exemplo em um arquivo, descomente as linhas abaixo\n","'''\n","with open('example_config.json', 'w') as f:\n","    json.dump(example_config, f, indent=2, ensure_ascii=False)\n","print(\"Arquivo de exemplo salvo como 'example_config.json'\")\n","'''\n","\n","# Definição manual de JSON (alternativa em caso de falha na extração)\n","manual_json = '''\n","{\n","  \"project_base_dir\": \"/caminho/do/seu/projeto/\",\n","  \"feature_columns\": [\"distancia_cm\", \"velocidade_cm_s\"],\n","  \"label_column\": \"tipo_obstaculo\",\n","  \"obstacle_types\": [\"Pessoa\", \"Parede\", \"Objeto Pequeno\", \"Vazio\"]\n","}\n","'''\n","\n","# Para usar esta opção, descomente as linhas abaixo\n","# config_data = json.loads(manual_json)\n","# config_data['project_base_dir'] = project_base_dir_manual  # Use o caminho configurado pelo usuário\n","# print('Configuração definida manualmente:')\n","# display(config_data)"]},{"cell_type":"markdown","id":"809ecf33","metadata":{"id":"809ecf33"},"source":["# 01_Geracao_Dados_Mock.ipynb\n","\n","Este notebook realiza a coleta de requisitos via chat com IA Gemini, gera o arquivo de configuração do projeto e simula dados de sensores para projetos de séries temporais multivariadas.\n","\n","**Instruções:**\n","- Monte seu Google Drive.\n","- Adapte o caminho base do projeto conforme sua estrutura.\n","- Configure sua chave de API Gemini nos Segredos do Colab (`GEMINI_API_KEY`).\n","- A interação com a API começa aqui."]},{"cell_type":"code","execution_count":62,"id":"9c4ae0d5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3102,"status":"ok","timestamp":1747531427742,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"},"user_tz":180},"id":"9c4ae0d5","outputId":"49bcceb0-f4a3-467e-e137-affa418bf562"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n","Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n","Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n","Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.2)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n","Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n","Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.4.26)\n"]}],"source":["# Instalar bibliotecas necessárias\n","!pip install numpy pandas google-generativeai"]},{"cell_type":"markdown","id":"b215126e","metadata":{"id":"b215126e"},"source":["## Montagem do Google Drive\n","Monte seu Google Drive para salvar arquivos de configuração e dados."]},{"cell_type":"code","execution_count":63,"id":"4a4b6b95","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2433,"status":"ok","timestamp":1747531437862,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"},"user_tz":180},"id":"4a4b6b95","outputId":"8fa53c5d-4aa1-4c79-9920-357b7d3319c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["# Montar Google Drive\n","drive.mount('/content/drive/')"]},{"cell_type":"markdown","id":"e5abfdd1","metadata":{"id":"e5abfdd1"},"source":["## Definição do caminho base do projeto\n","Adapte a string abaixo para o diretório desejado no seu Google Drive."]},{"cell_type":"code","execution_count":64,"id":"d9628e2e","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1747531440342,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"},"user_tz":180},"id":"d9628e2e"},"outputs":[],"source":["# Obter o diretório atual do notebook\n","\n","# Verificar ambiente (Colab ou local)\n","try:\n","    # Se estiver no Colab\n","    from google.colab import drive\n","    IS_COLAB = True\n","    # O diretório base será definido depois de montar o Google Drive\n","    current_notebook_dir = None\n","except ImportError:\n","    # Se estiver em ambiente local\n","    IS_COLAB = False\n","    # Obtém o diretório atual onde o notebook está sendo executado\n","    current_notebook_dir = os.path.abspath('')\n","    print(f\"Diretório atual do notebook: {current_notebook_dir}\")"]},{"cell_type":"code","execution_count":65,"id":"a1a2acd1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1747531443423,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"},"user_tz":180},"id":"a1a2acd1","outputId":"2d139101-a257-41c9-976b-f91a7e7c08cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Usando diretório base: /content/drive/MyDrive/SimClasIotIA/\n"]}],"source":["# Defina o diretório base do projeto (ADAPTE PARA O SEU CASO)\n","if IS_COLAB:\n","    # Sempre use um subdiretório do MyDrive para evitar erro de permissão\n","    project_base_dir_manual = '/content/drive/MyDrive/SimClasIotIA/'\n","    os.makedirs(project_base_dir_manual, exist_ok=True)\n","else:\n","    project_base_dir_manual = os.path.abspath('SimClasIotIA')\n","    os.makedirs(project_base_dir_manual, exist_ok=True)\n","print(f\"Usando diretório base: {project_base_dir_manual}\")"]},{"cell_type":"markdown","id":"a38a58d3","metadata":{"id":"a38a58d3"},"source":["## Configuração segura da API Gemini\n","A chave de API Gemini deve ser salva nos Segredos do Colab com o nome `GEMINI_API_KEY`."]},{"cell_type":"code","execution_count":66,"id":"10d0a847","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":961,"status":"ok","timestamp":1747531452024,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"},"user_tz":180},"id":"10d0a847","outputId":"307bc52c-fe22-4c17-d758-91c3a339d79f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Gemini API configurada com sucesso.\n"]}],"source":["# Configurar API Gemini\n","from google.colab import userdata\n","\n","API_KEY = userdata.get('GOOGLE_API_KEY')\n","\n","if API_KEY is None:\n","    print(\"ERRO: Chave GEMINI_API_KEY não encontrada nos Segredos do Colab. Por favor, configure-a.\")\n","else:\n","    try:\n","        genai.configure(api_key=API_KEY)\n","        print(\"Gemini API configurada com sucesso.\")\n","    except Exception as e:\n","        print(f'ERRO ao configurar Gemini API: {e}')"]},{"cell_type":"markdown","id":"38a7c81c","metadata":{"id":"38a7c81c"},"source":["## Chat em duas fases com Gemini\n","Na Fase 1, o foco é entender a natureza e o contexto do sensor.\n","\n","**Gatilho para encerrar digite:** `xpto`\n","\n","# Verificar modelos disponíveis\n","if GEMINI_AVAILABLE:\n","    try:\n","        print(\"Modelos disponíveis:\")\n","        for m in genai.list_models():\n","            print(m.name)\n","    except Exception as e:\n","        print(f\"ERRO ao listar modelos Gemini: {e}\")\n","else:\n","    print(\"Não foi possível listar modelos porque o Gemini API não está disponível.\")"]},{"cell_type":"code","execution_count":null,"id":"d44ed1c1","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"executionInfo":{"elapsed":452983,"status":"ok","timestamp":1747528149277,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"},"user_tz":180},"id":"d44ed1c1","outputId":"e5daaa42-b3a6-47dc-d110-2524bc21a7e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Iniciando Fase 1 do chat:\n","IA: Ok, vamos lá!\n","\n","Olá! Obrigado por disponibilizar seu tempo para me ajudar com este projeto. Sou [Seu Nome], cientista de dados, e estou trabalhando na simulação de dados de sensores para o seu projeto de IoT. Para começar, preciso entender melhor o sensor que você pretende simular e o contexto em que ele será utilizado.\n","\n","Primeiramente, poderia me dizer **qual é o tipo de fenômeno físico que o sensor mede?** Por exemplo, ele mede distância, luz, temperatura, movimento, pressão, umidade, qualidade do ar, ou algo diferente?\n","\n","(Aguardando resposta)\n","\n","Certo, e agora, pensando no **ambiente de operação do sensor**, onde ele será utilizado? Ele estará em um robô móvel, em um sistema de segurança, em uma área de monitoramento ambiental, dentro de uma máquina industrial, em um dispositivo vestível, ou em outro lugar?\n","\n","(Aguardando resposta)\n","\n","Excelente. Agora, um pouco mais de detalhe sobre o **ambiente**:\n","\n","*   Se for um ambiente interno, qual o tamanho aproximado do espaço e as condições ambientais típicas (temperatura média, umidade relativa)?\n","*   Se for um ambiente externo, está exposto a intempéries (sol, chuva, vento) ou protegido? Qual a variação de temperatura esperada ao longo do dia e do ano?\n","*   Se for um ambiente industrial, quais são os processos que ocorrem nas proximidades? Há vibrações, radiação eletromagnética, produtos químicos no ar, variações extremas de temperatura?\n","\n","(Aguardando resposta)\n","\n","Ok. Com base nas suas respostas, gostaria de verificar se o contexto geral do sensor está bem definido para você.\n","\n","Você considera que o **CONTEXTO DO SENSOR ESTÁ DEFINIDO**?\n","\n","Você: sensor hs-SR04; ambiente urbano (externo)\n","IA: Entendi. Sensor de distância ultrassônico HS-SR04 utilizado em ambiente urbano externo.\n","\n","Com isso em mente, posso te fazer mais algumas perguntas para refinar o entendimento do contexto? Especificamente sobre o ambiente urbano:\n","\n","*   **Qual a localização típica do sensor dentro do ambiente urbano?** Está em um poste de luz, um semáforo, um veículo, na fachada de um prédio, enterrado no solo, ou em outro local? Essa localização influencia na exposição do sensor a elementos como poeira, vibração, vandalismo, etc.?\n","\n","*   **Qual a densidade típica do ambiente urbano onde o sensor estará operando?** É uma área densamente povoada com muito tráfego de pedestres e veículos, uma área mais suburbana com menos movimento, ou uma área industrial com pouco acesso público? Isso afeta os tipos de objetos ou obstáculos que o sensor irá detectar?\n","\n","*   **Quais as condições climáticas típicas da região?** É uma região com muita chuva, neve, neblina, sol forte, ou variações sazonais extremas? Isso afeta o desempenho do sensor?\n","\n","(Aguardando resposta)\n","\n","Certo, e agora, levando em consideração as respostas adicionais e o contexto geral que discutimos até agora, você considera que o **CONTEXTO DO SENSOR ESTÁ DEFINIDO**?\n","\n","Você: anexo a uma bengala guia para deficientes visuais\n","IA: Ok, muito bom! Então, o sensor de distância ultrassônico HS-SR04 está anexado a uma bengala guia para deficientes visuais em um ambiente urbano externo.\n","\n","Este contexto é crucial! Com isso em mente, preciso refinar um pouco mais o entendimento:\n","\n","*   **Como o sensor está posicionado na bengala?** Aponta diretamente para frente, para o chão, ou em um ângulo específico? Isso afeta o alcance e o campo de visão do sensor?\n","*   **Qual a altura do sensor em relação ao chão quando a bengala está em uso?** Essa altura influencia os tipos de obstáculos que o sensor precisa detectar (ex: buracos, degraus, objetos pendurados)?\n","*   **Qual a velocidade típica de caminhada do usuário?** A velocidade afeta a frequência com que o sensor precisa coletar dados para evitar colisões?\n","*   **Em qual tipo de ambiente urbano específico o usuário irá utilizar a bengala com mais frequência?** Calçadas com diferentes tipos de piso (lisos, irregulares, com obstáculos), ruas com tráfego de veículos, parques, etc. Isso influencia nos tipos de obstáculos e superfícies que o sensor irá encontrar.\n","\n","(Aguardando resposta)\n","\n","Agora, com todas essas informações em mente, você considera que o **CONTEXTO DO SENSOR ESTÁ DEFINIDO**?\n","\n","Você: posicionado a frente para dectar obstáculo a frente, aereos e fixos\n","IA: Entendido. O sensor está posicionado para frente, detectando obstáculos aéreos e fixos.\n","\n","Para garantir que capturei todas as nuances importantes do contexto, preciso entender alguns detalhes finais:\n","\n","*   **Qual a faixa de altura dos obstáculos aéreos que precisam ser detectados?** (ex: galhos de árvores baixos, toldos, placas de sinalização)\n","*   **Qual a menor distância que o sensor precisa ser capaz de detectar obstáculos com precisão para dar tempo de reação ao usuário?** (ex: 3 metros, 1 metro, 50 centímetros)\n","*   **O sensor precisa ser capaz de diferenciar entre diferentes tipos de obstáculos (ex: pessoas, carros, postes)?** Se sim, quais são os tipos de obstáculos mais importantes para o sistema identificar?\n","*   **Quais as condições de iluminação típicas em que o sensor operará?** (ex: luz solar direta, sombra, noite com iluminação pública) A iluminação afeta o desempenho do sensor ultrassônico?\n","\n","(Aguardando resposta)\n","\n","Finalmente, com tudo o que discutimos até agora sobre a natureza do sensor, sua funcionalidade geral e o contexto de uso na bengala guia, você considera que o **CONTEXTO DO SENSOR ESTÁ DEFINIDO**?\n","\n","Você: sim\n","IA: Excelente! Agora que temos um bom entendimento do contexto do sensor, podemos passar para a próxima fase: definir os objetivos de detecção e os cenários específicos que você deseja simular. Preparado?\n","\n","Você: sim\n","IA: Ótimo! Agora vamos nos concentrar nos **objetivos de detecção** e nos **cenários** que você deseja simular.\n","\n","Primeiro, qual é o **objetivo principal** do sensor neste contexto? É alertar o usuário sobre a presença de obstáculos para evitar colisões? É ajudar o usuário a navegar por ambientes complexos? É coletar dados sobre o ambiente para mapeamento ou análise?\n","\n","(Aguardando resposta)\n","\n","Você: m um sistema acoplado a uma bengala guia para informar se existe algum obstáculo a frente \n","IA: Entendi. O objetivo principal é informar a presença de obstáculos à frente.\n","\n","Agora, vamos detalhar os **cenários de uso** que você gostaria de simular. Pense em situações específicas que o usuário da bengala enfrentaria no dia a dia e que seriam importantes para testar o sistema.\n","\n","*   **Pode me dar exemplos de cenários específicos onde o sensor precisaria funcionar de forma confiável?**\n","\n","Por exemplo:\n","\n","*   Caminhar em uma calçada movimentada com pedestres e outros obstáculos.\n","*   Atravessar uma rua com carros estacionados e tráfego.\n","*   Navegar por um ambiente interno com corredores estreitos e objetos pendurados.\n","*   Detectar um buraco ou obstáculo no chão.\n","*   Detectar um galho de árvore baixo ou uma placa de sinalização.\n","*   Identificar a presença de um degrau ou escada.\n","\n","Quanto mais detalhes você puder fornecer sobre esses cenários, melhor poderemos simular os dados do sensor. Por favor, liste os cenários mais importantes para você.\n","\n","Você: aminhar em uma calçada movimentada com pedestres e outros obstáculos, Detectar um galho de árvore baixo ou uma placa de sinalização.\n","IA: Ok, temos dois cenários principais:\n","\n","1.  **Caminhar em uma calçada movimentada com pedestres e outros obstáculos.**\n","2.  **Detectar um galho de árvore baixo ou uma placa de sinalização.**\n","\n","Para o primeiro cenário (calçada movimentada), quais são os tipos de obstáculos *além* de pedestres que você considera mais importantes para simular? (ex: lixeiras, postes, placas de rua, bicicletas estacionadas, etc.) E qual a densidade de pedestres que você gostaria de simular (baixa, média, alta)?\n","\n","Para o segundo cenário (galho de árvore/placa), qual a faixa de altura típica desses obstáculos em relação ao chão? Qual a distância mínima que o sensor deve detectar esses obstáculos para alertar o usuário a tempo? Qual a largura/tamanho típico desses obstáculos?\n","\n","Você: acima da linha da cintura\n","IA: Ok, então focaremos em obstáculos acima da linha da cintura.\n","\n","Para o cenário da calçada movimentada: além de pedestres, vamos considerar lixeiras, postes de luz e placas de rua como obstáculos relevantes. Para simular a movimentação dos pedestres, qual densidade você acha mais importante: baixa, média ou alta? (Pense em quão cheia a calçada precisa estar para ser um desafio para o usuário).\n","\n","Para o cenário do galho de árvore/placa de sinalização: se \"acima da linha da cintura\" for a única informação que temos, podemos assumir uma altura mínima de 1 metro do chão, correto? Qual a distância mínima que o sensor deve detectar esses obstáculos (galhos e placas) para alertar o usuário a tempo? E qual o tamanho/largura típico desses objetos? (ex: galhos finos, placas grandes, etc.)\n","\n","Você: acima de 1 metro, distancia minima de 45 centimetros, todos os tamanhos\n","IA: Perfeito. Então, recapitulando:\n","\n","**Cenário 1: Calçada Movimentada**\n","\n","*   Obstáculos: Pedestres (densidade a definir), lixeiras, postes de luz e placas de rua.\n","*   Altura dos obstáculos: Variável, mas geralmente acima da linha da cintura (acima de 1 metro).\n","\n","**Cenário 2: Detecção de Objetos Aéreos**\n","\n","*   Obstáculos: Galhos de árvores baixos e placas de sinalização.\n","*   Altura dos obstáculos: Acima de 1 metro.\n","*   Distância mínima de detecção: 45 centímetros.\n","*   Tamanho dos obstáculos: Todos os tamanhos (de galhos finos a placas grandes).\n","\n","Para o cenário da calçada movimentada, qual densidade de pedestres você considera mais relevante para simular: baixa, média ou alta? Isso ajudará a definir a complexidade da simulação e a testar a capacidade do sensor de lidar com diferentes níveis de obstrução.\n","\n","Você: xpto\n","Fase 1 concluída pelo usuário.\n","...\n"]}],"source":["# Fase 1: Coleta de contexto do sensor\n","phase1_complete_trigger = \"xpto\"\n","gemini_model_name = 'gemini-2.0-flash'\n","\n","phase1_initial_prompt = f'''Aja como um cientista de daods experiente que está entrevistando um usuário leigo para coletar requisitos para simular dados de um sensor para um projeto IOT.\n","Seu foco é entender a NATUREZA e a FUNCIONALIDADE geral do sensor e o CONTEXTO onde ele será usado (ex: robô móvel, sistema de segurança, monitoramento ambiental).\n","Faça perguntas sobre que tipo de fenômeno físico o sensor mede (distância, luz, temperatura, movimento, etc.) e qual o ambiente de operação.\n","Ao final desta fase de entendimento do sensor e contexto, você deve perguntar ao usuário se ele considera que o CONTEXTO DO SENSOR ESTÁ DEFINIDO. Ele responderá \"{phase1_complete_trigger}\" para indicar que podemos seguir.\n","Não avance para perguntar sobre objetivos de detecção ainda.'''\n","chat = genai.GenerativeModel(model_name=gemini_model_name).start_chat(history=[])\n","response = chat.send_message(phase1_initial_prompt)\n","print(\"Iniciando Fase 1 do chat:\")\n","print(\"IA:\", response.text)\n","\n","# Loop de interação Fase 1\n","while True:\n","    user_input = input('Você: ')\n","    if user_input == phase1_complete_trigger:\n","        print('Fase 1 concluída pelo usuário.')\n","        break\n","    response = chat.send_message(user_input)\n","    print('IA:', response.text)\n","print('...')"]},{"cell_type":"markdown","id":"c3ed8d62","metadata":{"id":"c3ed8d62"},"source":["### Interação do usuário na Fase 1\n","Digite suas respostas abaixo, linha por linha. Use a frase gatilho para encerrar a Fase 1."]},{"cell_type":"markdown","id":"9e41fbf1","metadata":{"id":"9e41fbf1"},"source":["## Fase 2: Objetivos de detecção/classificação\n","Agora, o foco é entender os objetivos de detecção/classificação e as características relevantes.\n","\n","**Gatilho para pedir o JSON final:** `Gerar Config JSON agora`"]},{"cell_type":"code","execution_count":null,"id":"d88439ad","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":145313,"status":"ok","timestamp":1747528303050,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"},"user_tz":180},"id":"d88439ad","outputId":"df958739-6b73-4dcf-855b-1e0fc0dca43d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Iniciando Fase 2 do chat:\n","IA: Entendido! Fase 2 iniciada: Objetivos de Detecção e Classificação.\n","\n","Agora que temos os cenários definidos, vamos nos aprofundar nos objetivos específicos de detecção/classificação. Quais *tipos* de situações ou obstáculos o sistema precisa *identificar* ou *diferenciar* usando os dados do sensor?\n","\n","Por exemplo:\n","\n","*   O sistema precisa *detectar a presença* de pessoas?\n","*   Precisa *diferenciar* entre obstáculos estáticos (postes, lixeiras) e obstáculos dinâmicos (pessoas, animais)?\n","*   Precisa *identificar* o tipo de superfície à frente (calçada, rua, grama)?\n","*   Precisa *notar mudanças ambientais* como a presença de uma poça d'água?\n","*   Precisa *diferenciar* objetos grandes de pequenos?\n","\n","Quais desses objetivos são mais importantes para o seu sistema, e existem outros que você gostaria de adicionar?\n","\n","Você: O sistema precisa *detectar a presença* de pessoas,  Precisa *diferenciar* entre obstáculos estáticos e Precisa *diferenciar* objetos grandes de pequenos? \n","IA: Ótimo. Então os objetivos são:\n","\n","1.  **Detectar a presença de pessoas.**\n","2.  **Diferenciar entre obstáculos estáticos (postes, lixeiras, etc.) e obstáculos dinâmicos (pessoas, animais, etc.).**\n","3.  **Diferenciar objetos grandes de pequenos.**\n","\n","Com base nesses objetivos, quais características (features) *derivadas dos dados do sensor de distância* você acha que seriam mais relevantes para classificar esses diferentes tipos de obstáculos?\n","\n","Pensando no sensor de distância, algumas possibilidades são:\n","\n","*   **Distância:** A distância bruta medida pelo sensor.\n","*   **Variação da Distância:** A taxa de mudança na distância ao longo do tempo. (útil para detectar movimento e diferenciar objetos estáticos de dinâmicos).\n","*   **Tamanho Percebido:** Uma estimativa do tamanho do objeto com base na distância e na largura do feixe do ultrassom (se conhecermos essa informação). Podemos estimar se o objeto é pequeno (ex: um galho fino) ou grande (ex: uma pessoa).\n","*   **Velocidade de Aproximação:** A velocidade com que um objeto está se aproximando ou se afastando do sensor. (útil para detectar pessoas se movendo).\n","*   **Frequência de Detecção:** A frequência com que o sensor detecta um objeto em um determinado período de tempo. (obstáculos estáticos tendem a ser detectados de forma consistente, enquanto obstáculos dinâmicos podem aparecer e desaparecer).\n","\n","Quais dessas características você considera mais relevantes para alcançar seus objetivos de detecção? Existem outras características que você gostaria de adicionar à lista?\n","\n","Você: **Distância:** A distância bruta medida pelo sensor. *   **Variação da Distância:** A taxa de mudança na distância ao longo do tempo. (útil para detectar movimento e diferenciar objetos estáticos de dinâmicos). *   **Tamanho Percebido:** Uma estimativa do tamanho do objeto com base na distância e na largura do feixe do ultrassom (se conhecermos essa informação). Podemos estimar se o objeto é pequeno (ex: um galho fino) ou grande (ex: uma pessoa). *   **Velocidade de Aproximação (útil para detectar pessoas se movendo). *   **Frequência de Detecção:**\n","IA: Ok, as características (features) selecionadas são:\n","\n","*   Distância\n","*   Variação da Distância\n","*   Tamanho Percebido\n","*   Velocidade de Aproximação\n","*   Frequência de Detecção\n","\n","Em relação aos tipos de obstáculos que o sistema precisa identificar (nosso \"label\"), podemos definir as seguintes categorias com base nos objetivos que você mencionou:\n","\n","*   Pessoa\n","*   Obstáculo Estático (Poste, Lixeira, etc.)\n","*   Obstáculo Pequeno (Galho, etc.)\n","*   Obstáculo Grande (Carro, etc.)\n","\n","Essa categorização atende às suas necessidades? Você gostaria de adicionar ou modificar alguma dessas categorias? Por exemplo, podemos combinar \"Obstáculo Pequeno\" e \"Obstáculo Grande\" em uma única categoria \"Obstáculo Estático\" com uma característica adicional que indique o tamanho (pequeno ou grande).\n","\n","Você: Pessoa *   Obstáculo Estático (Poste, Lixeira, etc.) *   Obstáculos pequenos e medios\n","IA: Entendido. As categorias finais de obstáculos são:\n","\n","*   Pessoa\n","*   Obstáculo Estático\n","*   Obstáculos pequenos e medios\n","\n","Agora, para garantir que estamos alinhados, confirme se esta configuração está completa. Se estiver tudo certo, diga: \"Sim, fim do Config\".\n","\n","Você: Sim, fim do Config\"\n","Gatilho para JSON detectado na entrada do usuário.\n","IA: ```json\n","{\"project_base_dir\": \"/caminho/definir/usuario/\", \"feature_columns\": [\"Distancia\", \"Variacao da Distancia\", \"Tamanho Percebido\", \"Velocidade de Aproximacao\", \"Frequencia de Deteccao\"], \"label_column\": \"tipo_obstaculo\", \"obstacle_types\": [\"Pessoa\", \"Obstaculo Estatico\", \"Obstaculos pequenos e medios\"]}\n","```\n","\n","==================================================\n","RESPOSTA FINAL RECEBIDA:\n","==================================================\n","```json\n","{\"project_base_dir\": \"/caminho/definir/usuario/\", \"feature_columns\": [\"Distancia\", \"Variacao da Distancia\", \"Tamanho Percebido\", \"Velocidade de Aproximacao\", \"Frequencia de Deteccao\"], \"label_column\": \"tipo_obstaculo\", \"obstacle_types\": [\"Pessoa\", \"Obstaculo Estatico\", \"Obstaculos pequenos e medios\"]}\n","```\n","\n","==================================================\n","Finalizando fase de chat e extraindo JSON...\n","Chat concluído. Processando resposta final...\n"]}],"source":["# Fase 2: Coleta de objetivos e características\n","phase2_complete_trigger = \"Sim, fim do Config\"\n","phase2_transition_prompt = f'''O usuário confirmou que a Fase 1 (contexto do sensor) está completa. Agora, mude seu foco.\n","Nesta Fase 2, seu objetivo é entender os OBJETIVOS de DETECÇÃO/CLASSIFICAÇÃO do usuário com este sensor. Pergunte quais TIPOS de situações ou 'obstáculos' o sistema deve identificar (ex: detectar pessoas, identificar portas abertas/fechadas, diferenciar objetos grandes de pequenos, notar mudanças ambientais).\n","Com base nas respostas do usuário, você deve inferir quais CARACTERÍSTICAS (features) *derivadas dos dados do sensor* serão relevantes para classificar esses objetivos. Ex: se o sensor mede distância, a 'velocidade de aproximação' ou 'tamanho percebido' podem ser características relevantes. Se mede temperatura, a 'taxa de variação da temperatura' pode ser relevante.\n","Ao final desta fase, quando o usuário disser exatamente \"{phase2_complete_trigger}\", você deve gerar APENAS um objeto JSON com a configuração final, sem texto adicional. O JSON deve estar formatado em uma única linha sem quebras de linha adicionais, e usar aspas duplas para chaves e strings.\n","O JSON deve ter o formato:  {{\"project_base_dir\": \"/caminho/definir/usuario/\", \"feature_columns\": [\"nome_caracteristica_1\", \"nome_caracteristica_2\"], \"label_column\": \"tipo_obstaculo\", \"obstacle_types\": [\"Nome Obstáculo 1\", \"Nome Obstáculo 2\"]}}\n","Use nomes de características e obstáculos baseados na conversa. Use \"/caminho/definir/usuario/\" como valor para project_base_dir.\n","Comece perguntando sobre os objetivos de detecção.'''\n","response = chat.send_message(phase2_transition_prompt)\n","print('Iniciando Fase 2 do chat:')\n","print('IA:', response.text)\n","\n","# Loop de interação Fase 2\n","final_ai_response = ''\n","json_requested = False\n","while True:\n","    user_input = input('Você: ')\n","\n","    # Verificar se o usuário solicitou o JSON\n","    if phase2_complete_trigger in user_input:\n","        json_requested = True\n","        print('Gatilho para JSON detectado na entrada do usuário.')\n","        # Adicionar lembrete explícito para a IA gerar apenas o JSON\n","        user_input = f\"{user_input} - Por favor, gere APENAS o objeto JSON conforme formato especificado, sem comentários ou texto adicional.\"\n","\n","    # Enviar mensagem para a IA\n","    response = chat.send_message(user_input)\n","    print('IA:', response.text)\n","\n","    # Guardar a resposta final sempre (garantindo que tenhamos o conteúdo mais recente)\n","    final_ai_response = response.text\n","\n","    # Sair do loop se o JSON for solicitado\n","    if json_requested:\n","        print('='*50)\n","        print('RESPOSTA FINAL RECEBIDA:')\n","        print('='*50)\n","        print(final_ai_response)\n","        print('='*50)\n","        print('Finalizando fase de chat e extraindo JSON...')\n","        break\n","\n","print('Chat concluído. Processando resposta final...')"]},{"cell_type":"markdown","id":"f0a99b6f","metadata":{"id":"f0a99b6f"},"source":["### Interação do usuário na Fase 2\n","Digite suas respostas abaixo. Use a frase gatilho para pedir o JSON final."]},{"cell_type":"code","execution_count":67,"id":"921f984c","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1747531464323,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"},"user_tz":180},"id":"921f984c","outputId":"7f52eaee-2c3b-493d-b8ea-6589d9b269ae"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"```json\n{\n  \"project_base_dir\": \"/caminho/definir/usuario/\",\n  \"feature_columns\": [\n    \"Distancia\",\n    \"Variacao da Distancia\",\n    \"Tamanho Percebido\",\n    \"Velocidade de Aproximacao\",\n    \"Frequencia de Deteccao\"\n  ],\n  \"label_column\": \"tipo_obstaculo\",\n  \"obstacle_types\": [\n    \"Pessoa\",\n    \"Obstaculo Estatico\",\n    \"Obstaculos pequenos e medios\"\n  ]\n}\n```"},"metadata":{}}],"source":["# Visualizar resposta final da IA que será usada para extrair o JSON\n","from IPython.display import display, Markdown\n","import json as pyjson\n","import re\n","\n","if isinstance(final_ai_response, dict):\n","    display(final_ai_response)\n","else:\n","    try:\n","        # Tenta extrair JSON da string\n","        json_string = re.search(r'\\{.*\\}', final_ai_response, re.DOTALL).group(0)\n","        parsed = pyjson.loads(json_string)\n","        display(Markdown(f'```json\\n{pyjson.dumps(parsed, indent=2, ensure_ascii=False)}\\n```'))\n","    except Exception:\n","        display(Markdown(f'````\\n{final_ai_response}\\n````'))"]},{"cell_type":"markdown","id":"1ef99c91","metadata":{"id":"1ef99c91"},"source":["## Extração do JSON de configuração\n","O código abaixo tentará extrair e validar o JSON da resposta final da IA."]},{"cell_type":"markdown","id":"db7ef4f8","metadata":{"id":"db7ef4f8"},"source":["## Carregar JSON de arquivo existente\n","Você pode carregar uma configuração existente de um arquivo JSON no ambiente local, útil quando estiver executando o notebook sem acesso à API Gemini."]},{"cell_type":"markdown","id":"0ecba66c","metadata":{"id":"0ecba66c"},"source":["## Opção de JSON manual para recuperação\n","Se a extração do JSON da resposta do Gemini falhar, você pode utilizar esta opção manual abaixo."]},{"cell_type":"code","execution_count":68,"id":"55c0dff0","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1747531470010,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"},"user_tz":180},"id":"55c0dff0","outputId":"9c8260ff-944d-4857-e9fb-d257a8af5fb7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","JSON encontrado na resposta:\n","{\"project_base_dir\": \"/caminho/definir/usuario/\", \"feature_columns\": [\"Distancia\", \"Variacao da Distancia\", \"Tamanho Percebido\", \"Velocidade de Aproximacao\", \"Frequencia de Deteccao\"], \"label_column\": \"tipo_obstaculo\", \"obstacle_types\": [\"Pessoa\", \"Obstaculo Estatico\", \"Obstaculos pequenos e medios\"]}\n","\n","JSON extraído e parseado com sucesso.\n","\n","Configuração final obtida:\n"]},{"output_type":"display_data","data":{"text/plain":["{'project_base_dir': '/content/drive/MyDrive/SimClasIotIA/',\n"," 'feature_columns': ['Distancia',\n","  'Variacao da Distancia',\n","  'Tamanho Percebido',\n","  'Velocidade de Aproximacao',\n","  'Frequencia de Deteccao'],\n"," 'label_column': 'tipo_obstaculo',\n"," 'obstacle_types': ['Pessoa',\n","  'Obstaculo Estatico',\n","  'Obstaculos pequenos e medios']}"]},"metadata":{}}],"source":["# Extração e validação do JSON\n","fallback_config_data = {\n","    'project_base_dir': project_base_dir_manual,\n","    'feature_columns': ['distancia_cm'],\n","    'label_column': 'tipo_obstaculo',\n","    'obstacle_types': ['Default Obstacle']\n","}\n","config_data = None\n","try:\n","    # Verificar se temos uma resposta final para processar\n","    if not final_ai_response or final_ai_response.strip() == '':\n","        print('ERRO: Resposta final da IA está vazia.')\n","    else:\n","        # Procurar por padrão que se parece com JSON entre chaves\n","        # Pattern melhorado para ser mais robusto\n","        json_string_match = re.search(r'\\{[^{}]*((\\{[^{}]*\\})|[^{}])*\\}', final_ai_response, re.DOTALL)\n","        if json_string_match:\n","            json_string = json_string_match.group(0)\n","            print('\\nJSON encontrado na resposta:')\n","            print(json_string)\n","            # Tenta parsear o JSON\n","            config_data = json.loads(json_string)\n","            print('\\nJSON extraído e parseado com sucesso.')\n","        else:\n","            print('ERRO: Objeto JSON não encontrado na resposta final da IA.')\n","            print('Conteúdo da resposta:')\n","            print(final_ai_response)\n","\n","            # Tentativa alternativa: procurar por chaves individuais e construir o JSON\n","            feature_match = re.search(r'\"feature_columns\"\\s*:\\s*\\[(.*?)\\]', final_ai_response)\n","            obstacle_match = re.search(r'\"obstacle_types\"\\s*:\\s*\\[(.*?)\\]', final_ai_response)\n","            label_match = re.search(r'\"label_column\"\\s*:\\s*\"(.*?)\"', final_ai_response)\n","\n","            if feature_match and obstacle_match and label_match:\n","                # Tentar construir o JSON manualmente\n","                try:\n","                    feature_str = '[' + feature_match.group(1) + ']'\n","                    obstacle_str = '[' + obstacle_match.group(1) + ']'\n","                    features = json.loads(feature_str)\n","                    obstacles = json.loads(obstacle_str)\n","                    label = label_match.group(1)\n","\n","                    config_data = {\n","                        'project_base_dir': project_base_dir_manual,\n","                        'feature_columns': features,\n","                        'label_column': label,\n","                        'obstacle_types': obstacles\n","                    }\n","                    print('\\nJSON construído manualmente a partir dos fragmentos encontrados.')\n","                except Exception as e:\n","                    print(f'Erro ao tentar construir JSON manualmente: {e}')\n","\n","except json.JSONDecodeError as e:\n","    print(f'ERRO: Falha ao parsear JSON da resposta da IA: {e}')\n","    print(f'Texto que causou o erro: {json_string if \"json_string\" in locals() else \"N/A\"}')\n","    # Tenta limpar o JSON removendo texto extra\n","    if \"json_string\" in locals():\n","        clean_json = re.sub(r'[^{}\\[\\]:,\"0-9a-zA-Z_\\-\\.\\s]', '', json_string)\n","        try:\n","            config_data = json.loads(clean_json)\n","            print('JSON limpo e parseado com sucesso após remoção de caracteres inválidos.')\n","        except:\n","            print('Falha ao parsear JSON mesmo após limpeza.')\n","except Exception as e:\n","    print(f'ERRO inesperado ao processar resposta da IA: {e}')\n","\n","# Validar e completar config_data\n","if config_data and isinstance(config_data, dict):\n","    required_keys = ['feature_columns', 'obstacle_types', 'label_column']\n","    missing_keys = []\n","    for key in required_keys:\n","        if key not in config_data:\n","            missing_keys.append(key)\n","            print(f'Aviso: Chave {key} ausente no JSON gerado pela IA.')\n","\n","    if missing_keys:\n","        print(f\"Chaves ausentes: {missing_keys}. Usando valores padrão para as chaves ausentes.\")\n","        for key in missing_keys:\n","            config_data[key] = fallback_config_data[key]\n","\n","    config_data['project_base_dir'] = project_base_dir_manual\n","    print('\\nConfiguração final obtida:')\n","    display(config_data)\n","else:\n","    print('Usando configuração de fallback devido a erro ou falta de JSON da IA.')\n","    config_data = fallback_config_data\n","    config_data['project_base_dir'] = project_base_dir_manual\n","    display(config_data)"]},{"cell_type":"markdown","id":"89ef81a7","metadata":{"id":"89ef81a7"},"source":["## Geração dos dados simulados\n","A partir deste ponto, o código usará o config_data para gerar dados simulados e salvar os arquivos."]},{"cell_type":"code","execution_count":69,"id":"7bbd329a","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1747531476654,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"},"user_tz":180},"id":"7bbd329a","outputId":"29172383-f2f3-4a12-c64a-adaae7aa8ead"},"outputs":[{"output_type":"stream","name":"stdout","text":["Diretório base criado: /content/drive/MyDrive/SimClasIotIA/\n","Amostra dos dados simulados:\n"]},{"output_type":"display_data","data":{"text/plain":["                timestamp   Distancia  Variacao da Distancia  \\\n","0 2025-01-01 00:00:00.000  132.296717             110.721300   \n","1 2025-01-01 00:00:00.500  147.416050             115.990516   \n","2 2025-01-01 00:00:01.000  147.033945             123.018566   \n","3 2025-01-01 00:00:01.500  159.757942             131.526410   \n","4 2025-01-01 00:00:02.000  127.963571             133.463119   \n","\n","   Tamanho Percebido  Velocidade de Aproximacao  Frequencia de Deteccao  \\\n","0          99.963975                 117.491721               89.767722   \n","1          88.616340                 109.993741               92.255726   \n","2         115.433876                 113.433612               89.377090   \n","3         109.373263                 127.662581               92.100445   \n","4          98.589505                 140.838001              108.026107   \n","\n","       tipo_obstaculo  \n","0              Pessoa  \n","1              Pessoa  \n","2              Pessoa  \n","3  Obstaculo Estatico  \n","4  Obstaculo Estatico  "],"text/html":["\n","  <div id=\"df-2a468df1-3cb5-4ccf-959e-244e4ae10fdd\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>timestamp</th>\n","      <th>Distancia</th>\n","      <th>Variacao da Distancia</th>\n","      <th>Tamanho Percebido</th>\n","      <th>Velocidade de Aproximacao</th>\n","      <th>Frequencia de Deteccao</th>\n","      <th>tipo_obstaculo</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2025-01-01 00:00:00.000</td>\n","      <td>132.296717</td>\n","      <td>110.721300</td>\n","      <td>99.963975</td>\n","      <td>117.491721</td>\n","      <td>89.767722</td>\n","      <td>Pessoa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2025-01-01 00:00:00.500</td>\n","      <td>147.416050</td>\n","      <td>115.990516</td>\n","      <td>88.616340</td>\n","      <td>109.993741</td>\n","      <td>92.255726</td>\n","      <td>Pessoa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2025-01-01 00:00:01.000</td>\n","      <td>147.033945</td>\n","      <td>123.018566</td>\n","      <td>115.433876</td>\n","      <td>113.433612</td>\n","      <td>89.377090</td>\n","      <td>Pessoa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2025-01-01 00:00:01.500</td>\n","      <td>159.757942</td>\n","      <td>131.526410</td>\n","      <td>109.373263</td>\n","      <td>127.662581</td>\n","      <td>92.100445</td>\n","      <td>Obstaculo Estatico</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2025-01-01 00:00:02.000</td>\n","      <td>127.963571</td>\n","      <td>133.463119</td>\n","      <td>98.589505</td>\n","      <td>140.838001</td>\n","      <td>108.026107</td>\n","      <td>Obstaculo Estatico</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a468df1-3cb5-4ccf-959e-244e4ae10fdd')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2a468df1-3cb5-4ccf-959e-244e4ae10fdd button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2a468df1-3cb5-4ccf-959e-244e4ae10fdd');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-8631de2e-e179-4487-818e-8c1b5a9661da\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8631de2e-e179-4487-818e-8c1b5a9661da')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-8631de2e-e179-4487-818e-8c1b5a9661da button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-01-01 00:00:00\",\n        \"max\": \"2025-01-01 00:00:02\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2025-01-01 00:00:00.500000\",\n          \"2025-01-01 00:00:02\",\n          \"2025-01-01 00:00:01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Distancia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.817963179127764,\n        \"min\": 127.96357112623451,\n        \"max\": 159.75794179051502,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          147.41604968123903,\n          127.96357112623451,\n          147.03394501429386\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Variacao da Distancia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.773184052363295,\n        \"min\": 110.72130035456613,\n        \"max\": 133.4631188982487,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          115.9905157248589,\n          133.4631188982487,\n          123.0185661322395\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tamanho Percebido\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.35557341178202,\n        \"min\": 88.6163397750079,\n        \"max\": 115.43387635953785,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          88.6163397750079,\n          98.58950520139508,\n          115.43387635953785\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Velocidade de Aproximacao\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.497255486880372,\n        \"min\": 109.99374121642172,\n        \"max\": 140.8380009919086,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          109.99374121642172,\n          140.8380009919086,\n          113.43361194420967\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Frequencia de Deteccao\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.781380815481489,\n        \"min\": 89.37709012323485,\n        \"max\": 108.02610703491791,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          92.25572613224652,\n          108.02610703491791,\n          89.37709012323485\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tipo_obstaculo\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Obstaculo Estatico\",\n          \"Pessoa\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["# Criar diretório base do projeto\n","try:\n","    os.makedirs(project_base_dir_manual, exist_ok=True)\n","    print(f\"Diretório base criado: {project_base_dir_manual}\")\n","except Exception as e:\n","    print(f'ERRO ao criar diretório base: {e}')\n","\n","# Definir nomes e caminhos dos arquivos de saída\n","config_output_filename = 'project_config.json'\n","data_output_filename = 'simulated_sensor_data.csv'\n","config_filepath = os.path.join(project_base_dir_manual, config_output_filename)\n","data_filepath = os.path.join(project_base_dir_manual, data_output_filename)\n","\n","# Ajustar caminhos para ambiente Windows\n","if os.name == 'nt':  # Verificar se é Windows\n","    # Verificar se o caminho atual tem espaços ou caracteres especiais\n","    current_path = os.path.abspath('')\n","    if ' ' in current_path or any(c in current_path for c in '()[]{}áéíóúàèìòùâêîôûãõñç'):\n","        print(\"AVISO: O caminho atual contém espaços ou caracteres especiais:\")\n","        print(current_path)\n","        print(\"\\nPara melhor compatibilidade, considere criar uma pasta de projeto com nome simples.\")\n","\n","        # Sugerir pasta no usuário para o projeto\n","        simpler_path = os.path.join(os.path.expanduser(\"~\"), \"SimClasIotIA_Project\")\n","        print(f\"\\nSugestão de caminho alternativo: {simpler_path}\")\n","\n","        # Perguntar se deseja usar o caminho alternativo\n","        print(\"\\nPara usar o caminho alternativo, descomente e execute o código abaixo:\")\n","        print(f\"\"\"# projeto_dir = \"{simpler_path}\"\n","# os.makedirs(projeto_dir, exist_ok=True)\n","# project_base_dir_manual = projeto_dir\"\"\")\n","    else:\n","        print(\"O caminho atual não contém espaços ou caracteres especiais. Bom para compatibilidade!\")\n","\n","# Lógica de geração de dados simulados\n","n_samples = 500  # Número de amostras a gerar\n","time_interval_seconds = 0.5  # Intervalo entre medições\n","noise_level = 0.1  # Nível de ruído (0 a 1)\n","\n","# Verificar se temos as configurações mínimas\n","feature_columns = config_data.get('feature_columns', ['distancia'])\n","obstacle_types = config_data.get('obstacle_types', ['Default Obstacle'])\n","label_column = config_data.get('label_column', 'tipo_obstaculo')\n","\n","\n","\n","\n","# Gerar timestamp\n","np.random.seed(42)\n","start_time = pd.Timestamp('2025-01-01')\n","timestamps = [start_time + pd.Timedelta(seconds=i*time_interval_seconds) for i in range(n_samples)]\n","\n","# Gerar dados para cada feature\n","data = {'timestamp': timestamps}\n","for feature in feature_columns:\n","    # Gerar valores base para cada tipo de obstáculo\n","    values = []\n","    current_obstacle = None\n","    for i in range(n_samples):\n","        # Mudar de obstáculo a cada ~50 amostras em média\n","        if i % 50 == 0 or current_obstacle is None:\n","            current_obstacle = np.random.choice(obstacle_types)\n","\n","        # Gerar valor base dependendo do tipo de obstáculo (simulando características diferentes)\n","        obstacle_index = obstacle_types.index(current_obstacle)\n","        base_value = 100 + (obstacle_index * 20)  # Valores diferentes por tipo\n","\n","        # Adicionar tendência e ruído\n","        trend = np.sin(i/50) * 10  # Tendência senoidal\n","        noise = np.random.normal(0, noise_level * base_value)  # Ruído proporcional\n","        values.append(base_value + trend + noise)\n","\n","    data[feature] = values\n","\n","# Gerar labels (obstáculos) com alguma correlação com os valores gerados\n","obstacle_data = []\n","for i in range(n_samples):\n","    # Determinar o tipo de obstáculo com base em padrões dos valores\n","    feature_sum = sum(data[feature][i] for feature in feature_columns)\n","    index = min(int(feature_sum / 150) % len(obstacle_types), len(obstacle_types) - 1)\n","    obstacle_data.append(obstacle_types[index])\n","\n","data[label_column] = obstacle_data\n","\n","# Criar DataFrame\n","df = pd.DataFrame(data)\n","print('Amostra dos dados simulados:')\n","display(df.head())\n","\n"]},{"cell_type":"markdown","id":"57552091","metadata":{"id":"57552091"},"source":["## Salvando o dataset simulado\n","O DataFrame será salvo como CSV no diretório do projeto."]},{"cell_type":"code","execution_count":70,"id":"021fc24b","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":982},"executionInfo":{"elapsed":168,"status":"ok","timestamp":1747531482370,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"},"user_tz":180},"id":"021fc24b","outputId":"0519ce35-e715-4566-8b6a-da6f3355c155"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset simulado salvo em: /content/drive/MyDrive/SimClasIotIA/simulated_sensor_data.csv\n","Número total de amostras: 500\n"]},{"output_type":"display_data","data":{"text/plain":["                timestamp   Distancia  Variacao da Distancia  \\\n","0 2025-01-01 00:00:00.000  132.296717             110.721300   \n","1 2025-01-01 00:00:00.500  147.416050             115.990516   \n","2 2025-01-01 00:00:01.000  147.033945             123.018566   \n","3 2025-01-01 00:00:01.500  159.757942             131.526410   \n","4 2025-01-01 00:00:02.000  127.963571             133.463119   \n","\n","   Tamanho Percebido  Velocidade de Aproximacao  Frequencia de Deteccao  \\\n","0          99.963975                 117.491721               89.767722   \n","1          88.616340                 109.993741               92.255726   \n","2         115.433876                 113.433612               89.377090   \n","3         109.373263                 127.662581               92.100445   \n","4          98.589505                 140.838001              108.026107   \n","\n","       tipo_obstaculo  \n","0              Pessoa  \n","1              Pessoa  \n","2              Pessoa  \n","3  Obstaculo Estatico  \n","4  Obstaculo Estatico  "],"text/html":["\n","  <div id=\"df-83ec671a-9f1d-4599-a943-cc91d3c54206\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>timestamp</th>\n","      <th>Distancia</th>\n","      <th>Variacao da Distancia</th>\n","      <th>Tamanho Percebido</th>\n","      <th>Velocidade de Aproximacao</th>\n","      <th>Frequencia de Deteccao</th>\n","      <th>tipo_obstaculo</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2025-01-01 00:00:00.000</td>\n","      <td>132.296717</td>\n","      <td>110.721300</td>\n","      <td>99.963975</td>\n","      <td>117.491721</td>\n","      <td>89.767722</td>\n","      <td>Pessoa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2025-01-01 00:00:00.500</td>\n","      <td>147.416050</td>\n","      <td>115.990516</td>\n","      <td>88.616340</td>\n","      <td>109.993741</td>\n","      <td>92.255726</td>\n","      <td>Pessoa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2025-01-01 00:00:01.000</td>\n","      <td>147.033945</td>\n","      <td>123.018566</td>\n","      <td>115.433876</td>\n","      <td>113.433612</td>\n","      <td>89.377090</td>\n","      <td>Pessoa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2025-01-01 00:00:01.500</td>\n","      <td>159.757942</td>\n","      <td>131.526410</td>\n","      <td>109.373263</td>\n","      <td>127.662581</td>\n","      <td>92.100445</td>\n","      <td>Obstaculo Estatico</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2025-01-01 00:00:02.000</td>\n","      <td>127.963571</td>\n","      <td>133.463119</td>\n","      <td>98.589505</td>\n","      <td>140.838001</td>\n","      <td>108.026107</td>\n","      <td>Obstaculo Estatico</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83ec671a-9f1d-4599-a943-cc91d3c54206')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-83ec671a-9f1d-4599-a943-cc91d3c54206 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-83ec671a-9f1d-4599-a943-cc91d3c54206');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-70c15c94-12fb-4d44-84cc-67db5de49bd7\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-70c15c94-12fb-4d44-84cc-67db5de49bd7')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-70c15c94-12fb-4d44-84cc-67db5de49bd7 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"    print(f'ERRO ao salvar configura\\u00e7\\u00e3o: {e}')\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-01-01 00:00:00\",\n        \"max\": \"2025-01-01 00:00:02\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2025-01-01 00:00:00.500000\",\n          \"2025-01-01 00:00:02\",\n          \"2025-01-01 00:00:01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Distancia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.817963179127764,\n        \"min\": 127.96357112623451,\n        \"max\": 159.75794179051502,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          147.41604968123903,\n          127.96357112623451,\n          147.03394501429386\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Variacao da Distancia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.773184052363295,\n        \"min\": 110.72130035456613,\n        \"max\": 133.4631188982487,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          115.9905157248589,\n          133.4631188982487,\n          123.0185661322395\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tamanho Percebido\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.35557341178202,\n        \"min\": 88.6163397750079,\n        \"max\": 115.43387635953785,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          88.6163397750079,\n          98.58950520139508,\n          115.43387635953785\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Velocidade de Aproximacao\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.497255486880372,\n        \"min\": 109.99374121642172,\n        \"max\": 140.8380009919086,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          109.99374121642172,\n          140.8380009919086,\n          113.43361194420967\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Frequencia de Deteccao\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.781380815481489,\n        \"min\": 89.37709012323485,\n        \"max\": 108.02610703491791,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          92.25572613224652,\n          108.02610703491791,\n          89.37709012323485\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tipo_obstaculo\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Obstaculo Estatico\",\n          \"Pessoa\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["                           timestamp   Distancia  Variacao da Distancia  \\\n","count                            500  500.000000             500.000000   \n","mean   2025-01-01 00:02:04.750000128  117.821090             124.336719   \n","min              2025-01-01 00:00:00   58.947203              68.802827   \n","25%    2025-01-01 00:01:02.375000064  100.870700             110.515491   \n","50%    2025-01-01 00:02:04.750000128  116.374497             127.553247   \n","75%    2025-01-01 00:03:07.124999936  135.225766             139.732151   \n","max       2025-01-01 00:04:09.500000  185.017410             173.675032   \n","std                              NaN   22.771383              21.360143   \n","\n","       Tamanho Percebido  Velocidade de Aproximacao  Frequencia de Deteccao  \n","count         500.000000                 500.000000              500.000000  \n","mean          107.940897                 123.682613              112.511963  \n","min            70.368572                  69.464043               68.961443  \n","25%            98.128225                 108.156265               99.808016  \n","50%           108.021434                 122.681388              112.922579  \n","75%           116.748541                 139.058045              124.006298  \n","max           162.124079                 180.828204              162.202255  \n","std            14.501139                  21.479035               17.052380  "],"text/html":["\n","  <div id=\"df-970fe8a0-0ac5-460a-ac3e-a4e48accb934\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>timestamp</th>\n","      <th>Distancia</th>\n","      <th>Variacao da Distancia</th>\n","      <th>Tamanho Percebido</th>\n","      <th>Velocidade de Aproximacao</th>\n","      <th>Frequencia de Deteccao</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>500</td>\n","      <td>500.000000</td>\n","      <td>500.000000</td>\n","      <td>500.000000</td>\n","      <td>500.000000</td>\n","      <td>500.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2025-01-01 00:02:04.750000128</td>\n","      <td>117.821090</td>\n","      <td>124.336719</td>\n","      <td>107.940897</td>\n","      <td>123.682613</td>\n","      <td>112.511963</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>2025-01-01 00:00:00</td>\n","      <td>58.947203</td>\n","      <td>68.802827</td>\n","      <td>70.368572</td>\n","      <td>69.464043</td>\n","      <td>68.961443</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>2025-01-01 00:01:02.375000064</td>\n","      <td>100.870700</td>\n","      <td>110.515491</td>\n","      <td>98.128225</td>\n","      <td>108.156265</td>\n","      <td>99.808016</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>2025-01-01 00:02:04.750000128</td>\n","      <td>116.374497</td>\n","      <td>127.553247</td>\n","      <td>108.021434</td>\n","      <td>122.681388</td>\n","      <td>112.922579</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>2025-01-01 00:03:07.124999936</td>\n","      <td>135.225766</td>\n","      <td>139.732151</td>\n","      <td>116.748541</td>\n","      <td>139.058045</td>\n","      <td>124.006298</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>2025-01-01 00:04:09.500000</td>\n","      <td>185.017410</td>\n","      <td>173.675032</td>\n","      <td>162.124079</td>\n","      <td>180.828204</td>\n","      <td>162.202255</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>NaN</td>\n","      <td>22.771383</td>\n","      <td>21.360143</td>\n","      <td>14.501139</td>\n","      <td>21.479035</td>\n","      <td>17.052380</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-970fe8a0-0ac5-460a-ac3e-a4e48accb934')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-970fe8a0-0ac5-460a-ac3e-a4e48accb934 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-970fe8a0-0ac5-460a-ac3e-a4e48accb934');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-bebcd019-9a92-4d84-92b9-6eb4d32ee3d3\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bebcd019-9a92-4d84-92b9-6eb4d32ee3d3')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-bebcd019-9a92-4d84-92b9-6eb4d32ee3d3 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"    print(f'ERRO ao salvar configura\\u00e7\\u00e3o: {e}')\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1970-01-01 00:00:00.000000500\",\n        \"max\": \"2025-01-01 00:04:09.500000\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"500\",\n          \"2025-01-01 00:02:04.750000128\",\n          \"2025-01-01 00:04:09.500000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Distancia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 147.75979055364374,\n        \"min\": 22.77138331478674,\n        \"max\": 500.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          117.82108993817305,\n          135.22576644534743,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Variacao da Distancia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 145.64365472446673,\n        \"min\": 21.360142727039374,\n        \"max\": 500.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          124.33671923720195,\n          139.73215065224153,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tamanho Percebido\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 148.61944928790749,\n        \"min\": 14.50113948855419,\n        \"max\": 500.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          107.94089694606618,\n          116.74854090858398,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Velocidade de Aproximacao\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 146.00869428261078,\n        \"min\": 21.479035308353552,\n        \"max\": 500.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          123.68261346524841,\n          139.05804483580064,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Frequencia de Deteccao\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 147.7765711874053,\n        \"min\": 17.052380369860103,\n        \"max\": 500.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          112.51196279310736,\n          124.006298230321,\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tipo_obstaculo\n","Pessoa                285\n","Obstaculo Estatico    215\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>tipo_obstaculo</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Pessoa</th>\n","      <td>285</td>\n","    </tr>\n","    <tr>\n","      <th>Obstaculo Estatico</th>\n","      <td>215</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Configuração salva em: /content/drive/MyDrive/SimClasIotIA/project_config.json\n"]}],"source":["#print(f\"Caminho configurado para dados: {data_filepath}\")\n","#print(f\"Caminho configurado para configuração: {config_filepath}\")\n","# Salvar o DataFrame como CSV\n","try:\n","    # Criar diretório se não existir (novamente, para garantir)\n","    os.makedirs(os.path.dirname(data_filepath), exist_ok=True)\n","\n","    # Salvar o arquivo\n","    df.to_csv(data_filepath, index=False)\n","    print(f'Dataset simulado salvo em: {data_filepath}')\n","    print(f'Número total de amostras: {len(df)}')\n","    #print(f'Colunas: {list(df.columns)}')\n","\n","    # Exibir estatísticas básicas para visualização\n","    from IPython.display import display\n","    display(df.head())\n","    display(df.describe())\n","\n","    # Verificar distribuição das classes\n","    #print(\"\\nDistribuição dos tipos de obstáculos:\")\n","    display(df[label_column].value_counts())\n","except IOError as e:\n","    print(f'ERRO ao salvar dataset simulado: {e}')\n","\n","# Salvar o config_data como JSON\n","try:\n","    with open(config_filepath, 'w') as f:\n","        json.dump(config_data, f, indent=2, ensure_ascii=False)\n","    print(f'Configuração salva em: {config_filepath}')\n","except IOError as e:\n","    print(f'ERRO ao salvar configuração: {e}')"]},{"cell_type":"markdown","id":"57891d4a","metadata":{"id":"57891d4a"},"source":["## Salvando o arquivo de configuração\n","O dicionário config_data será salvo como JSON no diretório do projeto."]},{"cell_type":"markdown","id":"fcaaff08","metadata":{"id":"fcaaff08"},"source":["# Conclusão da Etapa 1\n","\n","A configuração do projeto e os dados simulados foram gerados e salvos no seu Google Drive.\n","\n","Na próxima etapa, você irá treinar o modelo de IA usando esses arquivos."]},{"cell_type":"markdown","id":"4fb821e7","metadata":{"id":"4fb821e7"},"source":["# Etapa 02 Treinamento do Modelo de IA\n","\n","Este notebook realiza o pré-processamento de dados multivariados e o treinamento de um modelo de IA a partir de arquivos de configuração e dados simulados salvos no Google Drive.\n","\n","**Passos principais:**\n","- Montar o Google Drive\n","- Carregar o arquivo de configuração e os dados simulados\n","- Pré-processar os dados (multi-feature, sequências)\n","- Treinar o modelo de IA (LSTM, GRU, Conv1D, etc.)\n","- Salvar o modelo treinado e os dados de teste\n"]},{"cell_type":"markdown","id":"26062d4c","metadata":{"id":"26062d4c"},"source":["## Instalar Bibliotecas Necessárias\n","\n","Execute a célula abaixo para instalar as bibliotecas necessárias para o notebook."]},{"cell_type":"markdown","id":"02a7492b","metadata":{"id":"02a7492b"},"source":["## Importar Bibliotecas"]},{"cell_type":"markdown","id":"868b0f49","metadata":{"id":"868b0f49"},"source":["## Montar Google Drive\n","Monte seu Google Drive para acessar os arquivos de configuração e dados simulados."]},{"cell_type":"markdown","id":"48795c03","metadata":{"id":"48795c03"},"source":["## Carregar Configuração e Caminhos\n","Carregue o arquivo de configuração (project_config.json) e extraia project_base_dir, feature_columns e label_column."]},{"cell_type":"code","execution_count":71,"id":"691e1f8c","metadata":{"id":"691e1f8c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747531489192,"user_tz":180,"elapsed":84,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"6bfef582-b60a-4379-f0c1-3395f572137c"},"outputs":[{"output_type":"stream","name":"stdout","text":["project_base_dir: /content/drive/MyDrive/SimClasIotIA/\n","feature_columns: ['Distancia', 'Variacao da Distancia', 'Tamanho Percebido', 'Velocidade de Aproximacao', 'Frequencia de Deteccao']\n","label_column: tipo_obstaculo\n"]}],"source":["# Defina o caminho do arquivo de configuração\n","config_path = '/content/drive/MyDrive/SimClasIotIA/project_config.json'\n","\n","with open(config_path, 'r') as f:\n","    config = json.load(f)\n","\n","project_base_dir = config['project_base_dir']\n","feature_columns = config['feature_columns']\n","label_column = config['label_column']\n","print('project_base_dir:', project_base_dir)\n","print('feature_columns:', feature_columns)\n","print('label_column:', label_column)"]},{"cell_type":"markdown","id":"fbd2149a","metadata":{"id":"fbd2149a"},"source":["## Definir Nomes de Arquivos\n","Defina os nomes dos arquivos relativos para dados, modelo e dados de teste.\n","\n","## Carregar Dados Simulados\n","Carregue o DataFrame de dados simulados a partir do arquivo CSV."]},{"cell_type":"code","execution_count":72,"id":"632b6db6","metadata":{"id":"632b6db6","colab":{"base_uri":"https://localhost:8080/","height":382},"executionInfo":{"status":"ok","timestamp":1747531493163,"user_tz":180,"elapsed":72,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"43d709bd-b4d2-43a0-9113-c81be025a845"},"outputs":[{"output_type":"stream","name":"stdout","text":["data_filepath: /content/drive/MyDrive/SimClasIotIA/simulated_sensor_data.csv\n","model_output_path: /content/drive/MyDrive/SimClasIotIA/modelo_treinado.h5\n"]},{"output_type":"execute_result","data":{"text/plain":["                 timestamp   Distancia  Variacao da Distancia  \\\n","0  2025-01-01 00:00:00.000  132.296717             110.721300   \n","1  2025-01-01 00:00:00.500  147.416050             115.990516   \n","2  2025-01-01 00:00:01.000  147.033945             123.018566   \n","3  2025-01-01 00:00:01.500  159.757942             131.526410   \n","4  2025-01-01 00:00:02.000  127.963571             133.463119   \n","\n","   Tamanho Percebido  Velocidade de Aproximacao  Frequencia de Deteccao  \\\n","0          99.963975                 117.491721               89.767722   \n","1          88.616340                 109.993741               92.255726   \n","2         115.433876                 113.433612               89.377090   \n","3         109.373263                 127.662581               92.100445   \n","4          98.589505                 140.838001              108.026107   \n","\n","       tipo_obstaculo  \n","0              Pessoa  \n","1              Pessoa  \n","2              Pessoa  \n","3  Obstaculo Estatico  \n","4  Obstaculo Estatico  "],"text/html":["\n","  <div id=\"df-69aea0e2-316b-4953-bf5f-03fe4f980541\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>timestamp</th>\n","      <th>Distancia</th>\n","      <th>Variacao da Distancia</th>\n","      <th>Tamanho Percebido</th>\n","      <th>Velocidade de Aproximacao</th>\n","      <th>Frequencia de Deteccao</th>\n","      <th>tipo_obstaculo</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2025-01-01 00:00:00.000</td>\n","      <td>132.296717</td>\n","      <td>110.721300</td>\n","      <td>99.963975</td>\n","      <td>117.491721</td>\n","      <td>89.767722</td>\n","      <td>Pessoa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2025-01-01 00:00:00.500</td>\n","      <td>147.416050</td>\n","      <td>115.990516</td>\n","      <td>88.616340</td>\n","      <td>109.993741</td>\n","      <td>92.255726</td>\n","      <td>Pessoa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2025-01-01 00:00:01.000</td>\n","      <td>147.033945</td>\n","      <td>123.018566</td>\n","      <td>115.433876</td>\n","      <td>113.433612</td>\n","      <td>89.377090</td>\n","      <td>Pessoa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2025-01-01 00:00:01.500</td>\n","      <td>159.757942</td>\n","      <td>131.526410</td>\n","      <td>109.373263</td>\n","      <td>127.662581</td>\n","      <td>92.100445</td>\n","      <td>Obstaculo Estatico</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2025-01-01 00:00:02.000</td>\n","      <td>127.963571</td>\n","      <td>133.463119</td>\n","      <td>98.589505</td>\n","      <td>140.838001</td>\n","      <td>108.026107</td>\n","      <td>Obstaculo Estatico</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69aea0e2-316b-4953-bf5f-03fe4f980541')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-69aea0e2-316b-4953-bf5f-03fe4f980541 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-69aea0e2-316b-4953-bf5f-03fe4f980541');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-0b3a4a65-3a27-446f-93db-0077237678e9\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b3a4a65-3a27-446f-93db-0077237678e9')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-0b3a4a65-3a27-446f-93db-0077237678e9 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"2025-01-01 00:03:00.500\",\n          \"2025-01-01 00:00:36.500\",\n          \"2025-01-01 00:03:07.000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Distancia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22.77138331478674,\n        \"min\": 58.94720343445852,\n        \"max\": 185.01741037408345,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          141.65685780822102,\n          125.58512019225653,\n          123.64627109905668\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Variacao da Distancia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.360142727039374,\n        \"min\": 68.8028272812163,\n        \"max\": 173.6750323015186,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          122.01229973931444,\n          116.3183506243261,\n          128.26349526812243\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tamanho Percebido\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.50113948855419,\n        \"min\": 70.36857187718223,\n        \"max\": 162.12407924898426,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          138.64201089428266,\n          124.38179947123987,\n          134.95603259777167\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Velocidade de Aproximacao\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.479035308353552,\n        \"min\": 69.46404288311548,\n        \"max\": 180.8282036943887,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          101.55672769915752,\n          157.3411674753117,\n          97.87153931526451\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Frequencia de Deteccao\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.052380369860103,\n        \"min\": 68.96144260255963,\n        \"max\": 162.20225542809175,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          107.34076098881148,\n          119.53312104558564,\n          87.7753721897587\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tipo_obstaculo\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Obstaculo Estatico\",\n          \"Pessoa\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":72}],"source":["data_input_filename = 'simulated_sensor_data.csv'\n","model_output_filename = 'modelo_treinado.h5'\n","X_test_output_filename = 'X_test.npy'\n","y_test_output_filename = 'y_test.npy'\n","\n","# Construir caminhos completos\n","import os\n","data_filepath = os.path.join(project_base_dir, data_input_filename)\n","model_output_path = os.path.join(project_base_dir, model_output_filename)\n","X_test_output_path = os.path.join(project_base_dir, X_test_output_filename)\n","y_test_output_path = os.path.join(project_base_dir, y_test_output_filename)\n","\n","print('data_filepath:', data_filepath)\n","print('model_output_path:', model_output_path)\n","\n","# frame de dados\n","df = pd.read_csv(data_filepath)\n","df.head()"]},{"cell_type":"markdown","id":"91b15a8b","metadata":{"id":"91b15a8b"},"source":["## Pré-processamento dos Dados\n","Selecione as colunas de características, escale os dados e crie as sequências multi-feature."]},{"cell_type":"code","execution_count":73,"id":"84383757","metadata":{"id":"84383757","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747531496945,"user_tz":180,"elapsed":74,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"8fcaaa98-4f16-41f3-9d1d-e5a4c8222ca4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape X: (480, 20, 5)\n","Shape y_cat: (480, 2)\n"]}],"source":["# Configurações do notebook\n","sequence_length = 20  # Ajuste conforme necessário\n","\n","df_features = df[feature_columns].copy()\n","scaler = StandardScaler()\n","df_features_scaled = pd.DataFrame(scaler.fit_transform(df_features), columns=feature_columns)\n","\n","# Salvar scaler se desejar reutilizar depois\n","import joblib\n","scaler_path = os.path.join(project_base_dir, 'scaler.save')\n","joblib.dump(scaler, scaler_path)\n","\n","# Criar sequências (X) e rótulos (y)\n","X_list = []\n","y_list = []\n","\n","# Para séries temporais, janela deslizante\n","for i in range(len(df_features_scaled) - sequence_length):\n","    X_seq = df_features_scaled.iloc[i:i+sequence_length].values\n","    y_seq = df[label_column].iloc[i+sequence_length]\n","    X_list.append(X_seq)\n","    y_list.append(y_seq)\n","\n","X = np.array(X_list)\n","y = np.array(y_list)\n","\n","# Converter rótulos para categórico\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","y_encoded = le.fit_transform(y)\n","y_cat = to_categorical(y_encoded)\n","\n","print('Shape X:', X.shape)\n","print('Shape y_cat:', y_cat.shape)"]},{"cell_type":"markdown","id":"a8398daf","metadata":{"id":"a8398daf"},"source":["## Divisão dos Dados\n","Divida os dados em conjuntos de treino, validação e teste."]},{"cell_type":"code","execution_count":74,"id":"22e29515","metadata":{"id":"22e29515","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747531500464,"user_tz":180,"elapsed":20,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"f755a0db-ac16-4cec-8c01-abe7bd6517f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train: (345, 20, 5) (345, 2)\n","Val: (39, 20, 5) (39, 2)\n","Test: (96, 20, 5) (96, 2)\n"]}],"source":["# Divisão dos dados\n","test_size = 0.2\n","val_size = 0.1\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=test_size, random_state=42, stratify=y_encoded)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size, random_state=42)\n","\n","print('Train:', X_train.shape, y_train.shape)\n","print('Val:', X_val.shape, y_val.shape)\n","print('Test:', X_test.shape, y_test.shape)"]},{"cell_type":"markdown","id":"4bcb0165","metadata":{"id":"4bcb0165"},"source":["## Salvar Dados de Teste\n","Salve os arrays X_test e y_test no diretório base do projeto."]},{"cell_type":"code","execution_count":75,"id":"4d343633","metadata":{"id":"4d343633","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747531502919,"user_tz":180,"elapsed":63,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"41e92e9a-14d3-49dd-d877-8c5d0f7abf41"},"outputs":[{"output_type":"stream","name":"stdout","text":["X_test e y_test salvos.\n"]}],"source":["np.save(X_test_output_path, X_test)\n","np.save(y_test_output_path, y_test)\n","print('X_test e y_test salvos.')"]},{"cell_type":"markdown","id":"a1929a8c","metadata":{"id":"a1929a8c"},"source":["## Construir o Modelo de IA\n","Defina a arquitetura do modelo com entrada compatível com (sequence_length, num_features)."]},{"cell_type":"code","execution_count":76,"id":"42b21571","metadata":{"id":"42b21571","colab":{"base_uri":"https://localhost:8080/","height":262},"executionInfo":{"status":"ok","timestamp":1747531506614,"user_tz":180,"elapsed":81,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"76064b84-f5a2-47f5-db9b-ca75be60a647"},"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_1\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m17,920\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m66\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,920</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,066\u001b[0m (78.38 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,066</span> (78.38 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,066\u001b[0m (78.38 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,066</span> (78.38 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout\n","\n","num_features = len(feature_columns)\n","num_classes = y_cat.shape[1]\n","\n","model = Sequential([\n","    tf.keras.layers.Input(shape=(sequence_length, num_features)),\n","    LSTM(64, return_sequences=False),\n","    Dropout(0.2),\n","    Dense(32, activation='relu'),\n","    Dense(num_classes, activation='softmax')\n","])\n","\n","model.summary()"]},{"cell_type":"markdown","id":"32b2ddb0","metadata":{"id":"32b2ddb0"},"source":["## Compilar o Modelo\n","Compile o modelo com função de perda, otimizador e métricas apropriadas."]},{"cell_type":"code","execution_count":77,"id":"eff498d3","metadata":{"id":"eff498d3","executionInfo":{"status":"ok","timestamp":1747531509333,"user_tz":180,"elapsed":5,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}}},"outputs":[],"source":["model.compile(\n","    loss='categorical_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy']\n",")"]},{"cell_type":"markdown","id":"385b760a","metadata":{"id":"385b760a"},"source":["## Definir Callbacks\n","Configure callbacks como ModelCheckpoint e EarlyStopping."]},{"cell_type":"code","execution_count":78,"id":"95523922","metadata":{"id":"95523922","executionInfo":{"status":"ok","timestamp":1747531511854,"user_tz":180,"elapsed":10,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}}},"outputs":[],"source":["from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","checkpoint = ModelCheckpoint(model_output_path, monitor='val_loss', save_best_only=True, verbose=1)\n","early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","callbacks = [checkpoint, early_stop]"]},{"cell_type":"markdown","id":"c5ef89b6","metadata":{"id":"c5ef89b6"},"source":["## Treinar o Modelo\n","Treine o modelo usando os dados de treino e validação."]},{"cell_type":"code","execution_count":79,"id":"b42ea94d","metadata":{"id":"b42ea94d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747531520790,"user_tz":180,"elapsed":6722,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"2cc0882b-2d66-4a2f-eff7-b8b2f0f7038b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4372 - loss: 0.6899\n","Epoch 1: val_loss improved from inf to 0.51781, saving model to /content/drive/MyDrive/SimClasIotIA/modelo_treinado.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.4508 - loss: 0.6865 - val_accuracy: 0.8974 - val_loss: 0.5178\n","Epoch 2/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8425 - loss: 0.5222\n","Epoch 2: val_loss improved from 0.51781 to 0.36788, saving model to /content/drive/MyDrive/SimClasIotIA/modelo_treinado.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8419 - loss: 0.5192 - val_accuracy: 0.8974 - val_loss: 0.3679\n","Epoch 3/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8173 - loss: 0.3829\n","Epoch 3: val_loss improved from 0.36788 to 0.35111, saving model to /content/drive/MyDrive/SimClasIotIA/modelo_treinado.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8185 - loss: 0.3814 - val_accuracy: 0.8974 - val_loss: 0.3511\n","Epoch 4/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8099 - loss: 0.3706\n","Epoch 4: val_loss did not improve from 0.35111\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8110 - loss: 0.3701 - val_accuracy: 0.8974 - val_loss: 0.3809\n","Epoch 5/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8414 - loss: 0.3354\n","Epoch 5: val_loss did not improve from 0.35111\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8399 - loss: 0.3364 - val_accuracy: 0.8974 - val_loss: 0.3645\n","Epoch 6/50\n","\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7448 - loss: 0.4161\n","Epoch 6: val_loss did not improve from 0.35111\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7564 - loss: 0.4056 - val_accuracy: 0.8974 - val_loss: 0.3911\n","Epoch 7/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8088 - loss: 0.3364\n","Epoch 7: val_loss did not improve from 0.35111\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8103 - loss: 0.3368 - val_accuracy: 0.8974 - val_loss: 0.3688\n","Epoch 8/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8392 - loss: 0.3202\n","Epoch 8: val_loss did not improve from 0.35111\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8372 - loss: 0.3222 - val_accuracy: 0.8974 - val_loss: 0.3790\n","Epoch 9/50\n","\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7992 - loss: 0.3794\n","Epoch 9: val_loss did not improve from 0.35111\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8032 - loss: 0.3726 - val_accuracy: 0.8974 - val_loss: 0.3796\n","Epoch 10/50\n","\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8521 - loss: 0.3130\n","Epoch 10: val_loss did not improve from 0.35111\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8487 - loss: 0.3167 - val_accuracy: 0.8974 - val_loss: 0.3816\n","Epoch 11/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8238 - loss: 0.3488\n","Epoch 11: val_loss did not improve from 0.35111\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8247 - loss: 0.3475 - val_accuracy: 0.8974 - val_loss: 0.3894\n","Epoch 12/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8106 - loss: 0.3615\n","Epoch 12: val_loss did not improve from 0.35111\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8122 - loss: 0.3597 - val_accuracy: 0.8974 - val_loss: 0.3961\n","Epoch 13/50\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8314 - loss: 0.3523\n","Epoch 13: val_loss did not improve from 0.35111\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8305 - loss: 0.3509 - val_accuracy: 0.8974 - val_loss: 0.3774\n"]}],"source":["history = model.fit(\n","    X_train, y_train,\n","    validation_data=(X_val, y_val),\n","    epochs=50,\n","    batch_size=32,\n","    callbacks=callbacks\n",")"]},{"cell_type":"markdown","id":"276778ef","metadata":{"id":"276778ef"},"source":["## Salvar o Modelo Treinado\n","O modelo treinado será salvo no diretório base do projeto como .h5."]},{"cell_type":"code","execution_count":80,"id":"456f5834","metadata":{"id":"456f5834","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747531524683,"user_tz":180,"elapsed":50,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"67b560f1-2d2d-40a7-d7d3-5b8a4fc405a2"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Modelo salvo em: /content/drive/MyDrive/SimClasIotIA/modelo_treinado.h5\n"]}],"source":["# Salvar modelo final (opcional, caso queira garantir)\n","model.save(model_output_path)\n","print(f'Modelo salvo em: {model_output_path}')"]},{"cell_type":"markdown","id":"5cbd0444","metadata":{"id":"5cbd0444"},"source":["# 03_Avaliacao_Resultados.ipynb\n","\n","Este notebook avalia o desempenho do modelo multi-feature treinado, gera métricas, salva resultados numéricos e identifica exemplos de erro para análise posterior.\n","\n","**Passos principais:**\n","- Montar o Google Drive\n","- Carregar configuração, modelo e dados de teste\n","- Avaliar o modelo e calcular métricas\n","- Salvar métricas e exemplos de erro\n","- Visualizar resultados"]},{"cell_type":"markdown","id":"bcee9e5b","metadata":{"id":"bcee9e5b"},"source":["## Instalar Bibliotecas Necessárias\n","\n","Execute a célula abaixo para instalar as bibliotecas necessárias para o notebook."]},{"cell_type":"code","execution_count":81,"id":"cbfa1088","metadata":{"id":"cbfa1088","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747531531200,"user_tz":180,"elapsed":3168,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"0404f4eb-1842-4b93-ea9b-520092240803"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"]}],"source":["!pip install pandas numpy scikit-learn tensorflow matplotlib seaborn"]},{"cell_type":"markdown","id":"78d8c0a2","metadata":{"id":"78d8c0a2"},"source":["## Importar Bibliotecas"]},{"cell_type":"markdown","id":"c2543b55","metadata":{"id":"c2543b55"},"source":["## Carregar Configuração e Caminhos\n","Carregue o arquivo de configuração (project_config.json) e extraia project_base_dir, feature_columns e obstacle_types."]},{"cell_type":"code","execution_count":82,"id":"da9f7d82","metadata":{"id":"da9f7d82","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747531542843,"user_tz":180,"elapsed":38,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"a3cce3a9-07e0-4de2-c355-62b022894b27"},"outputs":[{"output_type":"stream","name":"stdout","text":["project_base_dir: /content/drive/MyDrive/SimClasIotIA/\n","feature_columns: ['Distancia', 'Variacao da Distancia', 'Tamanho Percebido', 'Velocidade de Aproximacao', 'Frequencia de Deteccao']\n","obstacle_types: ['Pessoa', 'Obstaculo Estatico', 'Obstaculos pequenos e medios']\n"]}],"source":["# Defina o caminho do arquivo de configuração\n","config_path = '/content/drive/MyDrive/SimClasIotIA/project_config.json'\n","\n","with open(config_path, 'r') as f:\n","    config = json.load(f)\n","\n","project_base_dir = config['project_base_dir']\n","feature_columns = config['feature_columns']\n","obstacle_types = config['obstacle_types']\n","print('project_base_dir:', project_base_dir)\n","print('feature_columns:', feature_columns)\n","print('obstacle_types:', obstacle_types)"]},{"cell_type":"markdown","id":"603385c9","metadata":{"id":"603385c9"},"source":["## Definir Nomes de Arquivos\n","Defina os nomes dos arquivos relativos para modelo, dados de teste, métricas e erros."]},{"cell_type":"code","execution_count":83,"id":"33a4a121","metadata":{"id":"33a4a121","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747531546364,"user_tz":180,"elapsed":26,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"fc2121df-7513-4947-aa3d-211b0afc383b"},"outputs":[{"output_type":"stream","name":"stdout","text":["model_output_path: /content/drive/MyDrive/SimClasIotIA/modelo_treinado.h5\n","X_test_output_path: /content/drive/MyDrive/SimClasIotIA/X_test.npy\n","y_test_output_path: /content/drive/MyDrive/SimClasIotIA/y_test.npy\n"]}],"source":["model_output_filename = 'modelo_treinado.h5'\n","X_test_output_filename = 'X_test.npy'\n","y_test_output_filename = 'y_test.npy'\n","metrics_output_filename = 'metrics.json'\n","errors_output_filename = 'errors.csv'\n","\n","data_input_filename = 'simulated_sensor_data.csv'  # Para análise de features, se necessário\n","\n","# Construir caminhos completos\n","model_output_path = os.path.join(project_base_dir, model_output_filename)\n","X_test_output_path = os.path.join(project_base_dir, X_test_output_filename)\n","y_test_output_path = os.path.join(project_base_dir, y_test_output_filename)\n","metrics_output_path = os.path.join(project_base_dir, metrics_output_filename)\n","errors_output_path = os.path.join(project_base_dir, errors_output_filename)\n","data_filepath = os.path.join(project_base_dir, data_input_filename)\n","\n","print('model_output_path:', model_output_path)\n","print('X_test_output_path:', X_test_output_path)\n","print('y_test_output_path:', y_test_output_path)"]},{"cell_type":"markdown","id":"e2759115","metadata":{"id":"e2759115"},"source":["## Carregar o Modelo Treinado e os Dados de Teste\n","Carregue o modelo treinado (.h5) e os arrays X_test, y_test."]},{"cell_type":"code","execution_count":84,"id":"81af1e38","metadata":{"id":"81af1e38","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747531551348,"user_tz":180,"elapsed":341,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"89ae3def-e822-4124-95de-1d5f085a3a1a"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["X_test shape: (96, 20, 5)\n","y_test shape: (96, 2)\n"]}],"source":["# Carregar modelo treinado\n","model = tf.keras.models.load_model(model_output_path)\n","\n","# Carregar dados de teste\n","X_test = np.load(X_test_output_path)\n","y_test = np.load(y_test_output_path)\n","\n","print('X_test shape:', X_test.shape)\n","print('y_test shape:', y_test.shape)"]},{"cell_type":"markdown","id":"65b58d80","metadata":{"id":"65b58d80"},"source":["## Obter Predições do Modelo\n","Obtenha as predições do modelo para o conjunto de teste."]},{"cell_type":"code","execution_count":85,"id":"9c7d4ac6","metadata":{"id":"9c7d4ac6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747531554469,"user_tz":180,"elapsed":366,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"f6c59465-44ff-46f0-8055-5f8014cd5d0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step \n"]}],"source":["y_pred_probs = model.predict(X_test)\n","y_pred = np.argmax(y_pred_probs, axis=1)\n","y_true = np.argmax(y_test, axis=1)  # y_test está one-hot"]},{"cell_type":"markdown","id":"1f755ad0","metadata":{"id":"1f755ad0"},"source":["## Calcular Métricas\n","Calcule métricas como accuracy, classification_report e confusion_matrix."]},{"cell_type":"code","execution_count":86,"id":"178d651f","metadata":{"id":"178d651f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747531556821,"user_tz":180,"elapsed":168,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"3577155e-2d16-4adf-de8d-a96a6d2f7230"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n","Accuracy: 0.875\n","Classification Report:\n","{\n","  \"Pessoa\": {\n","    \"precision\": 0.8125,\n","    \"recall\": 0.9285714285714286,\n","    \"f1-score\": 0.8666666666666667,\n","    \"support\": 42.0\n","  },\n","  \"Obstaculo Estatico\": {\n","    \"precision\": 0.9375,\n","    \"recall\": 0.8333333333333334,\n","    \"f1-score\": 0.8823529411764706,\n","    \"support\": 54.0\n","  },\n","  \"Obstaculos pequenos e medios\": {\n","    \"precision\": 0.0,\n","    \"recall\": 0.0,\n","    \"f1-score\": 0.0,\n","    \"support\": 0.0\n","  },\n","  \"accuracy\": 0.875,\n","  \"macro avg\": {\n","    \"precision\": 0.5833333333333334,\n","    \"recall\": 0.5873015873015873,\n","    \"f1-score\": 0.5830065359477125,\n","    \"support\": 96.0\n","  },\n","  \"weighted avg\": {\n","    \"precision\": 0.8828125,\n","    \"recall\": 0.875,\n","    \"f1-score\": 0.8754901960784314,\n","    \"support\": 96.0\n","  }\n","}\n","Número de erros: 12\n","Métricas salvas em: /content/drive/MyDrive/SimClasIotIA/metrics.json\n","Erros salvos em: /content/drive/MyDrive/SimClasIotIA/errors.csv\n"]}],"source":["# Carregar o LabelEncoder\n","import joblib\n","\n","scaler_path = os.path.join(project_base_dir, 'scaler.save') # This was defined in the training notebook\n","le_path = os.path.join(project_base_dir, 'label_encoder.save') # We need to save the label encoder in the training notebook\n","\n","label_indices = list(range(len(obstacle_types)))\n","\n","# Obtain predictions and true labels (same as before)\n","y_pred_probs = model.predict(X_test)\n","y_pred = np.argmax(y_pred_probs, axis=1)\n","y_true = np.argmax(y_test, axis=1)  # y_test está one-hot\n","\n","# Calculate metrics, explicitly providing labels to classification_report\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","import json\n","\n","acc = accuracy_score(y_true, y_pred)\n","\n","# Use the inferred or loaded label indices\n","report = classification_report(y_true, y_pred,\n","                               target_names=obstacle_types,\n","                               labels=label_indices, # Explicitly provide all possible labels\n","                               output_dict=True,\n","                               zero_division=0) # Handle cases with no samples from a class\n","\n","cm = confusion_matrix(y_true, y_pred, labels=label_indices) # Also provide labels for confusion matrix\n","\n","metrics = {\n","    'accuracy': acc,\n","    'classification_report': report,\n","    'confusion_matrix': cm.tolist(),\n","    'obstacle_types': obstacle_types # Store the original obstacle types\n","}\n","\n","print('Accuracy:', acc)\n","print('Classification Report:')\n","print(json.dumps(report, indent=2, ensure_ascii=False))\n","\n","# Identify and collect data for error examples (same as before)\n","# Encontrar índices de erro\n","error_indices = np.where(y_true != y_pred)[0]\n","\n","# Montar DataFrame de erros\n","errors_df = pd.DataFrame({\n","    'error_index': error_indices,\n","    'true_label_id': y_true[error_indices],\n","    'pred_label_id': y_pred[error_indices],\n","    'true_label_str': [obstacle_types[i] for i in y_true[error_indices]],\n","    'pred_label_str': [obstacle_types[i] for i in y_pred[error_indices]]\n","})\n","\n","print(f'Número de erros: {len(errors_df)}')\n","# errors_df.head() # Commenting out display in code block\n","\n","# Save results (same as before)\n","metrics_output_filename = 'metrics.json'\n","errors_output_filename = 'errors.csv'\n","metrics_output_path = os.path.join(project_base_dir, metrics_output_filename)\n","errors_output_path = os.path.join(project_base_dir, errors_output_filename)\n","\n","# Salvar métricas\n","with open(metrics_output_path, 'w') as f:\n","    json.dump(metrics, f, indent=2, ensure_ascii=False)\n","print(f'Métricas salvas em: {metrics_output_path}')\n","\n","# Salvar erros\n","errors_df.to_csv(errors_output_path, index=False)\n","print(f'Erros salvos em: {errors_output_path}')\n","\n","\n","\n","\n"]},{"cell_type":"markdown","id":"4ff1a8c5","metadata":{"id":"4ff1a8c5"},"source":["## Identificar e Coletar Dados para Exemplos de Erro\n","Salve os índices dos erros, rótulos verdadeiros e preditos, e referências para análise posterior."]},{"cell_type":"code","execution_count":87,"id":"34dc1e98","metadata":{"id":"34dc1e98","colab":{"base_uri":"https://localhost:8080/","height":223},"executionInfo":{"status":"ok","timestamp":1747531563387,"user_tz":180,"elapsed":48,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"b3aaac6f-ab23-4bff-f91d-8b3dcb559cb5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Número de erros: 12\n"]},{"output_type":"execute_result","data":{"text/plain":["   error_index  true_label_id  pred_label_id      true_label_str  \\\n","0           23              1              0  Obstaculo Estatico   \n","1           24              1              0  Obstaculo Estatico   \n","2           42              0              1              Pessoa   \n","3           43              1              0  Obstaculo Estatico   \n","4           56              1              0  Obstaculo Estatico   \n","\n","       pred_label_str  \n","0              Pessoa  \n","1              Pessoa  \n","2  Obstaculo Estatico  \n","3              Pessoa  \n","4              Pessoa  "],"text/html":["\n","  <div id=\"df-94e61359-9a64-4bd2-b828-bed9441284bc\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>error_index</th>\n","      <th>true_label_id</th>\n","      <th>pred_label_id</th>\n","      <th>true_label_str</th>\n","      <th>pred_label_str</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>23</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Obstaculo Estatico</td>\n","      <td>Pessoa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>24</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Obstaculo Estatico</td>\n","      <td>Pessoa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>42</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>Pessoa</td>\n","      <td>Obstaculo Estatico</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>43</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Obstaculo Estatico</td>\n","      <td>Pessoa</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>56</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Obstaculo Estatico</td>\n","      <td>Pessoa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94e61359-9a64-4bd2-b828-bed9441284bc')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-94e61359-9a64-4bd2-b828-bed9441284bc button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-94e61359-9a64-4bd2-b828-bed9441284bc');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-c98e34df-c55c-48db-94e2-4f9db55be652\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c98e34df-c55c-48db-94e2-4f9db55be652')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-c98e34df-c55c-48db-94e2-4f9db55be652 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"errors_df","summary":"{\n  \"name\": \"errors_df\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"error_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25,\n        \"min\": 23,\n        \"max\": 95,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          92,\n          90,\n          23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"true_label_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_label_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"true_label_str\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Pessoa\",\n          \"Obstaculo Estatico\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_label_str\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Obstaculo Estatico\",\n          \"Pessoa\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":87}],"source":["# Encontrar índices de erro\n","error_indices = np.where(y_true != y_pred)[0]\n","\n","# Montar DataFrame de erros\n","errors_df = pd.DataFrame({\n","    'error_index': error_indices,\n","    'true_label_id': y_true[error_indices],\n","    'pred_label_id': y_pred[error_indices],\n","    'true_label_str': [obstacle_types[i] for i in y_true[error_indices]],\n","    'pred_label_str': [obstacle_types[i] for i in y_pred[error_indices]]\n","})\n","\n","print(f'Número de erros: {len(errors_df)}')\n","errors_df.head()"]},{"cell_type":"markdown","id":"0dc09830","metadata":{"id":"0dc09830"},"source":["## Salvar Resultados\n","Salve as métricas como JSON e os erros como CSV."]},{"cell_type":"code","execution_count":88,"id":"e447b674","metadata":{"id":"e447b674","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747531566641,"user_tz":180,"elapsed":34,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"0433361d-58b5-406c-be5e-bd54ea68fc90"},"outputs":[{"output_type":"stream","name":"stdout","text":["Métricas salvas em: /content/drive/MyDrive/SimClasIotIA/metrics.json\n","Erros salvos em: /content/drive/MyDrive/SimClasIotIA/errors.csv\n"]}],"source":["# Salvar métricas\n","with open(metrics_output_path, 'w') as f:\n","    json.dump(metrics, f, indent=2, ensure_ascii=False)\n","print(f'Métricas salvas em: {metrics_output_path}')\n","\n","# Salvar erros\n","errors_df.to_csv(errors_output_path, index=False)\n","print(f'Erros salvos em: {errors_output_path}')"]},{"cell_type":"markdown","id":"3c0ea8ef","metadata":{"id":"3c0ea8ef"},"source":["## Visualizar Resultados\n","Visualize a matriz de confusão e a distribuição dos erros."]},{"cell_type":"code","execution_count":89,"id":"bc5a3fb2","metadata":{"id":"bc5a3fb2","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1747531569599,"user_tz":180,"elapsed":387,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"4a10d839-cf29-465e-a17c-1f450877f9a6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 800x600 with 2 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAA0sAAALuCAYAAAB/4o2fAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAicZJREFUeJzs3Xd4FGX3//HPJpBeSAIkBBJqIIQOKoQmQpAmgiBIUUIRUEA6Ij5AAGkiXYooGFApShNB6VURkBZ6b6GE3gMESPb3Bz/265oAu5Gwift+PddcV/ae2Zkz+6yak3PfZwxGo9EoAAAAAIAZB1sHAAAAAADpEckSAAAAAKSAZAkAAAAAUkCyBAAAAAApIFkCAAAAgBSQLAEAAABACkiWAAAAACAFJEsAAAAAkAKSJQAAAABIAckSAABWGjBggAwGQ5pew2AwaMCAAWl6jRftiy++UL58+eTo6KiSJUumyTV69uwpT09PRUZG6urVqwoLC1NMTEyaXAvAfx/JEgAg3Zo+fboMBoMMBoP++OOPZPuNRqOCgoJkMBj0xhtvpOoaQ4cO1c8///wvI80YEhMTFR0drSpVqsjX11fOzs7KkyePWrVqpW3btqXptVesWKGPP/5YFSpUUHR0tIYOHfrcr3H79m1NnjxZgwYN0r59+5Q1a1Z5eHioePHiz/1aAOwDyRIAIN1zcXHRrFmzko2vX79eZ86ckbOzc6rPnZpkqW/fvrp7926qr2kLd+/e1RtvvKHWrVvLaDTq008/1eTJk9WiRQtt2rRJr7zyis6cOZNm11+zZo0cHBw0bdo0tWjRQrVr137u13BxcdH+/fvVrVs3bdu2TWfOnNHmzZvl4MCvOwBSJ5OtAwAA4Flq166tuXPnavz48cqU6f/+0zVr1iyVKVNGly9ffiFxxMfHy93dXZkyZTKLIyPo1auXli1bpjFjxqhr165m+6KiojRmzJg0vf7Fixfl6uoqJyenNLtGpkyZlDt3btPrwMDANLsWAPvAn1oAAOle06ZNdeXKFa1cudI0dv/+fc2bN0/NmjVL8T0jR45U+fLl5efnJ1dXV5UpU0bz5s0zO8ZgMCg+Pl4zZswwTfdr2bKlpP9bl7R//341a9ZMPj4+qlixotm+x1q2bGl6/z+3Z607SkhIULdu3ZQtWzZ5enrqzTfffGKF5+zZs2rdurX8/f3l7OysIkWK6Ntvv33Wx6czZ85oypQpql69erJESZIcHR3Vs2dP5cqVyzS2c+dO1apVS15eXvLw8FC1atW0efNms/c9nia5ceNGde/eXdmyZZO7u7veeustXbp0yXScwWBQdHS04uPjTZ/L9OnTdfLkSdPP//TPz+7WrVvq2rWr8uTJI2dnZ2XPnl3Vq1fXjh07TMesW7dOb7/9toKDg+Xs7KygoCB169YtxSrgmjVrVKlSJbm7uytLliyqV6+eDhw48MzPEoB9yVh/FgMA2KU8efIoPDxcs2fPVq1atSRJS5cu1Y0bN9SkSRONHz8+2XvGjRunN998U82bN9f9+/c1Z84cNWrUSEuWLFGdOnUkSd9//73ef/99vfLKK2rXrp0kKX/+/GbnadSokUJCQjR06FAZjcYU42vfvr0iIiLMxpYtW6aZM2cqe/bsT723999/Xz/88IOaNWum8uXLa82aNab4/u7ChQsqV66cDAaDOnXqpGzZsmnp0qVq06aNbt68mWIS9NjSpUv18OFDvffee0+N5bF9+/apUqVK8vLy0scff6zMmTNrypQpqlKlitavX6+yZcuaHf/RRx/Jx8dHUVFROnnypMaOHatOnTrpxx9/lPToc/7666/1119/aerUqZKk8uXLWxTLYx988IHmzZunTp06KSwsTFeuXNEff/yhAwcOqHTp0pKkn376SXfv3lWHDh3k6+urv/76S19++aXOnDmjuXPnms61atUq1apVS/ny5dOAAQN09+5dffnll6pQoYJ27NihPHnyWBUbgP8wIwAA6VR0dLRRknHr1q3GCRMmGD09PY137twxGo1GY6NGjYyvvfaa0Wg0GnPnzm2sU6eO2XsfH/fY/fv3jUWLFjVWrVrVbNzd3d0YGRmZ7NpRUVFGScamTZs+cd+THDlyxOjt7W2sXr268eHDh088LiYmxijJ2KFDB7PxZs2aGSUZo6KiTGNt2rQx5siRw3j58mWzY5s0aWL09vZOdr9/161bN6Mk486dO594zN/Vr1/f6OTkZDx27Jhp7Ny5c0ZPT09j5cqVTWOP//+JiIgwJiUlmV3P0dHReP36ddNYZGSk0d3d3ew6J06cMEoyRkdHJ4vhn/fv7e1t7Nix41Pjjo+PTzY2bNgwo8FgMJ46dco0VrJkSWP27NmNV65cMY3t2rXL6ODgYGzRosVTrwHAvjANDwCQITRu3Fh3797VkiVLdOvWLS1ZsuSJU/AkydXV1fTztWvXdOPGDVWqVMls2pYlPvjgA6uOj4+P11tvvSUfHx/Nnj1bjo6OTzz2t99+kyR17tzZbPyfVSKj0aj58+erbt26MhqNunz5smmrUaOGbty48dT7unnzpiTJ09PzmfEnJiZqxYoVql+/vvLly2caz5Ejh5o1a6Y//vjDdL7H2rVrZzYtsVKlSkpMTNSpU6eeeT1LZcmSRVu2bNG5c+eeeIybm5vp5/j4eF2+fFnly5eX0WjUzp07JUlxcXGKiYlRy5Yt5evrazq+ePHiql69uun/EwCQmIYHAMggsmXLpoiICM2aNUt37txRYmKi3n777Scev2TJEg0ePFgxMTFKSEgwjVv7fKS8efNadXzbtm117Ngx/fnnn/Lz83vqsadOnZKDg0OyqX+FChUye33p0iVdv35dX3/9tb7++usUz3Xx4sUnXsfLy0vSo3U/z3Lp0iXduXMnWQySVLhwYSUlJen06dMqUqSIaTw4ONjsOB8fH0mPktTnZcSIEYqMjFRQUJDKlCmj2rVrq0WLFmYJXWxsrPr3769ffvkl2bVv3LghSaYE7kn3t3z5clMjDwAgWQIAZBjNmjVT27Ztdf78edWqVUtZsmRJ8bjff/9db775pipXrqxJkyYpR44cypw5s6Kjo1NsQf40f69QPcu4ceM0e/Zs/fDDD8/1oatJSUmSpHfffVeRkZEpHvO0ZwmFhoZKkvbs2ZMmD4N9UvXM+IQ1Xo89KXFNTExMNta4cWNVqlRJCxcu1IoVK/TFF1/o888/14IFC1SrVi0lJiaqevXqunr1qnr37q3Q0FC5u7vr7NmzatmypekzBABrkCwBADKMt956S+3bt9fmzZtNzQNSMn/+fLm4uGj58uVmz2CKjo5Odqy1laYn+f3339WzZ0917dpVzZs3t+g9uXPnVlJSko4dO2ZW6Th06JDZcY875SUmJiZrJGGJWrVqydHRUT/88MMzmzxky5ZNbm5uyWKQpIMHD8rBwUFBQUFWx5CSxxWo69evm40/afpejhw51KFDB3Xo0EEXL15U6dKlNWTIENWqVUt79uzR4cOHNWPGDLVo0cL0nr93UJRkai3+pPvLmjUrVSUAJqxZAgBkGB4eHpo8ebIGDBigunXrPvE4R0dHGQwGswrFyZMnU3z4rLu7e7Jf1q0VFxenxo0bq2LFivriiy8sft/jzn7/7OY3duxYs9eOjo5q2LCh5s+fr7179yY7z9/bdKckKChIbdu21YoVK/Tll18m25+UlKRRo0bpzJkzcnR01Ouvv65Fixbp5MmTpmMuXLigWbNmqWLFiqZpff+Wl5eXsmbNqg0bNpiNT5o0yex1YmKiaRrdY9mzZ1dgYKBpiuXj6tbfq1lGo1Hjxo0ze1+OHDlUsmRJzZgxw+z/971792rFihVp8rBcABkXlSUAQIbypGlof1enTh2NHj1aNWvWVLNmzXTx4kVNnDhRBQoU0O7du82OLVOmjFatWqXRo0crMDBQefPmTdYa+1k6d+6sS5cu6eOPP9acOXPM9hUvXvyJU+RKliyppk2batKkSbpx44bKly+v1atX6+jRo8mOHT58uNauXauyZcuqbdu2CgsL09WrV7Vjxw6tWrVKV69efWqMo0aN0rFjx9S5c2ctWLBAb7zxhnx8fBQbG6u5c+fq4MGDatKkiSRp8ODBWrlypSpWrKgOHTooU6ZMmjJlihISEjRixAirPptnef/99zV8+HC9//77eumll7RhwwYdPnzY7Jhbt24pV65cevvtt1WiRAl5eHho1apV2rp1q0aNGiXp0VTD/Pnzq2fPnjp79qy8vLw0f/78FNdNffHFF6pVq5bCw8PVpk0bU+twb2/vZz4XC4CdsWUrPgAAnubvrcOfJqXW4dOmTTOGhIQYnZ2djaGhocbo6OgUW34fPHjQWLlyZaOrq6tRkqmN+ONjL126lOx6/zzPq6++apSU4vb39tcpuXv3rrFz585GPz8/o7u7u7Fu3brG06dPp/jeCxcuGDt27GgMCgoyZs6c2RgQEGCsVq2a8euvv37qNR57+PChcerUqcZKlSoZvb29jZkzZzbmzp3b2KpVq2RtxXfs2GGsUaOG0cPDw+jm5mZ87bXXjH/++afZMU/6/2ft2rVGSca1a9eaxlJqHW40Pmrx3qZNG6O3t7fR09PT2LhxY+PFixfN7j8hIcHYq1cvY4kSJYyenp5Gd3d3Y4kSJYyTJk0yO9f+/fuNERERRg8PD2PWrFmNbdu2Ne7atSvF9uSrVq0yVqhQwejq6mr08vIy1q1b17h//36LPkcA9sNgND5j9SUAAAAA2CHWLAEAAABACkiWAAAAACAFJEsAAAAAkAKSJQAAAAAZ2vDhw2UwGNS1a1fTWJUqVWQwGMy2Dz74wKrz0jocAAAAQIa1detWTZkyJcXHNLRt21aDBg0yvXZzc7Pq3FSWAAAAAGRIt2/fVvPmzfXNN9/Ix8cn2X43NzcFBASYNmsfqk2yBAAAAMDmEhISdPPmTbMtISHhqe/p2LGj6tSpo4iIiBT3z5w5U1mzZlXRokXVp08f3blzx6qYmIYH2DH3t6NtHQJg5mT0e7YOAUjG05Vfl5C+uNjwK+laqlOanbt3vawaOHCg2VhUVJQGDBiQ4vFz5szRjh07tHXr1hT3N2vWTLlz51ZgYKB2796t3r1769ChQ1qwYIHFMfFPPwAAAACb69Onj7p372425uzsnOKxp0+fVpcuXbRy5Uq5uLikeEy7du1MPxcrVkw5cuRQtWrVdOzYMeXPn9+imEiWAAAAAFjGkHareJydnZ+YHP3T9u3bdfHiRZUuXdo0lpiYqA0bNmjChAlKSEiQo6Oj2XvKli0rSTp69CjJEgAAAID/pmrVqmnPnj1mY61atVJoaKh69+6dLFGSpJiYGElSjhw5LL4OyRIAAAAAyxgMto5AkuTp6amiRYuajbm7u8vPz09FixbVsWPHNGvWLNWuXVt+fn7avXu3unXrpsqVK6fYYvxJSJYAAAAAWCYNp+E9T05OTlq1apXGjh2r+Ph4BQUFqWHDhurbt69V5yFZAgAAAJDhrVu3zvRzUFCQ1q9f/6/PSbIEAAAAwDLpZBrei5Ix6mgAAAAA8IJRWQIAAABgmQyyZul5sa+7BQAAAAALUVkCAAAAYBnWLAEAAAAAqCwBAAAAsIydrVkiWQIAAABgGabhAQAAAACoLAEAAACwjJ1Nw7OvuwUAAAAAC1FZAgAAAGAZ1iwBAAAAAKgsAQAAALAMa5YAAAAAAFSWAAAAAFjGztYskSwBAAAAsAzT8AAAAAAAVJYAAAAAWIbKEgAAAACAyhIAAAAAyzjYV4MHKksAAAAAkAIqSwAAAAAsw5olAAAAAACVJQAAAACW4aG0AAAAAJACpuEBAAAAAKgsAQAAALCMnU3Do7IEAAAAACmgsgQAAADAMqxZAgAAAABQWQIAAABgGdYsAQAAAACoLAEAAACwjJ2tWSJZAgAAAGAZpuEBAAAAAKgsAQAAALCMnU3Ds6+7BQAAAAALUVkCAAAAYBnWLAEAAAAASJYAAAAAWMbgkHbbvzB8+HAZDAZ17drVNHbv3j117NhRfn5+8vDwUMOGDXXhwgWrzkuyBAAAACDD2rp1q6ZMmaLixYubjXfr1k2LFy/W3LlztX79ep07d04NGjSw6twkSwAAAAAsk84qS7dv31bz5s31zTffyMfHxzR+48YNTZs2TaNHj1bVqlVVpkwZRUdH688//9TmzZstPj/JEgAAAACbS0hI0M2bN822hISEp76nY8eOqlOnjiIiIszGt2/frgcPHpiNh4aGKjg4WJs2bbI4JpIlAAAAAJYxGNJsGzZsmLy9vc22YcOGPTGUOXPmaMeOHSkec/78eTk5OSlLlixm4/7+/jp//rzFt0vrcAAAAACWScOH0vbp00fdu3c3G3N2dk7x2NOnT6tLly5auXKlXFxc0iwmkiUAAAAANufs7PzE5Oiftm/frosXL6p06dKmscTERG3YsEETJkzQ8uXLdf/+fV2/ft2sunThwgUFBARYHBPJEgAAAADLpJOH0larVk179uwxG2vVqpVCQ0PVu3dvBQUFKXPmzFq9erUaNmwoSTp06JBiY2MVHh5u8XVIlgAAAABkKJ6enipatKjZmLu7u/z8/Ezjbdq0Uffu3eXr6ysvLy999NFHCg8PV7ly5Sy+DskSAAAAAMuk4Zql523MmDFycHBQw4YNlZCQoBo1amjSpElWncNgNBqNaRQfgHTO/e1oW4cAmDkZ/Z6tQwCS8XTlb8tIX1xs+JV0fWtqmp377sL30+zcqcU//QAAAAAsk07WLL0oGaeOBgAAAAAvEJUlAAAAABYx2FlliWQJAAAAgEXsLVliGh4AAAAApIDKEgAAAADL2FdhicoSAAAAAKSEyhIAAAAAi7BmCQAAAABAZQkAAACAZagsAQAAAACoLAEAAACwjL1VlkiWAAAAAFjE3pIlpuEBT9GyZUsZDAYZDAY5OTmpQIECGjRokB4+fGjr0PCCvf96IW0ZVU9x3zVX3HfNtWZIHb1eKqdpf15/T83uVVUnpzVV3HfN9V33Ksru7WLDiGGPFs6bo8gmb+n1V1/R66++ovatmmnTxt9tHRagObNmqlb1qnq5VDE1b9JIe3bvtnVIgEVIloBnqFmzpuLi4nTkyBH16NFDAwYM0BdffGHrsPCCnb1yR/1/2K6KHy9Wpd6LtX5vnH78uJoK58oiN+dM+qXf6zJKqjNwmSL6/ianTA6a+0mE7OwPcLCxbNn99UGnbpr2/VxN/e4nlX6prPr06KTjx47aOjTYsWVLf9PIEcPUvkNHzZm7UIUKherD9m105coVW4eG1DCk4ZYOkSwBz+Ds7KyAgADlzp1bH374oSIiIvTLL78oISFBPXv2VM6cOeXu7q6yZctq3bp1pvedOnVKdevWlY+Pj9zd3VWkSBH99ttvkqRr166pefPmypYtm1xdXRUSEqLo6GjTe/fs2aOqVavK1dVVfn5+ateunW7fvm3av3XrVlWvXl1Zs2aVt7e3Xn31Ve3YseOFfSb2aOn201q+84yOnb+po3E3NXD2Dt2+91AvF8ym8NDsyp3NQ+0n/K59sde0L/aa2k34XaXzZ1WVojlsHTrsSMXKrym8YmUFBedWcO48at+xi1zd3LR/zy5bhwY79v2MaDV4u7Hqv9VQ+QsUUN+ogXJxcdHPC+bbOjTgmUiWACu5urrq/v376tSpkzZt2qQ5c+Zo9+7datSokWrWrKkjR45Ikjp27KiEhARt2LBBe/bs0eeffy4PDw9JUr9+/bR//34tXbpUBw4c0OTJk5U1a1ZJUnx8vGrUqCEfHx9t3bpVc+fO1apVq9SpUydTDLdu3VJkZKT++OMPbd68WSEhIapdu7Zu3br14j8QO+TgYNDbFfLK3SWT/jp8UU6ZHGWUlPAg0XTMvfuJSjIaFV7Y33aBwq4lJiZq1fLfdO/uXRUpXsLW4cBOPbh/Xwf271O58PKmMQcHB5UrV167d+20YWRIrcfLE9JiS49o8ABYyGg0avXq1Vq+fLmaNm2q6OhoxcbGKjAwUJLUs2dPLVu2TNHR0Ro6dKhiY2PVsGFDFStWTJKUL18+07liY2NVqlQpvfTSS5KkPHnymPbNmjVL9+7d03fffSd3d3dJ0oQJE1S3bl19/vnn8vf3V9WqVc1i+/rrr5UlSxatX79eb7zxRlp+DHatSLCP1gypIxcnR92+90BNR6zRwTM3dPnmPcXfe6jB776kqFnbZTAYNKh5GWVydFBAFjdbhw07c+zoYX3Qqpnu378vV1c3Df1ivPLmK2DrsGCnrl2/psTERPn5+ZmN+/n56cSJ4zaKCrAcyRLwDEuWLJGHh4cePHigpKQkNWvWTG+//bamT5+uggULmh2bkJBg+g9C586d9eGHH2rFihWKiIhQw4YNVbx4cUnShx9+qIYNG2rHjh16/fXXVb9+fZUv/+ivbgcOHFCJEiVMiZIkVahQQUlJSTp06JD8/f114cIF9e3bV+vWrdPFixeVmJioO3fuKDY29on3kZCQoISEBLMxY+IDGRwzP5fPyR4cPndD4b0WycvNSW+Vy6MpnSqpZtRvOnjmht4bvVZj24brw9phSjIaNfeP49p57LKSjEZbhw07E5w7j6Jnzdft27e1bvUKDRnwqb78ejoJE4DnIr1WgNIK0/CAZ3jttdcUExOjI0eO6O7du5oxY4Zu374tR0dHbd++XTExMabtwIEDGjdunCTp/fff1/Hjx/Xee+9pz549eumll/Tll19KkmrVqqVTp06pW7duOnfunKpVq6aePXtaHFNkZKRiYmI0btw4/fnnn4qJiZGfn5/u37//xPcMGzZM3t7eZtuDQ7/+uw/Hzjx4mKTj528p5vgVRc3arr2nrqpD7SKSpNW7zqlYp/nK02a2glvN1vtf/q5AXzedvMDUSLxYmTM7KVdQboUWLqIPOnVT/oKFNHf2D7YOC3bKJ4uPHB0dkzVzuHLlimn6OZCekSwBz+Du7q4CBQooODhYmTI9KsaWKlVKiYmJunjxogoUKGC2BQQEmN4bFBSkDz74QAsWLFCPHj30zTffmPZly5ZNkZGR+uGHHzR27Fh9/fXXkqTChQtr165dio+PNx27ceNGOTg4qFChQqbXnTt3Vu3atVWkSBE5Ozvr8uXLT72PPn366MaNG2Zb5kJ1ntvnZI8cDAY5Zzb/1+iVWwm6cee+Xi2aQ9m8XfXrtidX+4AXwZiUpAcPnvyHFCAtZXZyUuGwItqyeZNpLCkpSVu2bFLxEqVsGBlSizVLAJ6pYMGCat68uVq0aKFRo0apVKlSunTpklavXq3ixYurTp066tq1q2rVqqWCBQvq2rVrWrt2rQoXLixJ6t+/v8qUKaMiRYooISFBS5YsMe1r3ry5oqKiFBkZqQEDBujSpUv66KOP9N5778nf/1GzgJCQEH3//fd66aWXdPPmTfXq1Uuurq5PjdnZ2VnOzs5mY0zBs9zAZmW0YucZnb4cL0/XzGpcMZ8qFQlQvcErJEnvvVbAtH6pbMFsGtG6rCYs2acj527aOHLYk68mjFG58pXkH5BDd+7Ea+WyX7Vz+1aN/vJrW4cGO/ZeZCv1+7S3ihQpqqLFiuuH72fo7t27qv9WA1uHhlRIr0lNWiFZAlIpOjpagwcPVo8ePXT27FllzZpV5cqVMzVYSExMVMeOHXXmzBl5eXmpZs2aGjNmjCTJyclJffr00cmTJ+Xq6qpKlSppzpw5kiQ3NzctX75cXbp00csvvyw3Nzc1bNhQo0ePNl172rRpateunUqXLq2goCANHTrUqml8sF42bxd981ElBfi46ead+9p76prqDV6hNbvPSZJCAr01sFkZ+Xg469Sl2/pi/m59uWSfjaOGvbl29aoGR/XRlcuX5O7hqfwhBTX6y6/1crnyz34zkEZq1qqta1evatKE8bp8+ZIKhRbWpClT5cc0PGQABqOR1ceAvXJ/O/rZBwEv0Mno92wdApCMpyt/W0b64mLDr6Rf5Ow0O/eVGU3T7NypxZolAAAAAEgBfyoBAAAAYBF7W7NEZQkAAAAAUkBlCQAAAIBFqCwBAAAAAKgsAQAAALCMvVWWSJYAAAAAWMa+ciWm4QEAAABASqgsAQAAALCIvU3Do7IEAAAAACmgsgQAAADAIlSWAAAAAABUlgAAAABYhsoSAAAAAIDKEgAAAADL2FtliWQJAAAAgGXsK1diGh4AAACAjGXy5MkqXry4vLy85OXlpfDwcC1dutS0v0qVKjIYDGbbBx98YPV1qCwBAAAAsEh6mYaXK1cuDR8+XCEhITIajZoxY4bq1aunnTt3qkiRIpKktm3batCgQab3uLm5WX0dkiUAAAAAGUrdunXNXg8ZMkSTJ0/W5s2bTcmSm5ubAgIC/tV1mIYHAAAAwCL/nNr2PLfUSkxM1Jw5cxQfH6/w8HDT+MyZM5U1a1YVLVpUffr00Z07d6w+N5UlAAAAADaXkJCghIQEszFnZ2c5OzunePyePXsUHh6ue/fuycPDQwsXLlRYWJgkqVmzZsqdO7cCAwO1e/du9e7dW4cOHdKCBQusiolkCQAAAIBF0nLN0rBhwzRw4ECzsaioKA0YMCDF4wsVKqSYmBjduHFD8+bNU2RkpNavX6+wsDC1a9fOdFyxYsWUI0cOVatWTceOHVP+/PktjslgNBqNqbobABme+9vRtg4BMHMy+j1bhwAk4+nK35aRvrjY8CsZ1HFRmp376OiaVlWW/ikiIkL58+fXlClTku2Lj4+Xh4eHli1bpho1algcE//0AwAAALBMGjbDsyYxSklSUlKyZOuxmJgYSVKOHDmsOifJEgAAAACLpJfW4X369FGtWrUUHBysW7duadasWVq3bp2WL1+uY8eOadasWapdu7b8/Py0e/dudevWTZUrV1bx4sWtug7JEgAAAIAM5eLFi2rRooXi4uLk7e2t4sWLa/ny5apevbpOnz6tVatWaezYsYqPj1dQUJAaNmyovn37Wn0dkiUAAAAAFkkvlaVp06Y9cV9QUJDWr1//XK7Dc5YAAAAAIAVUlgAAAABYJL1Ull4UKksAAAAAkAIqSwAAAAAsQmUJAAAAAEBlCQAAAICF7KuwRLIEAAAAwDJMwwMAAAAAUFkCAAAAYBkqSwAAAAAAKksAAAAALGNnhSUqSwAAAACQEipLAAAAACzCmiUAAAAAAJUlAAAAAJaxs8ISyRIAAAAAyzANDwAAAABAZQkAAACAZeyssERlCQAAAABSQmUJAAAAgEUcHOyrtERlCQAAAABSQGUJAAAAgEVYswQAAAAAoLIEAAAAwDI8ZwkAAAAAQGUJAAAAgGXsrLBEsgQAAADAMkzDAwAAAABQWQIAAABgGSpLAAAAAAAqSwAAAAAsY2eFJSpLAAAAAJASKksAAAAALMKaJQAAAAAAlSUAAAAAlrGzwhLJEgAAAADLMA0PAAAAAEBlCQAAAIBl7KywRGUJAAAAAFJCZQkAAACARVizBAAAAAAgWQIAAABgGYMh7TZrTJ48WcWLF5eXl5e8vLwUHh6upUuXmvbfu3dPHTt2lJ+fnzw8PNSwYUNduHDB6vslWQIAAACQoeTKlUvDhw/X9u3btW3bNlWtWlX16tXTvn37JEndunXT4sWLNXfuXK1fv17nzp1TgwYNrL4Oa5YAAAAAWCS9rFmqW7eu2eshQ4Zo8uTJ2rx5s3LlyqVp06Zp1qxZqlq1qiQpOjpahQsX1ubNm1WuXDmLr0OyBAAAAMAiaZkrJSQkKCEhwWzM2dlZzs7OT31fYmKi5s6dq/j4eIWHh2v79u168OCBIiIiTMeEhoYqODhYmzZtIlkCYJk/R79t6xAAM8GVu9o6BCCZa1sn2DoEwC4MGzZMAwcONBuLiorSgAEDUjx+z549Cg8P17179+Th4aGFCxcqLCxMMTExcnJyUpYsWcyO9/f31/nz562KiWQJAAAAgEXSchpenz591L17d7Oxp1WVChUqpJiYGN24cUPz5s1TZGSk1q9f/1xjIlkCAAAAYHOWTLn7OycnJxUoUECSVKZMGW3dulXjxo3TO++8o/v37+v69etm1aULFy4oICDAqpjohgcAAADAIumldXhKkpKSlJCQoDJlyihz5sxavXq1ad+hQ4cUGxur8PBwq85JZQkAAABAhtKnTx/VqlVLwcHBunXrlmbNmqV169Zp+fLl8vb2Vps2bdS9e3f5+vrKy8tLH330kcLDw61q7iCRLAEAAACwUHppHX7x4kW1aNFCcXFx8vb2VvHixbV8+XJVr15dkjRmzBg5ODioYcOGSkhIUI0aNTRp0iSrr0OyBAAAACBDmTZt2lP3u7i4aOLEiZo4ceK/ug7JEgAAAACLpJPC0gtDsgQAAADAIullGt6LQjc8AAAAAEgBlSUAAAAAFqGyBAAAAACgsgQAAADAMnZWWKKyBAAAAAApobIEAAAAwCKsWQIAAAAAUFkCAAAAYBk7KyyRLAEAAACwDNPwAAAAAABUlgAAAABYxs4KS1SWAAAAACAlVJYAAAAAWMTBzkpLVJYAAAAAIAVUlgAAAABYxM4KS1SWAAAAACAlVJYAAAAAWMTenrNEsgQAAADAIg72lSsxDQ8AAAAAUkJlCQAAAIBF7G0aHpUlAAAAAEgBlSUAAAAAFrGzwhKVJQAAAABICZUlAAAAABYxyL5KS1SWAAAAACAFVJYAAAAAWMTenrNEsgQAAADAIrQOBwAAAABQWQIAAABgGTsrLFFZAgAAAICUUFkCAAAAYBEHOystUVkCAAAAgBRQWQIAAABgETsrLKU+Wbp06ZIOHTokSSpUqJCyZcv23IICAAAAAFuzehpefHy8WrdurcDAQFWuXFmVK1dWYGCg2rRpozt37qRFjAAAAADSAYPBkGZbemR1stS9e3etX79ev/zyi65fv67r169r0aJFWr9+vXr06JEWMQIAAABIBwyGtNvSI6un4c2fP1/z5s1TlSpVTGO1a9eWq6urGjdurMmTJz/P+AAAAADAJqxOlu7cuSN/f/9k49mzZ2caHgAAAPAfRuvwZwgPD1dUVJTu3btnGrt7964GDhyo8PDw5xocAAAAAPzTsGHD9PLLL8vT01PZs2dX/fr1Tc3nHqtSpUqydVEffPCBVdexurI0duxY1axZU7ly5VKJEiUkSbt27ZKLi4uWL19u7ekAAAAAZBDppa60fv16dezYUS+//LIePnyoTz/9VK+//rr2798vd3d303Ft27bVoEGDTK/d3Nysuo7VyVKxYsV05MgRzZw5UwcPHpQkNW3aVM2bN5erq6u1pwMAAAAAqyxbtszs9fTp05U9e3Zt375dlStXNo27ubkpICAg1dexKll68OCBQkNDtWTJErVt2zbVFwUAAACQ8aRli++EhAQlJCSYjTk7O8vZ2fmZ771x44YkydfX12x85syZ+uGHHxQQEKC6deuqX79+VlWXrFqzlDlzZrO1SgAAAADwPAwbNkze3t5m27Bhw575vqSkJHXt2lUVKlRQ0aJFTePNmjXTDz/8oLVr16pPnz76/vvv9e6771oVk8FoNBqtecPQoUN1+PBhTZ06VZkyWT2LD0A6siv2lq1DAMyUq9fH1iEAyVzbOsHWIQBmXGz4K3jz72PS7NzfNi6cqsrShx9+qKVLl+qPP/5Qrly5nnjcmjVrVK1aNR09elT58+e3KCarP+qtW7dq9erVWrFihYoVK2a2gEqSFixYYO0pAQAAANg5S6fc/V2nTp20ZMkSbdiw4amJkiSVLVtWktI2WcqSJYsaNmxo7dsAAAAAZHBpuWbJGkajUR999JEWLlyodevWKW/evM98T0xMjCQpR44cFl/H6mQpOjra2rcAAAAA+A9IJ7mSOnbsqFmzZmnRokXy9PTU+fPnJUne3t5ydXXVsWPHNGvWLNWuXVt+fn7avXu3unXrpsqVK6t48eIWX4dFRwAAAAAylMmTJ0t69ODZv4uOjlbLli3l5OSkVatWaezYsYqPj1dQUJAaNmyovn37WnUdi5Kl0qVLa/Xq1fLx8VGpUqWeWn7bsWOHVQEAAAAAyBjS0zS8pwkKCtL69ev/9XUsSpbq1atnWmxVv379f31RAAAAAEjvLEqWoqKiUvwZAAAAgP1wSB+FpRfGqofSPnb9+nVNnTpVffr00dWrVyU9mn539uzZ5xocAAAAANiK1Q0edu/erYiICHl7e+vkyZNq27atfH19tWDBAsXGxuq7775LizgBAAAA2Fh6WbP0olhdWerevbtatmypI0eOyMXFxTReu3Ztbdiw4bkGBwAAAAC2YnVlaevWrZoyZUqy8Zw5c5r6mwMAAAD477GvulIqkiVnZ2fdvHkz2fjhw4eVLVu25xIUAAAAgPTHgWl4T/fmm29q0KBBevDggaRH8xZjY2PVu3dvNWzY8LkHCAAAAAC2YHWyNGrUKN2+fVvZs2fX3bt39eqrr6pAgQLy9PTUkCFD0iJGAAAAAOmAwZB2W3pk9TQ8b29vrVy5Un/88Yd2796t27dvq3Tp0oqIiEiL+AAAAADAJqxOlh6rWLGiKlas+DxjAQAAAJCO2VvrcIuSpfHjx1t8ws6dO6c6GAAAAABILyxKlsaMGWP2+tKlS7pz546yZMkiSbp+/brc3NyUPXt2kqUMKE+ePOratau6du1q61CsMn36dHXt2lXXr1+3dSjPxcmTJ5U3b17t3LlTJUuWtHU4AAAAydhZYcmyBg8nTpwwbUOGDFHJkiV14MABXb16VVevXtWBAwdUunRpffbZZ2kdL6xw+vRptW7dWoGBgXJyclLu3LnVpUsXXbly5bleJ0+ePBo7duxzPeeLMmDAABkMhmRbaGioRe+vUqVKqpLMli1bqn79+mZjQUFBiouLU9GiRa0+H2zj7p14TZ80Sh2av6HmdSqob5fWOnpon63Dgp3q2aq67u6coC96/l9n2uXfdNHdnRPMtvH/a2LDKGGv5syaqVrVq+rlUsXUvEkj7dm929YhARaxes1Sv379NG/ePBUqVMg0VqhQIY0ZM0Zvv/22mjdv/lwDROocP35c4eHhKliwoGbPnq28efNq37596tWrl5YuXarNmzfL19fX1mGmC0WKFNGqVavMxjJlSvVyvlRzdHRUQEDAC78uUu+r0YN1+uQxdeo9SL5+2bRh9W/67OMOGjNtrnyzZrd1eLAjZcKC1aZhBe0+fCbZvmnzN+qzyUtMr+/ce/AiQwO0bOlvGjlimPpGDVSxYiU08/sZ+rB9Gy1askx+fn62Dg9W4jlLzxAXF6eHDx8mG09MTNSFCxeeS1D49zp27CgnJyetWLFCr776qoKDg1WrVi2tWrVKZ8+e1f/+9z+z42/duqWmTZvK3d1dOXPm1MSJE037jEajBgwYoODgYDk7OyswMNA03bJKlSo6deqUunXrZqrKSNKVK1fUtGlT5cyZU25ubipWrJhmz55tds2kpCSNGDFCBQoUkLOzs4KDg03t59etWyeDwWA2xS4mJkYGg0EnT5584n1PnjxZ+fPnl5OTkwoVKqTvv//+mZ9VpkyZFBAQYLZlzZrVtH/SpEkKCQmRi4uL/P399fbbb0t6VB1av369xo0bZ7r3kydPKjExUW3atFHevHnl6uqqQoUKady4cabzDRgwQDNmzNCiRYtM71u3bp1Onjwpg8GgmJgY07H79u3TG2+8IS8vL3l6eqpSpUo6duyY6fMbNGiQcuXKJWdnZ5UsWVLLli175v3i+bifcE9bfl+jd9t2Vljx0grIGaTGLdorIGeQViyeZ+vwYEfcXZ0UPbSlOnw2W9dv3k22/+69+7pw5ZZpuxV/zwZRwp59PyNaDd5urPpvNVT+AgXUN2qgXFxc9POC+bYODalgb63DrU6WqlWrpvbt22vHjh2mse3bt+vDDz+kfXg6cfXqVS1fvlwdOnSQq6ur2b6AgAA1b95cP/74o4xGo2n8iy++UIkSJbRz50598skn6tKli1auXClJmj9/vsaMGaMpU6boyJEj+vnnn1WsWDFJ0oIFC5QrVy4NGjRIcXFxiouLkyTdu3dPZcqU0a+//qq9e/eqXbt2eu+99/TXX3+ZrtmnTx8NHz5c/fr10/79+zVr1iz5+/un+r4XLlyoLl26qEePHtq7d6/at2+vVq1aae3atak+57Zt29S5c2cNGjRIhw4d0rJly1S5cmVJ0rhx4xQeHq62bdua7j0oKEhJSUnKlSuX5s6dq/3796t///769NNP9dNPP0mSevbsqcaNG6tmzZqm95UvXz7Ztc+ePavKlSvL2dlZa9as0fbt29W6dWvTHyvGjRunUaNGaeTIkdq9e7dq1KihN998U0eOHEn1/cJyiYmJSkpKVObMTmbjTk7OOrg3xjZBwS6N7fOOlv2+V2u3HEpx/zu1X9LpNcO1be6nGvTRm3J1yfyCI4Q9e3D/vg7s36dy4f/33zkHBweVK1deu3fttGFkgGWsnmv07bffKjIyUi+99JIyZ370L9yHDx+qRo0amjp16nMPENY7cuSIjEajChcunOL+woUL69q1a7p06ZKyZ380VahChQr65JNPJEkFCxbUxo0bNWbMGFWvXl2xsbEKCAhQRESEMmfOrODgYL3yyiuSJF9fXzk6OsrT09NsClnOnDnVs2dP0+uPPvpIy5cv108//aRXXnlFt27d0rhx4zRhwgRFRkZKkvLnz/+v2tGPHDlSLVu2VIcOHSRJ3bt31+bNmzVy5Ei99tprT3zfnj175OHhYTb27rvv6quvvlJsbKzc3d31xhtvyNPTU7lz51apUqUkPXrmmJOTk9zc3Mzu3dHRUQMHDjS9zps3rzZt2qSffvpJjRs3loeHh1xdXZWQkPDUaXcTJ06Ut7e35syZY/pnrWDBgmb327t3bzVp8mj9weeff661a9dq7NixZpVBpA1XN3cVDCuu+TOnKmdwXmXx8dUfa5fr8IE9CgjMZevwYCca1SijkqFBqvjuiBT3/7h0m2Ljriru0g0VCwnU4C71VDB3djXpyX+v8WJcu35NiYmJyabb+fn56cSJ4zaKCv8GrcOfIVu2bPrtt990+PBhHTx4UJIUGhpq9ksc0oe/V46eJTw8PNnrx00bGjVqpLFjxypfvnyqWbOmateurbp16z51XU9iYqKGDh2qn376SWfPntX9+/eVkJAgNzc3SdKBAweUkJCgatWqWX9jT3DgwAG1a9fObKxChQpmU+BSUqhQIf3yyy9mY15eXpKk6tWrK3fu3KZ7r1mzpt566y3TfTzJxIkT9e233yo2NlZ3797V/fv3re5wFxMTo0qVKpkSpb+7efOmzp07pwoVKpiNV6hQQbt27UrxfAkJCUpISDAbu59wX07OzlbFhf/TqfcgTR45SB80rSUHB0flDSmkCq/V0InDB2wdGuxALv8s+qJXQ73x4QQl3E8+PV6Svl2w0fTzvqPnFHf5ppZ93Vl5c2XViTOXX1SoAJBhWT0N77GCBQvqzTff1JtvvkmilM4UKFBABoNBBw6k/AvbgQMH5OPjo2zZsll0vqCgIB06dEiTJk2Sq6urOnTooMqVK+vBgycvEv7iiy80btw49e7dW2vXrlVMTIxq1Kih+/fvS1Ky6YH/5ODw6Kv594Tvadf7N5ycnFSgQAGz7XHFzdPTUzt27NDs2bOVI0cO9e/fXyVKlHhqu/I5c+aoZ8+eatOmjVasWKGYmBi1atXKdO+WetZnZK1hw4bJ29vbbJs2adRzvYa9CQjMpYGjv9Z3v/yuybN+1bAJ3ynx4UNlz5HT1qHBDpQqHCx/Py9tmtVbt7aO062t41T5pRB1aPqqbm0dJweH5H/93brnpCQpf5Bl//4H/i2fLD5ydHRM1on3ypUrZuuDkXE4pOGWHqWq5deZM2f0yy+/KDY2NtkvgKNHj34ugSH1/Pz8VL16dU2aNEndunUz+6X7/Pnzmjlzplq0aGFWRt28ebPZOTZv3mw2jc/V1VV169ZV3bp11bFjR4WGhmrPnj0qXbq0nJyclJiYaPb+jRs3ql69enr33XclPWpGcPjwYYWFhUmSQkJC5OrqqtWrV+v9999Pdg+PE7m4uDj5+PhIklnjg5QULlxYGzduNE3rexzH42umVqZMmRQREaGIiAhFRUUpS5YsWrNmjRo0aPDEey9fvrxpOqAkU1OGx1J63z8VL15cM2bM0IMHD5JVl7y8vBQYGKiNGzfq1VdfNbv24ymS/9SnTx91797dbOzQBesSOKTMxdVVLq6uun3rpnZt26R32/K8OaS9tX8dUpm3h5iNfT3wXR06cUGjpq9UUlLy2QUlCj2aInr+8o0XEiOQ2clJhcOKaMvmTapa7dHa9qSkJG3ZsklNmr5r4+iAZ7M6WVq9erXefPNN5cuXTwcPHlTRokV18uRJGY1GlS5dOi1iRCpMmDBB5cuXV40aNTR48GCz1uE5c+Y0dZ17bOPGjRoxYoTq16+vlStXau7cufr1118lPXr4a2JiosqWLSs3Nzf98MMPcnV1Ve7cuSU9es7Shg0b1KRJEzk7Oytr1qwKCQnRvHnz9Oeff8rHx0ejR4/WhQsXTImLi4uLevfurY8//lhOTk6qUKGCLl26pH379qlNmzYqUKCAgoKCNGDAAA0ZMkSHDx/WqFFPr4L06tVLjRs3VqlSpRQREaHFixdrwYIFydqC/9PDhw91/vx5szGDwSB/f38tWbJEx48fV+XKleXj46PffvtNSUlJptb5efLk0ZYtW3Ty5El5eHjI19dXISEh+u6777R8+XLlzZtX33//vbZu3aq8efOazp8nTx4tX75chw4dkp+fn7y9vZPF1alTJ3355Zdq0qSJ+vTpI29vb23evFmvvPKKChUqpF69eikqKkr58+dXyZIlFR0drZiYGM2cOTPF+3R2dpbzP6bcOV2/9dTPBk8Xs3WTJKMCc+XW+XOn9f3X45UzKI+q1HjT1qHBDty+k6D9x+LMxuLv3tfVG/HafyxOeXNl1Tu1XtLyP/bpyvV4FSuYUyN6NNDv249o75FzNooa9ui9yFbq92lvFSlSVEWLFdcP38/Q3bt3Vf+tBrYODanAmqVn6NOnj3r27KmBAwfK09NT8+fPV/bs2dW8eXPVrFkzLWJEKoSEhGjbtm2KiopS48aNdfXqVQUEBKh+/fqKiopK9oylHj16aNu2bRo4cKC8vLw0evRo1ahRQ5KUJUsWDR8+XN27d1diYqKKFSumxYsXmxZrDho0SO3bt1f+/PmVkJAgo9Govn376vjx46pRo4bc3NzUrl071a9fXzdu/N9fM/v166dMmTKpf//+OnfunHLkyKEPPvhAkpQ5c2bNnj1bH374oYoXL66XX35ZgwcPVqNGjZ54z/Xr19e4ceM0cuRIdenSRXnz5lV0dLSqVKny1M9q3759ypEjh9mYs7Oz7t27pyxZsmjBggUaMGCA7t27p5CQEM2ePVtFihSR9KizXWRkpMLCwnT37l2dOHFC7du3186dO/XOO+/IYDCoadOm6tChg5YuXWo6f9u2bbVu3Tq99NJLun37ttauXas8efKYxeDn56c1a9aoV69eevXVV+Xo6KiSJUua1il17txZN27cUI8ePXTx4kWFhYXpl19+UUhIyFPvF8/PnTu3NXvaBF25fFEenl4qW7GqmrbuaJPndAH/9ODBQ1UtW0idmr0md1cnnblwTT+vjtHwqcttHRrsTM1atXXt6lVNmjBely9fUqHQwpo0Zar8mIaHDMBgtKYLgB6t4YiJiVH+/Pnl4+OjP/74Q0WKFNGuXbtUr169pz4DB0D6siuWyhLSl3L1+tg6BCCZa1sn2DoEwIyLDf8m13XRwTQ799h6oWl27tSyei2Vu7u7aZ1Sjhw5zNZiXL5MZx0AAADgv8rBkHZbemR1XlquXDn98ccfKly4sGrXrq0ePXpoz549WrBggcqVK5cWMQIAAADAC2d1sjR69Gjdvn1bkjRw4EDdvn1bP/74o0JCQuiEBwAAAPyH0eDhGfLly2f62d3dXV999dVzDQgAAAAA0gNaNgEAAACwSHpdW5RWLEqWfHx8LC65Xb169V8FBAAAAADpgUXJ0tixY00/X7lyRYMHD1aNGjUUHh4uSdq0aZOWL1+ufv36pUmQAAAAAGzPzpYsWZYsRUZGmn5u2LChBg0apE6dOpnGOnfurAkTJmjVqlXq1q3b848SAAAAAF4wq5+ztHz5ctWsWTPZeM2aNbVq1arnEhQAAACA9MfBYEizLT2yOlny8/PTokWLko0vWrRIfn5+zyUoAAAAAOmPQxpu6ZHV3fAGDhyo999/X+vWrVPZsmUlSVu2bNGyZcv0zTffPPcAAQAAAMAWrE6WWrZsqcKFC2v8+PFasGCBJKlw4cL6448/TMkTAAAAgP+edDpbLs1YlSw9ePBA7du3V79+/TRz5sy0igkAAAAAbM6q6YGZM2fW/Pnz0yoWAAAAAOkYDR6eoX79+vr555/TIBQAAAAASD+sXrMUEhKiQYMGaePGjSpTpozc3d3N9nfu3Pm5BQcAAAAg/UinBaA0Y3WyNG3aNGXJkkXbt2/X9u3bzfYZDAaSJQAAAABpatiwYVqwYIEOHjwoV1dXlS9fXp9//rkKFSpkOubevXvq0aOH5syZo4SEBNWoUUOTJk2Sv7+/xdexOlk6ceKEtW8BAAAA8B/gkE4qS+vXr1fHjh318ssv6+HDh/r000/1+uuva//+/aaZb926ddOvv/6quXPnytvbW506dVKDBg20ceNGi69jdbL02P3793XixAnlz59fmTKl+jQAAAAAMoj00ohh2bJlZq+nT5+u7Nmza/v27apcubJu3LihadOmadasWapataokKTo6WoULF9bmzZtVrlw5i65jdYOHO3fuqE2bNnJzc1ORIkUUGxsrSfroo480fPhwa08HAAAAAP/KjRs3JEm+vr6SpO3bt+vBgweKiIgwHRMaGqrg4GBt2rTJ4vNanSz16dNHu3bt0rp16+Ti4mIaj4iI0I8//mjt6QAAAABkEAZD2m0JCQm6efOm2ZaQkPDMmJKSktS1a1dVqFBBRYsWlSSdP39eTk5OypIli9mx/v7+On/+vMX3a3Wy9PPPP2vChAmqWLGiDH8rwxUpUkTHjh2z9nQAAAAAoGHDhsnb29tsGzZs2DPf17FjR+3du1dz5sx57jFZvdjo0qVLyp49e7Lx+Ph4s+QJAAAAwH9LWjZ4+LhPH3Xv3t1szNnZ+anv6dSpk5YsWaINGzYoV65cpvGAgADdv39f169fN6suXbhwQQEBARbHZHVl6aWXXtKvv/5qev04QZo6darCw8OtPR0AAAAAyNnZWV5eXmbbk5Ilo9GoTp06aeHChVqzZo3y5s1rtr9MmTLKnDmzVq9ebRo7dOiQYmNjrcpZLK4s7d27V0WLFtWwYcNUs2ZN7d+/Xw8ePNC4ceO0f/9+/fnnn1q/fr3FFwYAAACQsRiUPmaSdezYUbNmzdKiRYvk6elpWofk7e0tV1dXeXt7q02bNurevbt8fX3l5eWljz76SOHh4RZ3wpOsqCwVL15cZcuW1f79+7Vx40Y9fPhQxYsX14oVK5Q9e3Zt2rRJZcqUsf5OAQAAAMAKkydP1o0bN1SlShXlyJHDtP294dyYMWP0xhtvqGHDhqpcubICAgK0YMECq65jcWVp/fr1io6OVo8ePZSUlKSGDRtq5MiRqly5slUXBAAAAJAxpZeH0hqNxmce4+LiookTJ2rixImpvo7FlaVKlSrp22+/VVxcnL788kudPHlSVapUUcGCBfX5559b1YIPAAAAQMbjYEi7LT2yusGDu7u7WrVqpfXr1+vw4cNq1KiRJk6cqODgYL355ptpESMAAAAAvHBWtw7/uwIFCujTTz9V7ty51adPH7MueQAAAAD+W+ztUUGpTpY2bNigb7/9VvPnz5eDg4MaN26sNm3aPM/YAAAAAMBmrEqWzp07p+nTp2v69Ok6evSoypcvr/Hjx6tx48Zyd3dPqxgBAAAApAPpdW1RWrE4WapVq5ZWrVqlrFmzqkWLFmrdurUKFSqUlrEBAAAAgM1YnCxlzpxZ8+bN0xtvvCFHR8e0jAkAAABAOmRnS5YsT5Z++eWXtIwDAAAAANKVf9UNDwAAAID9cLCz0hLJEgAAAACL2FuDB6sfSgsAAAAA9oDKEgAAAACL2NksPCpLAAAAAJASKksAAAAALOIg+yotUVkCAAAAgBRQWQIAAABgEdYsAQAAAACoLAEAAACwDM9ZAgAAAABQWQIAAABgGQc7W7REsgQAAADAInaWKzENDwAAAABSQmUJAAAAgEXsbRoelSUAAAAASAGVJQAAAAAWsbPCEpUlAAAAAEgJlSUAAAAAFrG3Sou93S8AAAAAWITKEgAAAACLGOxs0RLJEgAAAACL2FeqxDQ8AAAAAEgRlSUAAAAAFuGhtAAAAAAAKksAAAAALGNfdSUqSwAAAACQIipLAAAAACxiZ0uWqCwBAAAAQEqoLAEAAACwCA+lBQAAAIAU2Nu0NHu7XwAAAACwCJUlAAAAABaxt2l4VJYAAAAAZCgbNmxQ3bp1FRgYKIPBoJ9//tlsf8uWLWUwGMy2mjVrWn0dkiUAAAAAFjGk4WaN+Ph4lShRQhMnTnziMTVr1lRcXJxpmz17tpVXYRoeAAAAgAymVq1aqlWr1lOPcXZ2VkBAwL+6DskSAAAAAIuk5ZqlhIQEJSQkmI05OzvL2dk5Vedbt26dsmfPLh8fH1WtWlWDBw+Wn5+fVecwGI1GY6quDiDDu/fQ1hEAAABrudiw3DFvV1yanXvvwikaOHCg2VhUVJQGDBjw1PcZDAYtXLhQ9evXN43NmTNHbm5uyps3r44dO6ZPP/1UHh4e2rRpkxwdHS2OiWQJsGMkSwAAZDy2TJYWpGGyVCfUN1WVpZSSpX86fvy48ufPr1WrVqlatWoWx8Q0PAAAAAAWSctpeP9myt2z5MuXT1mzZtXRo0etSpbohgcAAADgP+3MmTO6cuWKcuTIYdX7qCwBAAAAsEh6eSTt7du3dfToUdPrEydOKCYmRr6+vvL19dXAgQPVsGFDBQQE6NixY/r4449VoEAB1ahRw6rrkCwBAAAAyFC2bdum1157zfS6e/fukqTIyEhNnjxZu3fv1owZM3T9+nUFBgbq9ddf12effWb1ND8aPAB2jAYPAABkPLZs8LBoz/k0O3e9Yv/umUhpgTVLAAAAAJACpuEBAAAAsIhDulm19GJQWQIAAACAFFBZAgAAAGCRNHzMUrpEsgQAAADAIgam4QEAAAAAqCwBAAAAsIi9TcOjsgQAAAAAKaCyBAAAAMAitA4HAAAAAFBZAgAAAGAZ1iwBAAAAAKgsAQAAALCMvVWWSJYAAAAAWISH0gIAAAAAqCwBAAAAsIyDfRWWqCwBAAAAQEqoLAEAAACwCGuWAAAAAABUlgAAAABYxt5ah1NZAgAAAIAUUFkCAAAAYBF7W7NEsgQAAADAIrQOBwAAAABQWQIAAABgGXubhkdlCQAAAABSQGUJAAAAgEVoHQ4AAAAAoLIEAAAAwDJ2VliisgQAAAAAKaGyBAAAAMAiDna2aIlkCQAAAIBF7CtVYhoeAAAAAKSIyhIAAAAAy9hZaYnKEgAAAACkgMoSAAAAAIsY7Ky0RGUJAAAAAFJAZQkAAACAReyscziVJQAAAABICZUlAAAAABaxs8ISlSUAAAAAFjKk4WaFDRs2qG7dugoMDJTBYNDPP/9stt9oNKp///7KkSOHXF1dFRERoSNHjlh9uyRLAAAAADKU+Ph4lShRQhMnTkxx/4gRIzR+/Hh99dVX2rJli9zd3VWjRg3du3fPqusYjEaj8XkEDCDjuffQ1hEAAABrudhwIc22EzfT7Nwv5fVK1fsMBoMWLlyo+vXrS3pUVQoMDFSPHj3Us2dPSdKNGzfk7++v6dOnq0mTJhafm8oSAAAAAJtLSEjQzZs3zbaEhASrz3PixAmdP39eERERpjFvb2+VLVtWmzZtsupcJEsAAAAALGIwpN02bNgweXt7m23Dhg2zOsbz589Lkvz9/c3G/f39TfssRTc8AAAAADbXp08fde/e3WzM2dnZRtE8QrIEAAAAwCJp2Trc2dn5uSRHAQEBkqQLFy4oR44cpvELFy6oZMmSVp2LaXgAAAAA/jPy5s2rgIAArV692jR28+ZNbdmyReHh4Vadi8oSAAAAAMukk6fS3r59W0ePHjW9PnHihGJiYuTr66vg4GB17dpVgwcPVkhIiPLmzat+/fopMDDQ1DHPUiRLAAAAADKUbdu26bXXXjO9frzWKTIyUtOnT9fHH3+s+Ph4tWvXTtevX1fFihW1bNkyubi4WHUdnrME2DGeswQAQMZjy+cs7Tx1K83OXSq3Z5qdO7WoLAEAAACwiCGdTMN7UWjwAAAAAAApoLIEAAAAwCJ2VliisgQAAAAAKaGyBAAAAMAydlZaorIEAAAAACmgsgQAAADAIgY7Ky1RWQIAAACAFFBZAgAAAGARe3vOEskSAAAAAIvYWa7ENDwAAAAASAmVJQAAAACWsbPSUoapLOXJk0djx461dRhWmz59urJkyWLrMJBO/fP7MWDAAJUsWdJm8QAAAOD/2DxZOn36tFq3bq3AwEA5OTkpd+7c6tKli65cufJcr5NRky3Yl549e2r16tW2DgNWmDNrpmpVr6qXSxVT8yaNtGf3bluHBPC9RLrDd/K/w5CG/0uPbJosHT9+XC+99JKOHDmi2bNn6+jRo/rqq6+0evVqhYeH6+rVq7YMD3jhPDw85OfnZ+swYKFlS3/TyBHD1L5DR82Zu1CFCoXqw/ZtnvsfewBr8L1EesN3EhmZTZOljh07ysnJSStWrNCrr76q4OBg1apVS6tWrdLZs2f1v//9z+z4W7duqWnTpnJ3d1fOnDk1ceJE0z6j0agBAwYoODhYzs7OCgwMVOfOnSVJVapU0alTp9StWzcZDAYZ/n/PwytXrqhp06bKmTOn3NzcVKxYMc2ePdvsmklJSRoxYoQKFCggZ2dnBQcHa8iQIZKkdevWyWAw6Pr166bjY2JiZDAYdPLkySfe9+TJk5U/f345OTmpUKFC+v777y26j5Q8nrY1ZcoUBQUFyc3NTY0bN9aNGzfMjps6daoKFy4sFxcXhYaGatKkSWb7//rrL5UqVUouLi566aWXtHDhQhkMBsXExEhKeTrhzz//bPosH1u0aJFKly4tFxcX5cuXTwMHDtTDhw9N+w0Gg6ZOnaq33npLbm5uCgkJ0S+//GJ2jvXr1+uVV16Rs7OzcuTIoU8++cTsHPPmzVOxYsXk6uoqPz8/RUREKD4+/omf0d69e1WrVi15eHjI399f7733ni5fvvzE4x/f65IlS1SoUCG5ubnp7bff1p07dzRjxgzlyZNHPj4+6ty5sxITE03vS0hIUM+ePZUzZ065u7urbNmyWrduXbJzBwcHy83NTW+99Vay/1D8cxpeUlKSBg0apFy5csnZ2VklS5bUsmXLTPvv37+vTp06KUeOHHJxcVHu3Lk1bNiwJ94bnq/vZ0SrwduNVf+thspfoID6Rg2Ui4uLfl4w39ahwY7xvUR6w3fyv8VgSLstPbJZsnT16lUtX75cHTp0kKurq9m+gIAANW/eXD/++KOMRqNp/IsvvlCJEiW0c+dOffLJJ+rSpYtWrlwpSZo/f77GjBmjKVOm6MiRI/r5559VrFgxSdKCBQuUK1cuDRo0SHFxcYqLi5Mk3bt3T2XKlNGvv/6qvXv3ql27dnrvvff0119/ma7Zp08fDR8+XP369dP+/fs1a9Ys+fv7p/q+Fy5cqC5duqhHjx7au3ev2rdvr1atWmnt2rXPvI8nOXr0qH766SctXrxYy5Yt086dO9WhQwfT/pkzZ6p///4aMmSIDhw4oKFDh6pfv36aMWOGJOn27dt64403FBYWpu3bt2vAgAHq2bOn1ff2+++/q0WLFurSpYv279+vKVOmaPr06abk8rGBAweqcePG2r17t2rXrq3mzZubqohnz55V7dq19fLLL2vXrl2aPHmypk2bpsGDB0uS4uLi1LRpU7Vu3VoHDhzQunXr1KBBA7Pvyd9dv35dVatWValSpbRt2zYtW7ZMFy5cUOPGjZ96L3fu3NH48eM1Z84cLVu2TOvWrdNbb72l3377Tb/99pu+//57TZkyRfPmzTO9p1OnTtq0aZPmzJmj3bt3q1GjRqpZs6aOHDkiSdqyZYvatGmjTp06KSYmRq+99prpvp5k3LhxGjVqlEaOHKndu3erRo0aevPNN03nHD9+vH755Rf99NNPOnTokGbOnKk8efI89Zx4Ph7cv68D+/epXHh505iDg4PKlSuv3bt22jAy2DO+l0hv+E4io7NZN7wjR47IaDSqcOHCKe4vXLiwrl27pkuXLil79uySpAoVKuiTTz6RJBUsWFAbN27UmDFjVL16dcXGxiogIEARERHKnDmzgoOD9corr0iSfH195ejoKE9PTwUEBJiukTNnTrOk4KOPPtLy5cv1008/6ZVXXtGtW7c0btw4TZgwQZGRkZKk/Pnzq2LFiqm+75EjR6ply5amZKZ79+7avHmzRo4cqddee+2p9/Ek9+7d03fffaecOXNKkr788kvVqVNHo0aNUkBAgKKiojRq1Cg1aNBAkpQ3b15TMhMZGalZs2YpKSlJ06ZNk4uLi4oUKaIzZ87oww8/tOreBg4cqE8++cT0WeXLl0+fffaZPv74Y0VFRZmOa9mypZo2bSpJGjp0qMaPH6+//vpLNWvW1KRJkxQUFKQJEybIYDAoNDRU586dU+/evdW/f3/FxcXp4cOHatCggXLnzi1JT00mJ0yYoFKlSmno0KGmsW+//VZBQUE6fPiwChYsmOL7Hjx4YKoAStLbb7+t77//XhcuXJCHh4fCwsL02muvae3atXrnnXcUGxur6OhoxcbGKjAwUNKj9UfLli1TdHS0hg4dqnHjxqlmzZr6+OOPJT36Dv/5559mlaJ/GjlypHr37q0mTZpIkj7//HOtXbtWY8eO1cSJExUbG6uQkBBVrFhRBoPB9Jkg7V27fk2JiYnJpk36+fnpxInjNooK9o7vJdIbvpP/Pem0AJRmbN7g4UkVgZSEh4cne33gwAFJUqNGjXT37l3ly5dPbdu21cKFC82mbqUkMTFRn332mYoVKyZfX195eHho+fLlio2NlSQdOHBACQkJqlatmpV39WQHDhxQhQoVzMYqVKjwr+4jODjYlChJjz6XpKQkHTp0SPHx8Tp27JjatGkjDw8P0zZ48GAdO3bMFFPx4sXl4uJidg5r7dq1S4MGDTK7Ttu2bRUXF6c7d+6YjitevLjpZ3d3d3l5eenixYumWMLDw82m91WoUEG3b9/WmTNnVKJECVWrVk3FihVTo0aN9M033+jatWtPjWnt2rVmMYWGhkqS6f5T4ubmZkqUJMnf31958uSRh4eH2djjuPfs2aPExEQVLFjQ7Frr1683+5zLli1rdp2nfc43b97UuXPnnvp9admypWJiYlSoUCF17txZK1aseOL5EhISdPPmTbMtISHhiccDAAAkY0jDLR2yWbJUoEABGQwG0y99/3TgwAH5+PgoW7ZsFp0vKChIhw4d0qRJk+Tq6qoOHTqocuXKevDgwRPf88UXX2jcuHHq3bu31q5dq5iYGNWoUUP379+XpGTTA//JweHRx/f3hO9p10ur+3ia27dvS5K++eYbxcTEmLa9e/dq8+bNFp/HwcEhWWL7z5hu376tgQMHml1nz549OnLkiFkiljlzZrP3GQwGJSUlWRSHo6OjVq5cqaVLlyosLExffvmlChUqpBMnTqR4/O3bt1W3bl2zmGJiYnTkyBFVrlz5iddJKcanxX379m05Ojpq+/btZtc5cOCAxo0bZ9G9pUbp0qV14sQJffbZZ7p7964aN26st99+O8Vjhw0bJm9vb7Pti89Z35RaPll85OjomGzd2ZUrV5Q1a1YbRQV7x/cS6Q3fSWR0NkuW/Pz8VL16dU2aNEl3794123f+/HnNnDlT77zzjlmF4Z+/3G/evNlsGp+rq6vq1q2r8ePHa926ddq0aZP27NkjSXJycjJbjC9JGzduVL169fTuu++qRIkSypcvnw4fPmzaHxISIldX1ye2cn6cyD1eAyXJ1BDhSQoXLqyNGzcmiyMsLMyi+0hJbGyszp07Z3q9efNmOTg4qFChQvL391dgYKCOHz+uAgUKmG158+Y1xbR7927du3fP7Bz/vNdbt26ZNVL4572WLl1ahw4dSnadAgUKmBLLZylcuLA2bdpklpht3LhRnp6eypUrl6RHSUqFChU0cOBA7dy5U05OTlq4cGGK5ytdurT27dunPHnyJIvJ3d3dopgsUapUKSUmJurixYvJrvN46mfhwoW1ZcsWs/c9LWH18vJSYGDgM78vXl5eeuedd/TNN9/oxx9/1Pz581PsJNmnTx/duHHDbOvVu8+/uW27ltnJSYXDimjL5k2msaSkJG3ZsknFS5SyYWSwZ3wvkd7wnfzvsbfW4TZbsyQ9Wk9Svnx51ahRQ4MHD1bevHm1b98+9erVSzlz5kzWGGDjxo0aMWKE6tevr5UrV2ru3Ln69ddfJT3qMpaYmKiyZcvKzc1NP/zwg1xdXU1rOPLkyaMNGzaoSZMmcnZ2VtasWRUSEqJ58+bpzz//lI+Pj0aPHq0LFy6YfhF1cXFR79699fHHH8vJyUkVKlTQpUuXtG/fPrVp00YFChRQUFCQBgwYoCFDhujw4cMaNWrUU++5V69eaty4sUqVKqWIiAgtXrxYCxYs0KpVqyy6j5S4uLgoMjJSI0eO1M2bN9W5c2c1btzY9Ev6wIED1blzZ3l7e6tmzZpKSEjQtm3bdO3aNXXv3l3NmjXT//73P7Vt21Z9+vTRyZMnNXLkSLNrPI7n008/VefOnbVlyxZNnz7d7Jj+/fvrjTfeUHBwsN5++205ODho165d2rt37zMbGTzWoUMHjR07Vh999JE6deqkQ4cOKSoqSt27d5eDg4O2bNmi1atX6/XXX1f27Nm1ZcsWXbp06Ylr3zp27KhvvvlGTZs21ccffyxfX18dPXpUc+bM0dSpU+Xo6GhRXM9SsGBBNW/eXC1atNCoUaNUqlQpXbp0SatXr1bx4sVVp04dde7cWRUqVNDIkSNVr149LV++/KnrlaRH35eoqCjlz59fJUuWVHR0tGJiYjRz5kxJ0ujRo5UjRw6VKlVKDg4Omjt3rgICAlJ8ELKzs7OcnZ3Nxu49fYYnnuG9yFbq92lvFSlSVEWLFdcP38/Q3bt3Vf+tBrYODXaM7yXSG76TyMhsmiyFhIRo27ZtioqKUuPGjXX16lUFBASofv36ioqKkq+vr9nxPXr00LZt2zRw4EB5eXlp9OjRqlGjhiQpS5YsGj58uLp3767ExEQVK1ZMixcvNi0oHDRokNq3b6/8+fMrISFBRqNRffv21fHjx1WjRg25ubmpXbt2ql+/vlnb7X79+ilTpkzq37+/zp07pxw5cuiDDz6Q9Giq1uzZs/Xhhx+qePHievnllzV48GA1atToifdcv359jRs3TiNHjlSXLl2UN29eRUdHq0qVKhbdR0oKFCigBg0aqHbt2rp69areeOMNs9bg77//vtzc3PTFF1+oV69ecnd3V7FixdS1a1dJj57ts3jxYn3wwQcqVaqUwsLC9Pnnn6thw4amc/j6+uqHH35Qr1699M0336hatWoaMGCA2rVrZzqmRo0aWrJkiQYNGqTPP/9cmTNnVmhoqN5///2nfQ3M5MyZU7/99pt69eqlEiVKyNfXV23atFHfvn0lPaqibNiwQWPHjtXNmzeVO3dujRo1SrVq1UrxfI8rM71799brr7+uhIQE5c6dWzVr1rS42mWp6OhoDR48WD169NDZs2eVNWtWlStXTm+88YYkqVy5cvrmm28UFRWl/v37KyIiQn379tVnn332xHN27txZN27cUI8ePXTx4kWFhYXpl19+UUhIiCTJ09NTI0aM0JEjR+To6KiXX35Zv/3223O/N6SsZq3aunb1qiZNGK/Lly+pUGhhTZoyVX5MLYEN8b1EesN38r8lvbb4TisGozUdFpDuDBgwQD///PMzp/9Z6+TJk8qbN6927txp9twf/LdQWQIAIONxsWG549D5O88+KJUKBbil2blTy6aVJQAAAAAZh50VlmzfOhwAAAAA0iOm4QF2jGl4AABkPLachnf4QtpNwyvozzQ8AAAAABlUem3xnVaYhgcAAAAAKaCyBAAAAMAi9tY6nMoSAAAAAKSAyhIAAAAAi9hZYYnKEgAAAACkhMoSAAAAAMvYWWmJyhIAAAAApIDKEgAAAACL2NtzlkiWAAAAAFiE1uEAAAAAACpLAAAAACxjZ4UlKksAAAAAkBKSJQAAAACWMaThZoUBAwbIYDCYbaGhof/27pJhGh4AAACADKdIkSJatWqV6XWmTM8/tSFZAgAAAGCR9NQ6PFOmTAoICEjTazANDwAAAECGc+TIEQUGBipfvnxq3ry5YmNjn/s1DEaj0fjczwogQ7j30NYRAAAAa7nYcG5Y7NWENDu3v7uUkGB+fmdnZzk7Oyc7dunSpbp9+7YKFSqkuLg4DRw4UGfPntXevXvl6en53GKisgQAAADAImnZ32HYsGHy9vY224YNG5ZiHLVq1VKjRo1UvHhx1ahRQ7/99puuX7+un3766fneL5UlwH5RWQIAIOOxZWXpdBpWlrJbUVlKycsvv6yIiIgnJlipQYMHAAAAABYxpGF/B2sSo3+6ffu2jh07pvfee++5xsQ0PAAAAAAZSs+ePbV+/XqdPHlSf/75p9566y05OjqqadOmz/U6VJYAAAAAWCh9tA4/c+aMmjZtqitXrihbtmyqWLGiNm/erGzZsj3X67BmCbBjrFkCACDjseWapTPX7qfZuXP5OKXZuVOLyhIAAAAAi6TlmqX0iDVLAAAAAJACKksAAAAALGJnhSWSJQAAAACWYRoeAAAAAIDKEgAAAADLGOxsIh6VJQAAAABIAZUlAAAAAJaxr8ISlSUAAAAASAmVJQAAAAAWsbPCEpUlAAAAAEgJlSUAAAAAFrG35yyRLAEAAACwCK3DAQAAAABUlgAAAABYyL4KS1SWAAAAACAlVJYAAAAAWMTOCktUlgAAAAAgJVSWAAAAAFjE3lqHU1kCAAAAgBRQWQIAAABgEZ6zBAAAAACgsgQAAADAMqxZAgAAAACQLAEAAABASpiGBwAAAMAiTMMDAAAAAFBZAgAAAGAZWocDAAAAAKgsAQAAALAMa5YAAAAAAFSWAAAAAFjGzgpLJEsAAAAALGRn2RLT8AAAAAAgBVSWAAAAAFiE1uEAAAAAACpLAAAAACxD63AAAAAAAJUlAAAAAJaxs8ISlSUAAAAASAmVJQAAAACWsbPSEpUlAAAAABYxpOH/UmPixInKkyePXFxcVLZsWf3111/P9X5JlgAAAABkOD/++KO6d++uqKgo7dixQyVKlFCNGjV08eLF53YNg9FoND63swHIUO49tHUEAADAWi42XEiTlr87WHtfZcuW1csvv6wJEyZIkpKSkhQUFKSPPvpIn3zyyXOJicoSAAAAAJtLSEjQzZs3zbaEhIQUj71//762b9+uiIgI05iDg4MiIiK0adOm5xYTDR4AO2bLv0z9lyQkJGjYsGHq06ePnJ2dbR0OwHcS6Q7fyf+OtPzdYcDgYRo4cKDZWFRUlAYMGJDs2MuXLysxMVH+/v5m4/7+/jp48OBzi4lpeADwL928eVPe3t66ceOGvLy8bB0OwHcS6Q7fSVgiISEhWSXJ2dk5xQT73Llzypkzp/7880+Fh4ebxj/++GOtX79eW7ZseS4x8XdlAAAAADb3pMQoJVmzZpWjo6MuXLhgNn7hwgUFBAQ8t5hYswQAAAAgQ3FyclKZMmW0evVq01hSUpJWr15tVmn6t6gsAQAAAMhwunfvrsjISL300kt65ZVXNHbsWMXHx6tVq1bP7RokSwDwLzk7OysqKopFy0g3+E4iveE7ibTwzjvv6NKlS+rfv7/Onz+vkiVLatmyZcmaPvwbNHgAAAAAgBSwZgkAAAAAUkCyBAAAAAApIFkCAAAAgBSQLAEAAABACkiWAAAAkOauX79u6xAAq5EsAQDwH3Ds2DF99NFHioiIUEREhDp37qxjx47ZOizYqc8//1w//vij6XXjxo3l5+ennDlzateuXTaMDLAOyRIAABnc8uXLFRYWpr/++kvFixdX8eLFtWXLFhUpUkQrV660dXiwQ1999ZWCgoIkSStXrtTKlSu1dOlS1apVS7169bJxdIDleM4SAKRSfHy81q9fr9jYWN2/f99sX+fOnW0UFexRqVKlVKNGDQ0fPtxs/JNPPtGKFSu0Y8cOG0UGe+Xq6qrDhw8rKChIXbp00b179zRlyhQdPnxYZcuW1bVr12wdImCRTLYOAAAyop07d6p27dq6c+eO4uPj5evrq8uXL8vNzU3Zs2cnWcILdeDAAf3000/Jxlu3bq2xY8e++IBg93x8fHT69GkFBQVp2bJlGjx4sCTJaDQqMTHRxtEBlmMaHgCkQrdu3VS3bl1du3ZNrq6u2rx5s06dOqUyZcpo5MiRtg4PdiZbtmyKiYlJNh4TE6Ps2bO/+IBg9xo0aKBmzZqpevXqunLlimrVqiXp0R+aChQoYOPoAMtRWQKAVIiJidGUKVPk4OAgR0dHJSQkKF++fBoxYoQiIyPVoEEDW4cIO9K2bVu1a9dOx48fV/ny5SVJGzdu1Oeff67u3bvbODrYozFjxihPnjw6ffq0RowYIQ8PD0lSXFycOnToYOPoAMuxZgkAUiFbtmz6888/FRISooIFC+rLL79UjRo1dPDgQZUpU0bx8fG2DhF2xGg0auzYsRo1apTOnTsnSQoMDFSvXr3UuXNnGQwGG0cIABkTyRIApMLrr7+uli1bqlmzZmrbtq12796tzp076/vvv9e1a9e0ZcsWW4cIO3Xr1i1Jkqenp40jgb07duyYxo4dqwMHDkiSwsLC1LVrV+XLl8/GkQGWY80SAKTC0KFDlSNHDknSkCFD5OPjow8//FCXLl3S119/bePoYG9OnDihI0eOSHqUJD1OlI4cOaKTJ0/aMDLYqye1sw8LC6OdPTIUKksAAGRwr776qlq3bq3IyEiz8R9++EFTp07VunXrbBMY7Bbt7PFfQbIEAP/CpUuXdOjQIUlSaGiosmbNauOIYI+8vLy0Y8eOZF3Gjh49qpdeeknXr1+3TWCwWy4uLtqzZ49CQkLMxg8fPqzixYvr3r17NooMsA7T8AAgFeLj49W6dWsFBgaqcuXKqly5snLkyKE2bdrozp07tg4PdsZgMJjWKv3djRs3eKYNbIJ29vivIFkCgFTo3r271q9fr19++UXXr1/X9evXtWjRIq1fv149evSwdXiwM5UrV9awYcPMEqPExEQNGzZMFStWtGFksFeP29l//vnn+v333/X7779r+PDhat++vdq2bWvr8ACLMQ0PAFIha9asmjdvnqpUqWI2vnbtWjVu3FiXLl2yTWCwS/v371flypWVJUsWVapUSZL0+++/6+bNm1qzZo2KFi1q4whhb2hnj/8KkiUASAU3Nzdt375dhQsXNhvft2+fXnnlFZ6zhBfu3LlzmjBhgnbt2iVXV1cVL15cnTp1kq+vr61Dg52jnT0yMpIlAEiFatWqyc/PT999951cXFwkSXfv3lVkZKSuXr2qVatW2ThCAADwb5EsAUAq7N27VzVq1FBCQoJKlCghSdq1a5dcXFy0fPlyFSlSxMYR4r9u9+7dKlq0qBwcHLR79+6nHlu8ePEXFBXsWenSpbV69Wr5+PioVKlST51qR+twZBSZbB0AAGRERYsW1ZEjRzRz5kwdPHhQktS0aVM1b95crq6uNo4O9qBkyZI6f/68smfPrpIlS8pgMCilv38aDAY64uGFqFevnpydnSVJ9evXt20wwHNCZQkAgAzo1KlTCg4OlsFg0KlTp556bO7cuV9QVADw30LrcABIhRkzZujXX381vf7444+VJUsWlS9f/pm/uALPQ+7cuU3TnE6dOqWcOXMqd+7cZlvOnDn5PgLAv0BlCQBSoVChQpo8ebKqVq2qTZs2qVq1aho7dqyWLFmiTJkyacGCBbYOEXbE0dFRcXFxyR72eeXKFWXPnp1peHghfHx8LG4JfvXq1TSOBng+WLMEAKlw+vRpFShQQJL0888/6+2331a7du1UoUKFZM9eAtKa0WhM8ZfUK1euyN3d3QYRwR6NHTvW9POVK1c0ePBg1ahRQ+Hh4ZKkTZs2afny5erXr5+NIgSsR7IEAKng4eGhK1euKDg4WCtWrFD37t0lSS4uLrp7966No4O9aNCggaRHTRxatmxpWlwvSYmJidq9e7fKly9vq/BgZyIjI00/N2zYUIMGDVKnTp1MY507d9aECRO0atUqdevWzRYhAlYjWQKAVKhevbref/99lSpVSocPH1bt2rUlPXoobZ48eWwbHOyGt7e3pEeVJU9PT7NOjE5OTipXrpzatm1rq/Bgx5YvX67PP/882XjNmjX1ySef2CAiIHVIlgAgFSZOnKi+ffvq9OnTmj9/vvz8/CRJ27dvV9OmTW0cHexFdHS0JClPnjzq2bMnU+6Qbvj5+WnRokXq0aOH2fiiRYtM/74EMgIaPAAAAOC5mj59ut5//33VqlVLZcuWlSRt2bJFy5Yt0zfffKOWLVvaNkDAQiRLAJAKy5Ytk4eHhypWrCjpUaXpm2++UVhYmCZOnCgfHx8bRwh7M2/ePP3000+KjY3V/fv3zfbt2LHDRlHBnm3ZskXjx4/XgQMHJEmFCxdW586dTckTkBHwnCUASIVevXrp5s2bkqQ9e/aoR48eql27tk6cOGFq9gC8KOPHj1erVq3k7++vnTt36pVXXpGfn5+OHz+uWrVq2To82KmyZctq5syZ2rFjh3bs2KGZM2eSKCHDobIEAKng4eGhvXv3Kk+ePBowYID27t2refPmaceOHapdu7bOnz9v6xBhR0JDQxUVFaWmTZvK09NTu3btUr58+dS/f39dvXpVEyZMsHWIsEPHjh1TdHS0jh8/rrFjxyp79uxaunSpgoODVaRIEVuHB1iEyhIApIKTk5Pu3LkjSVq1apVef/11SZKvr6+p4gS8KLGxsaYW4a6urrp165Yk6b333tPs2bNtGRrs1Pr161WsWDFt2bJF8+fP1+3btyVJu3btUlRUlI2jAyxHsgQAqVCxYkV1795dn332mf766y/VqVNHknT48GHlypXLxtHB3gQEBOjq1auSpODgYG3evFmSdOLECTGBBLbwySefaPDgwVq5cqWcnJxM41WrVjV9P4GMgGQJAFJhwoQJypQpk+bNm6fJkycrZ86ckqSlS5eqZs2aNo4O9qZq1ar65ZdfJEmtWrVSt27dVL16db3zzjt66623bBwd7NGePXtS/O5lz55dly9ftkFEQOqwZgkAgAwuKSlJSUlJypTp0eMT58yZoz///FMhISFq37692V/2gRchV65c+umnn1S+fHmzdXQLFy5Uz549dezYMVuHCFiEZAkAUunx4uVjx45p3LhxLF6GzcTGxiooKEgGg8Fs3Gg06vTp0woODrZRZLBXPXv21JYtWzR37lwVLFhQO3bs0IULF9SiRQu1aNGCdUvIMJiGBwCp8PfFywsWLGDxMmwqb968unTpUrLxq1evKm/evDaICPZu6NChCg0NVVBQkG7fvq2wsDBVrlxZ5cuXV9++fW0dHmAxKksAkArh4eFq1KiRunfvbjbF5K+//lKDBg105swZW4cIO+Lg4KALFy4oW7ZsZuOnTp1SWFiY4uPjbRQZ7F1sbKz27t2r27dvq1SpUgoJCbF1SIBVMtk6AADIiPbs2aNZs2YlG2fxMl6kxw9ANhgM6tevn9zc3Ez7EhMTtWXLFpUsWdJG0QGPujMyDRQZGckSAKRClixZFBcXl2yK086dO02d8YC0tnPnTkmP1ibt2bPHrJGDk5OTSpQooZ49e9oqPNgxo9GoefPmae3atbp48aKSkpLM9i9YsMBGkQHWIVkCgFRo0qSJevfurblz58pgMCgpKUkbN25Uz5491aJFC1uHBzuxdu1aSY/ahY8bN05eXl42jgh4pGvXrpoyZYpee+01+fv7J2s+AmQUrFkCgFS4f/++OnXqpOnTp+vhw4fKlCmTEhMT1axZM02fPl2Ojo62DhF27ObNm1qzZo1CQ0MVGhpq63Bgh3x9ffXDDz+odu3atg4F+FeoLAGAFZKSkvTFF1/ol19+0f379/Xee++pYcOGLF6GTTVu3FiVK1dWp06ddPfuXb300ks6efKkjEaj5syZo4YNG9o6RNgZb29v5cuXz9ZhAP8arcMBwApDhgzRp59+Kg8PD+XMmVOzZs3SvHnz1LhxYxIl2MyGDRtUqVIlSdLChQtlNBp1/fp1jR8/XoMHD7ZxdLBHAwYM0MCBA3X37l1bhwL8K0zDAwArhISEqGfPnmrfvr0kadWqVapTp47u3r0rBwf+/gTbcHV11eHDhxUUFKQWLVooMDBQw4cPV2xsrMLCwkzPAQNelLt37+qtt97Sxo0blSdPHmXOnNls/44dO2wUGWAdpuEBgBViY2PN5uBHRETIYDDo3LlzypUrlw0jgz0LCgrSpk2b5Ovrq2XLlmnOnDmSpGvXrsnFxcXG0cEeRUZGavv27Xr33Xdp8IAMjWQJAKzw8OHDZL98Zs6cWQ8ePLBRRMCjzmPNmzeXh4eHcufOrSpVqkh6ND2vWLFitg0OdunXX3/V8uXLVbFiRVuHAvwrJEsAYAWj0aiWLVvK2dnZNHbv3j198MEHcnd3N43xDBG8SB06dFDZsmUVGxur6tWrm6aE5suXjzVLsImgoCBa2eM/gTVLAGCFVq1aWXRcdHR0GkcCAOnXr7/+qi+//FJfffWV8uTJY+twgFQjWQIAIIMKCwvTH3/8IV9fX0mPKkyDBg1S1qxZJUkXL15Unjx5dOfOHVuGCTvk4+OjO3fu6OHDh3Jzc0vW4OHq1as2igywDskSAAAZlIODg86fP6/s2bNLkry8vBQTE2N6vs2FCxeUI0cOJSUl2TJM2KEZM2Y8dX9kZOQLigT4d1izBADAf0RKf/+kCxlsgWQI/xU8FAQAAAAAUkCyBABABmUwGJJVjqgkAcDzwzQ8AAAyKKPRqGrVqilTpkf/Ob97967q1q0rJycnSY+eCwYASD0aPAAAkEENHDjQouOioqLSOBIA+G8iWQIAAECaOHr0qI4dO6bKlSvL1dVVRqORqaLIUFizBAAAgOfqypUrioiIUMGCBVW7dm3FxcVJktq0aaMePXrYODrAciRLAAAAeK66deumTJkyKTY2Vm5ubqbxd955R8uWLbNhZIB1aPAAAACA52rFihVavny5cuXKZTYeEhKiU6dO2SgqwHpUlgAAAPBcxcfHm1WUHrt69aqcnZ1tEBGQOiRLAAAAeK4qVaqk7777zvTaYDAoKSlJI0aM0GuvvWbDyADr0A0PAID/gPXr12vkyJE6cOCAJCksLEy9evVSpUqVbBwZ7NHevXtVrVo1lS5dWmvWrNGbb76pffv26erVq9q4caPy589v6xABi1BZAgAgg/vhhx8UEREhNzc3de7cWZ07d5arq6uqVaumWbNm2To82KGiRYvq8OHDqlixourVq6f4+Hg1aNBAO3fuJFFChkJlCQCADK5w4cJq166dunXrZjY+evRoffPNN6ZqEwDAOiRLAABkcM7Oztq3b58KFChgNn706FEVLVpU9+7ds1FkAJCxMQ0PAIAMLigoSKtXr042vmrVKgUFBdkgIgD4b+A5SwAAZHA9evRQ586dFRMTo/Lly0uSNm7cqOnTp2vcuHE2jg4AMi6m4QEA8B+wcOFCjRo1yrQ+qXDhwurVq5fq1atn48gAIOMiWQIAAMBzdffuXRmNRtODaU+dOqWFCxcqLCxMr7/+uo2jAyzHmiUAAAA8V/Xq1TM9lPb69esqW7asRo0apXr16mny5Mk2jg6wHMkSAAAZkI+Pj3x9fS3agBdtx44dpgciz5s3T/7+/jp16pS+++47jR8/3sbRAZajwQMAABnQ2LFjbR0C8ER37tyRp6enJGnFihVq0KCBHBwcVK5cOZ06dcrG0QGWI1kCACADioyMtHUIwBMVKFBAP//8s9566y0tX77c9MDkixcvysvLy8bRAZajwQMAABlcbGzsU/cHBwe/oEiAR+bNm6dmzZopMTFRVatW1cqVKyVJw4YN04YNG7R06VIbRwhYhmQJAIAMzsHBQQaD4Yn7ExMTX2A0wCPnz59XXFycSpQoIQeHR8vk//rrL3l5eSk0NNTG0QGWIVkCACCD27Vrl9nrBw8eaOfOnRo9erSGDBmiBg0a2CgyQDpz5owkKVeuXDaOBLAeyRIAAP9Rv/76q7744gutW7fO1qHAziQlJWnw4MEaNWqUbt++LUny9PRUjx499L///c9UaQLSOxo8AADwH1WoUCFt3brV1mHADv3vf//TtGnTNHz4cFWoUEGS9Mcff2jAgAG6d++ehgwZYuMIActQWQIAIIO7efOm2Wuj0ai4uDgNGDBABw8eVExMjG0Cg90KDAzUV199pTfffNNsfNGiRerQoYPOnj1ro8gA61BZAgAgg8uSJUuyBg9Go1FBQUGaM2eOjaKCPbt69WqKTRxCQ0N19epVG0QEpA7JEgAAGdyaNWvMkiUHBwdly5ZNBQoUUKZM/KceL16JEiU0YcIEjR8/3mx8woQJKlGihI2iAqzHNDwAAAA8V+vXr1edOnUUHBys8PBwSdKmTZt0+vRp/fbbb6pUqZKNIwQsQ7IEAEAGN2zYMPn7+6t169Zm499++60uXbqk3r172ygy2LNz585p4sSJOnjwoCSpcOHC6tChgwIDA20cGWA5kiUAADK4PHnyaNasWSpfvrzZ+JYtW9SkSROdOHHCRpEBQMbGRGYAADK48+fPK0eOHMnGs2XLpri4OBtEBEjXr1/XX3/9pYsXLyopKclsX4sWLWwUFWAdkiUAADK4oKAgbdy4UXnz5jUb37hxI1OeYBOLFy9W8+bNdfv2bXl5eZk1IDEYDCRLyDBIlgAAyODatm2rrl276sGDB6pataokafXq1fr444/Vo0cPG0cHe9SjRw+1bt1aQ4cOlZubm63DAVKNNUsAAGRwRqNRn3zyicaPH6/79+9LklxcXNS7d2/179/fxtHBHrm7u2vPnj3Kly+frUMB/hWSJQAA/iNu376tAwcOyNXVVSEhIXJ2drZ1SLBTDRo0UJMmTdS4cWNbhwL8K0zDAwDgP8LDw0Mvv/yyrcMAVKdOHfXq1Uv79+9XsWLFlDlzZrP9b775po0iA6xDZQkAgP+Abdu26aefflJsbKxpKt5jCxYssFFUsFcODg5P3GcwGJSYmPgCowFS78nfZAAAkCHMmTNH5cuX14EDB7Rw4UI9ePBA+/bt05o1a+Tt7W3r8GCHkpKSnriRKCEjIVkCACCDGzp0qMaMGaPFixfLyclJ48aN08GDB9W4cWMFBwfbOjzYuXv37tk6BCDVSJYAAMjgjh07pjp16kiSnJycFB8fL4PBoG7duunrr7+2cXSwR4mJifrss8+UM2dOeXh46Pjx45Kkfv36adq0aTaODrAcyRIAABmcj4+Pbt26JUnKmTOn9u7dK0m6fv267ty5Y8vQYKeGDBmi6dOna8SIEXJycjKNFy1aVFOnTrVhZIB1SJYAAMjgKleurJUrV0qSGjVqpC5duqht27Zq2rSpqlWrZuPoYI++++47ff3112revLkcHR1N4yVKlNDBgwdtGBlgHVqHAwCQwU2YMMG0LuR///ufMmfOrD///FMNGzZU3759bRwd7NHZs2dVoECBZONJSUl68OCBDSICUodkCQCADM7X19f0s4ODgz755BMbRgNIYWFh+v3335U7d26z8Xnz5qlUqVI2igqwHskSAAAZnKOjo+Li4pQ9e3az8StXrih79uy0asYL179/f0VGRurs2bNKSkrSggULdOjQIX333XdasmSJrcMDLMaaJQAAMrgnPV8+ISHBbHE98KLUq1dPixcv1qpVq+Tu7q7+/fvrwIEDWrx4sapXr27r8ACLUVkCACCDGj9+vCTJYDBo6tSp8vDwMO1LTEzUhg0bFBoaaqvwYOcqVapkajwCZFQG45P+HAUAANK1vHnzSpJOnTqlXLlymXUdc3JyUp48eTRo0CCVLVvWViECQIZGsgQAQAb32muvacGCBfLx8bF1KICkR41GDAbDE/ezjg4ZBdPwAADI4NauXWv2OjExUXv27FHu3LlJoGATCxcuNHv94MED7dy5UzNmzNDAgQNtFBVgPSpLAABkcF27dlWxYsXUpk0bJSYmqnLlytq0aZPc3Ny0ZMkSValSxdYhApKkWbNm6ccff9SiRYtsHQpgEbrhAQCQwc2dO1clSpSQJC1evFgnT57UwYMH1a1bN/3vf/+zcXTA/ylXrpxWr15t6zAAi5EsAQCQwV25ckUBAQGSpN9++02NGjVSwYIF1bp1a+3Zs8fG0QGP3L17V+PHj1fOnDltHQpgMdYsAQCQwfn7+2v//v3KkSOHli1bpsmTJ0uS7ty5Y9YhD3hRfHx8zBo8GI1G3bp1S25ubvrhhx9sGBlgHZIlAAAyuFatWqlx48bKkSOHDAaDIiIiJElbtmzhOUuwiTFjxpglSw4ODsqWLZvKli1L0xFkKDR4AADgP2DevHk6ffq0GjVqpFy5ckmSZsyYoSxZsqhevXo2jg4AMiaSJQAAADxXu3fvtvjY4sWLp2EkwL9DsgQAwH/A6tWrNWbMGB04cECSVLhwYXXt2tU0JQ94kZ71UFrp0Tomg8HAA2qRrtENDwCADG7SpEmqWbOmPD091aVLF3Xp0kVeXl6qXbu2Jk6caOvwYIcWLFigvHnzatKkSdq5c6d27typSZMmKX/+/Jo/f76OHz+uEydO6Pjx47YOFXgqKksAAGRwuXLl0ieffKJOnTqZjU+cOFFDhw7V2bNnbRQZ7NUrr7yiAQMGqHbt2mbjv/32m/r166ft27fbKDLAOlSWAADI4K5fv66aNWsmG3/99dd148YNG0QEe7dnzx7lzZs32XjevHm1f/9+G0QEpA7JEgAAGdybb76phQsXJhtftGiR3njjDRtEBHtXuHBhDRs2TPfv3zeN3b9/X8OGDVPhwoVtGBlgHZ6zBABABjR+/HjTz2FhYRoyZIjWrVun8PBwSdLmzZu1ceNG9ejRw1Yhwo599dVXqlu3rnLlymXqdrd7924ZDAYtXrzYxtEBlmPNEgAAGVBKU5xSYjAYWEQPm4iPj9fMmTN18OBBSY+qTc2aNZO7u7uNIwMsR7IEAAAAAClgzRIAAP8Rly9f1uXLl20dBiBJ+v7771WxYkUFBgbq1KlTkqQxY8Zo0aJFNo4MsBzJEgAAGdj169fVsWNHZc2aVf7+/vL391fWrFnVqVMnXb9+3dbhwU5NnjxZ3bt3V61atXTt2jXTg2d9fHw0duxY2wYHWIFpeAAAZFBXr15VeHi4zp49q+bNm5u6jO3fv1+zZs1SUFCQ/vzzT/n4+Ng4UtibsLAwDR06VPXr15enp6d27dqlfPnyae/evapSpQoVUGQYdMMDACCDGjRokJycnHTs2DH5+/sn2/f6669r0KBBGjNmjI0ihL06ceKESpUqlWzc2dlZ8fHxNogISB2m4QEAkEH9/PPPGjlyZLJESZICAgI0YsSIFJ+/BKS1vHnzKiYmJtn4smXLeM4SMhQqSwAAZFBxcXEqUqTIE/cXLVpU58+ff4ERAY90795dHTt21L1792Q0GvXXX39p9uzZGjZsmKZOnWrr8ACLkSwBAJBBZc2aVSdPnlSuXLlS3H/ixAn5+vq+4KgA6f3335erq6v69u2rO3fuqFmzZgoMDNS4cePUpEkTW4cHWIwGDwAAZFCtW7fWsWPHtHLlSjk5OZntS0hIUI0aNZQvXz59++23NooQkO7cuaPbt28re/bstg4FsBrJEgAAGdSZM2f00ksvydnZWR07dlRoaKiMRqMOHDigSZMmKSEhQdu2bVNQUJCtQ4Wdunjxog4dOiRJCg0NVbZs2WwcEWAdkiUAADKwEydOqEOHDlqxYoUe/yfdYDCoevXqmjBhggoUKGDjCGGPbt26pQ4dOmj27NlKSkqSJDk6Ouqdd97RxIkT5e3tbeMIAcuQLAEA8B9w7do1HTlyRJJUoEAB1irBpt555x3t3LlTX375pcLDwyVJmzZtUpcuXVSyZEnNmTPHxhECliFZAgAAwHPl7u6u5cuXq2LFimbjv//+u2rWrMmzlpBh8JwlAAAAPFd+fn4pTrXz9vaWj4+PDSICUodkCQAAAM9V37591b17d7PnfJ0/f169evVSv379bBgZYB2m4QEAAOC5KlWqlI4ePaqE/9fe/cdEXT9wHH+dZ3f+AAPC+JGHOA+ExLmRm1M300ClIjU3qM211FYrNX5EGc50DKf9cP6cmpaibebMCirNaXru0s7l0rSRQKmBv4YrRCxz/PC87x8tvl/idHf4wY98ez7+8t6fD3cv7h99+f7xaWpSXFycJOns2bOy2+1KSEhoc+/3339vRkQgIDyUFgAAAIaaPHmy2REAQzCzBAAAAAB+sGcJAAAAAPygLAEAAACAH5QlAAAAAPCDsgQAAAAAflCWAAAA0Km8Xq+OHz+uy5cvmx0FCAplCQAAAIbKy8vTxo0bJf1VlB5++GGlpqbK4XDI7XabGw4IAmUJAAAAhvrkk080dOhQSdKOHTtUXV2tqqoq5efna968eSanAwJHWQIAAICh6urqFB0dLUnatWuXsrKylJiYqBkzZqi8vNzkdEDgKEsAAAAwVFRUlCoqKuT1erV7926NGzdOknTt2jVZrVaT0wGB6252AAAAAPx/mT59urKzsxUTEyOLxaL09HRJ0uHDh5WUlGRyOiBwlCUAAAAYqqioSCkpKTp37pyysrJkt9slSVarVYWFhSanAwJn8fl8PrNDAAAAAMDdhj1LAAAAMNzXX3+tJ554Qk6nU06nUxMnTtTBgwfNjgUEhbIEAAAAQ23ZskXp6enq1auXcnJylJOTo549eyotLU1bt241Ox4QMJbhAQAAwFDJycl64YUXlJ+f32Z82bJlev/991VZWWlSMiA4lCUAAAAYym6368SJE3I6nW3GT506pZSUFDU2NpqUDAgOy/AAAABgKIfDIZfL1W583759cjgcJiQCOoajwwEAAGCogoIC5eTk6Pjx4xo5cqQkyePxaPPmzVq5cqXJ6YDAsQwPAAAAhisrK9PSpUtb9yclJyfrtdde06RJk0xOBgSOsgQAAAAAfrBnCQAAAAD8YM8SAAAAblt4eLgsFktA99bX13dyGsAYlCUAAADcthUrVpgdATAce5YAAAAAwA9mlgAAAGCos2fP3vJ6XFzcHUoC3B5mlgAAAGCobt263XL/ktfrvYNpgI5jZgkAAACGOnbsWJvXLS0tOnbsmJYtW6ZFixaZlAoIHjNLAAAAuCO+/PJLLVmyRG632+woQEB4zhIAAADuiEGDBum7774zOwYQMJbhAQAAwFC///57m9c+n0+1tbUqKipSQkKCSamA4FGWAAAAYKiwsLB2Bzz4fD45HA5t27bNpFRA8NizBAAAAEO53e42Zalbt27q27evnE6nunfn/+rRdVCWAAAAAMAPDngAAACAod58802VlJS0Gy8pKdHbb79tQiKgYyhLAAAAMNT69euVlJTUbnzw4MFat26dCYmAjqEsAQAAwFAXL15UTExMu/G+ffuqtrbWhERAx1CWAAAAYCiHwyGPx9Nu3OPxKDY21oREQMdwHAkAAAAM9fzzzysvL08tLS165JFHJEkul0tz5sxRQUGByemAwHEaHgAAAAzl8/lUWFioVatWqbm5WZLUo0cPvf7661qwYIHJ6YDAUZYAAADQKa5evarKykr17NlTCQkJstvtZkcCgkJZAgAAAAA/2LMEAAAAwx05ckTbt2/X2bNnW5fi/a20tNSkVEBwOA0PAAAAhtq2bZtGjhypyspKlZWVqaWlRSdOnND+/ft17733mh0PCBhlCQAAAIZavHixli9frh07dshms2nlypWqqqpSdna24uLizI4HBIyyBAAAAEOdPn1ajz/+uCTJZrPpzz//lMViUX5+vt577z2T0wGBoywBAADAUOHh4frjjz8kSQ888IB+/PFHSVJDQ4OuXbtmZjQgKBzwAAAAAEONHj1ae/fu1ZAhQ5SVlaXc3Fzt379fe/fuVVpamtnxgIBxdDgAAAAMVV9fr8bGRsXGxurGjRt65513dOjQISUkJOiNN95QeHi42RGBgFCWAAAAAMAP9iwBAADAUFarVb/++mu78UuXLslqtZqQCOgYyhIAAAAMdbOFS01NTbLZbHc4DdBxHPAAAAAAQ6xatUqSZLFYtGHDBoWEhLRe83q9OnDggJKSksyKBwSNPUsAAAAwxIABAyRJZ86cUb9+/dosubPZbIqPj1dxcbGGDx9uVkQgKJQlAAAAGGrs2LEqLS3l1Dt0eZQlAAAAdCqv16vy8nL179+fAoUuhQMeAAAAYKi8vDxt3LhR0l9FafTo0UpNTZXD4ZDb7TY3HBAEyhIAAAAM9fHHH2vo0KGSpB07dqimpkZVVVXKz8/XvHnzTE4HBI6yBAAAAENdunRJ0dHRkqRdu3YpKytLiYmJmjFjhsrLy01OBwSOsgQAAABDRUVFqaKiQl6vV7t379a4ceMkSdeuXeOhtOhSeM4SAAAADDV9+nRlZ2crJiZGFotF6enpkqTDhw/znCV0KZQlAAAAGKqoqEgpKSk6d+6csrKyZLfbJUlWq1WFhYUmpwMCx9HhAAAAAOAHe5YAAABgOJfLpczMTA0cOFADBw5UZmam9u3bZ3YsICiUJQAAABhq7dq1ysjIUGhoqHJzc5Wbm6s+ffroscce05o1a8yOBwSMZXgAAAAwVL9+/VRYWKjZs2e3GV+zZo0WL16sCxcumJQMCA4zSwAAADBUQ0ODMjIy2o2PHz9eV65cMSER0DGUJQAAABhq4sSJKisrazf++eefKzMz04REQMdwdDgAAABu26pVq1r//OCDD2rRokVyu90aMWKEJOnbb7+Vx+NRQUGBWRGBoLFnCQAAALdtwIABAd1nsVj0yy+/dHIawBiUJQAAAADwgz1LAAAA6BR1dXWqq6szOwbQYZQlAAAAGKahoUGzZs1SZGSkoqKiFBUVpcjISM2ePVsNDQ1mxwOCwjI8AAAAGKK+vl4jRozQhQsXNHXqVCUnJ0uSKioqtHXrVjkcDh06dEjh4eEmJwUCQ1kCAACAIfLy8uRyubRv3z5FRUW1uXbx4kWNHz9eaWlpWr58uUkJgeBQlgAAAGCI+Ph4rV+/XhMmTPB7fffu3XrxxRdVU1NzZ4MBHcSeJQAAABiitrZWgwcPvun1lJQUXbx48Q4mAm4PZQkAAACGiIyMvOWsUXV1tSIiIu5cIOA2UZYAAABgiAkTJmjevHlqbm5ud62pqUnz589XRkaGCcmAjmHPEgAAAAxx/vx5DRs2THa7XbNmzVJSUpJ8Pp8qKyu1du1aNTU16ciRI3I4HGZHBQJCWQIAAIBhqqurNXPmTH311Vf6+5+ZFotF48aN0+rVq+V0Ok1OCASOsgQAAADDXb58WSdPnpQkOZ1O9iqhS6IsAQAAAIAfHPAAAAAAAH5QlgAAAADAD8oSAAAAAPhBWQIA4P/ctGnTNHny5NbXY8aMUV5enml5AKCroCwBAGCSadOmyWKxyGKxyGazyel0qri4WNevX+/Uzy0tLdXChQtbX8fHx2vFihWd+pkA0BV1NzsAAAD/ZhkZGdq0aZOampq0a9cuzZo1S/fcc4/mzp3b5r7m5mbZbDZDPpMjnAEgMMwsAQBgIrvdrujoaPXv318vvfSS0tPT9cUXX7QunVu0aJFiY2M1aNAgSdK5c+eUnZ2tsLAwRUREaNKkSaqpqWl9P6/Xq1deeUVhYWG67777NGfOHP3zKSH/uwxvzJgxOnPmjPLz81tnuf726aefavDgwbLb7YqPj9fSpUs7/fsAgLsJZQkAgLtIz5491dzcLElyuVz66aeftHfvXu3cuVMtLS2aMGGCQkNDdfDgQXk8HoWEhCgjI6P1Z5YuXarNmzerpKRE33zzjerr61VWVnbTzystLVW/fv1UXFys2tpa1dbWSpKOHj2q7OxsPf300yovL1dRUZHmz5+vzZs3d/p3AAB3C5bhAQBwF/D5fHK5XNqzZ49efvll/fbbb+rdu7c2bNjQuvxuy5YtunHjhjZs2NA6A7Rp0yaFhYXJ7XZr/PjxWrFihebOnaspU6ZIktatW6c9e/bc9HMjIiJktVoVGhqq6Ojo1vFly5YpLS1N8+fPlyQlJiaqoqJCS5Ys0bRp0zrpWwCAuwszSwAAmGjnzp0KCQlRjx499Oijj+qpp55SUVGRJGnIkCFt9in98MMPOnXqlEJDQxUSEqKQkBBFRESosbFRp0+f1pUrV1RbW6vhw4e3/kz37t01bNiwoHNVVlZq1KhRbcZGjRqlkydPyuv1duyXBYAuhpklAABMNHbsWL377ruy2WyKjY1V9+7//au5d+/ebe69evWqHnroIX344Yft3qdv376dnhUA/m0oSwAAmKh3795yOp0B3ZuamqqPPvpI999/v/r06eP3npiYGB0+fFijR4+WJF2/fl1Hjx5VamrqTd/XZrO1my1KTk6Wx+NpM+bxeJSYmCir1RpQXgDo6liGBwBAFzF16lRFRkZq0qRJOnjwoKqrq+V2u5WTk6Pz589LknJzc/XWW2/ps88+U1VVlWbOnKmGhoZbvm98fLwOHDigCxcuqK6uTpJUUFAgl8ulhQsX6ueff9YHH3yg1atX69VXX+3sXxMA7hqUJQAAuohevXrpwIEDiouL05QpU5ScnKznnntOjY2NrTNNBQUFeuaZZ/Tss89qxIgRCg0N1ZNPPnnL9y0uLlZNTY0GDhzYupwvNTVV27dv17Zt25SSkqIFCxaouLiYwx0A/KtYfP98+AIAAAAAgJklAAAAAPCHsgQAAAAAflCWAAAAAMAPyhIAAAAA+EFZAgAAAAA/KEsAAAAA4AdlCQAAAAD8oCwBAAAAgB+UJQAAAADwg7IEAAAAAH5QlgAAAADAD8oSAAAAAPjxH17nHLq6x0RJAAAAAElFTkSuQmCC\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 800x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["plt.figure(figsize=(8,6))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=obstacle_types, yticklabels=obstacle_types)\n","plt.xlabel('Predito')\n","plt.ylabel('Verdadeiro')\n","plt.title('Matriz de Confusão')\n","plt.show()\n","\n","# Distribuição dos erros\n","plt.figure(figsize=(8,4))\n","errors_df['true_label_str'].value_counts().plot(kind='bar', color='tomato', alpha=0.7)\n","plt.title('Distribuição dos Erros por Classe Verdadeira')\n","plt.xlabel('Classe Verdadeira')\n","plt.ylabel('Número de Erros')\n","plt.show()"]},{"cell_type":"markdown","id":"0e7e946e","metadata":{"id":"0e7e946e"},"source":["# 04_Analise_Textual_Gemini.ipynb\n","\n","Este notebook utiliza a API Gemini para análise textual interativa dos resultados e erros do modelo multi-feature, com foco em explicações e insights sobre os dados e classificações.\n","\n","**Passos principais:**\n","- Montar o Google Drive\n","- Carregar configuração, métricas, erros e dados de teste\n","- Configurar a chave da API Gemini de forma segura\n","- Analisar métricas globais e casos de erro específicos usando Gemini"]},{"cell_type":"markdown","id":"fce7da06","metadata":{"id":"fce7da06"},"source":["## Instalar Bibliotecas Necessárias\n","\n","Execute a célula abaixo para instalar as bibliotecas necessárias para o notebook."]},{"cell_type":"code","execution_count":46,"id":"00957119","metadata":{"id":"00957119","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747530157263,"user_tz":180,"elapsed":2915,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"f3a14399-a54f-4e70-a6cf-cc6225fc86f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n","Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n","Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n","Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.2)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n","Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.4.26)\n"]}],"source":["!pip install google-generativeai pandas numpy"]},{"cell_type":"markdown","id":"f1fc6df6","metadata":{"id":"f1fc6df6"},"source":["## Importar Bibliotecas"]},{"cell_type":"markdown","id":"7c52c9d2","metadata":{"id":"7c52c9d2"},"source":["## Montar Google Drive\n","Monte seu Google Drive para acessar os arquivos de configuração, métricas, erros e dados de teste."]},{"cell_type":"markdown","id":"70fa9753","metadata":{"id":"70fa9753"},"source":["## Carregar Configuração e Caminhos\n","Carregue o arquivo de configuração (project_config.json) e extraia project_base_dir, feature_columns e obstacle_types."]},{"cell_type":"code","execution_count":48,"id":"01f93ef1","metadata":{"id":"01f93ef1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747530182324,"user_tz":180,"elapsed":45,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"5cf69d83-7131-4996-c343-a4db7c4106aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["project_base_dir: /content/drive/MyDrive/SimClasIotIA/\n","feature_columns: ['Distancia', 'Variacao da Distancia', 'Tamanho Percebido', 'Velocidade de Aproximacao', 'Frequencia de Deteccao']\n","obstacle_types: ['Pessoa', 'Obstaculo Estatico', 'Obstaculos pequenos e medios']\n"]}],"source":["# Defina o caminho do arquivo de configuração\n","config_path = '/content/drive/MyDrive/SimClasIotIA/project_config.json'\n","\n","with open(config_path, 'r') as f:\n","    config = json.load(f)\n","\n","project_base_dir = config['project_base_dir']\n","feature_columns = config['feature_columns']\n","obstacle_types = config['obstacle_types']\n","print('project_base_dir:', project_base_dir)\n","print('feature_columns:', feature_columns)\n","print('obstacle_types:', obstacle_types)"]},{"cell_type":"markdown","id":"0fe0a3f8","metadata":{"id":"0fe0a3f8"},"source":["## Definir Nomes de Arquivos\n","Defina os nomes dos arquivos de entrada e construa os caminhos completos."]},{"cell_type":"code","execution_count":49,"id":"84f6aff6","metadata":{"id":"84f6aff6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747530186183,"user_tz":180,"elapsed":48,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"4547c0f2-d273-4257-d649-7853fca28ee2"},"outputs":[{"output_type":"stream","name":"stdout","text":["metrics_input_path: /content/drive/MyDrive/SimClasIotIA/metrics.json\n","errors_input_path: /content/drive/MyDrive/SimClasIotIA/errors.csv\n","X_test_path: /content/drive/MyDrive/SimClasIotIA/X_test.npy\n","y_test_path: /content/drive/MyDrive/SimClasIotIA/y_test.npy\n"]}],"source":["metrics_input_filename = 'metrics.json'\n","errors_input_filename = 'errors.csv'\n","X_test_filename = 'X_test.npy'\n","y_test_filename = 'y_test.npy'\n","\n","data_input_filename = 'simulated_sensor_data.csv'  # Opcional para análise\n","\n","metrics_input_path = os.path.join(project_base_dir, metrics_input_filename)\n","errors_input_path = os.path.join(project_base_dir, errors_input_filename)\n","X_test_path = os.path.join(project_base_dir, X_test_filename)\n","y_test_path = os.path.join(project_base_dir, y_test_filename)\n","\n","data_filepath = os.path.join(project_base_dir, data_input_filename)\n","\n","print('metrics_input_path:', metrics_input_path)\n","print('errors_input_path:', errors_input_path)\n","print('X_test_path:', X_test_path)\n","print('y_test_path:', y_test_path)"]},{"cell_type":"markdown","id":"b1a0175d","metadata":{"id":"b1a0175d"},"source":["## Configurar API Key Gemini (Segura)\n","A chave de API Gemini deve ser salva nos Segredos do Colab com o nome `GEMINI_API_KEY`.\n","\n","No menu do Colab: `Ambiente de execução` > `Gerenciar segredos` > Adicione `GEMINI_API_KEY`."]},{"cell_type":"markdown","id":"6e0157a4","metadata":{"id":"6e0157a4"},"source":["## Escolher e Iniciar o Modelo/Chat Gemini"]},{"cell_type":"code","execution_count":56,"id":"7eec75f6","metadata":{"id":"7eec75f6","executionInfo":{"status":"ok","timestamp":1747530415429,"user_tz":180,"elapsed":10,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}}},"outputs":[],"source":[]},{"cell_type":"markdown","id":"1f9528d0","metadata":{"id":"1f9528d0"},"source":["## Carregar Dados da Etapa 3 e 2\n","Carregue métricas, erros, X_test e y_test."]},{"cell_type":"code","execution_count":57,"id":"c399f680","metadata":{"id":"c399f680","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747530418276,"user_tz":180,"elapsed":41,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"f5809e2f-b7e7-4c8b-8eb1-dc3b4937bd75"},"outputs":[{"output_type":"stream","name":"stdout","text":["Métricas carregadas: ['accuracy', 'classification_report', 'confusion_matrix', 'obstacle_types']\n","Erros carregados: (13, 5)\n","X_test shape: (96, 20, 5)\n","y_test shape: (96, 2)\n"]}],"source":["gemini_model_name = 'gemini-2.0-flash'\n","chat2 = genai.GenerativeModel(model_name=gemini_model_name).start_chat(history=[])\n","\n","# Carregar métricas\n","with open(metrics_input_path, 'r') as f:\n","    metrics = json.load(f)\n","\n","# Carregar erros\n","errors_df = pd.read_csv(errors_input_path)\n","\n","# Carregar X_test e y_test\n","X_test = np.load(X_test_path)\n","y_test = np.load(y_test_path)\n","\n","print('Métricas carregadas:', list(metrics.keys()))\n","print('Erros carregados:', errors_df.shape)\n","print('X_test shape:', X_test.shape)\n","print('y_test shape:', y_test.shape)"]},{"cell_type":"markdown","id":"e81af824","metadata":{"id":"e81af824"},"source":["## Interação 1: Análise de Métricas Globais com Gemini"]},{"cell_type":"code","execution_count":58,"id":"f25fd9e7","metadata":{"id":"f25fd9e7","colab":{"base_uri":"https://localhost:8080/","height":974},"executionInfo":{"status":"ok","timestamp":1747530432590,"user_tz":180,"elapsed":10505,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"71deb67d-4559-4601-f448-2d87f3eee068"},"outputs":[{"output_type":"stream","name":"stdout","text":["Gemini: ## Análise do Modelo de Classificação de Séries Temporais\n","\n","Os resultados do modelo de classificação multivariada de séries temporais apresentam um desempenho geral bom, mas com algumas áreas que precisam de atenção e melhoria.\n","\n","**Pontos Fortes:**\n","\n","*   **Acurácia Global Alta:** A acurácia de 86.46% indica que o modelo está correto na maioria das vezes.\n","*   **Bom Desempenho para as Classes 'Pessoa' e 'Obstaculo Estatico':** As métricas de precisão, recall e f1-score para essas classes estão boas, sugerindo que o modelo consegue identificar corretamente tanto pessoas quanto obstáculos estáticos com uma boa taxa de sucesso. A precisão acima de 80% para ambas as classes indica que quando o modelo prediz uma classe, ele está correto na maioria das vezes. O recall também alto (acima de 85%) sugere que o modelo identifica uma alta proporção das ocorrências dessas classes.\n","\n","**Pontos Fracos:**\n","\n","*   **Problemas Graves com a Classe 'Obstaculos pequenos e medios':** O modelo não consegue identificar nenhum 'Obstaculos pequenos e medios', como demonstrado pelo recall, precisão e f1-score iguais a zero. O suporte (número de amostras) para essa classe é 0, o que indica que não existem exemplos dessa classe no conjunto de dados de teste. Isso leva a um problema grave de generalização para essa classe específica.\n","*   **Métricas Macro e Weighted Averages Distantes da Acurácia:** A discrepância entre a acurácia geral e as métricas macro e weighted averages refletem o desbalanceamento entre as classes. Isso indica que o modelo é bom em classificar as classes mais frequentes, mas tem dificuldades com as classes menos representadas.\n","*   **Matriz de Confusão Revela Confusão Entre 'Pessoa' e 'Obstaculo Estatico':** A matriz de confusão mostra que o modelo confunde 'Pessoa' com 'Obstaculo Estatico' (5 instâncias de 'Pessoa' classificadas como 'Obstaculo Estatico') e vice-versa (8 instâncias de 'Obstaculo Estatico' classificadas como 'Pessoa'). Isso sugere que algumas características das séries temporais dessas classes são semelhantes, levando à confusão.\n","\n","**Possíveis Causas dos Erros:**\n","\n","*   **Dados Desbalanceados:** A ausência de exemplos da classe \"Obstaculos pequenos e medios\" no conjunto de teste impossibilita a avaliação do modelo para essa classe.\n","*   **Similaridade entre Características:** As características dos sensores para 'Pessoa' e 'Obstaculo Estatico' podem ser semelhantes em certos cenários, levando à confusão entre as classes. Por exemplo, a velocidade de aproximação e a variação da distância podem ser parecidas em alguns casos.\n","*   **Características Insuficientes ou Não Informativas:** As 5 características do sensor podem não ser suficientes para distinguir claramente todas as classes, especialmente a 'Obstaculos pequenos e medios' (se houvesse exemplos).\n","*   **Problemas na Qualidade dos Dados:** Ruídos, outliers ou dados faltantes nas séries temporais podem afetar o desempenho do modelo.\n","*   **Modelo Não Otimizado:** O modelo pode não estar otimizado para o problema em questão. Talvez seja necessário ajustar os hiperparâmetros, experimentar diferentes algoritmos ou técnicas de regularização.\n","\n","**Sugestões para Melhoria:**\n","\n","1.  **Resolver o Problema da Classe 'Obstaculos pequenos e medios':**\n","    *   **Coleta de Dados:** Se possível, coletar dados para essa classe. É essencial ter exemplos representativos para que o modelo possa aprender a identificar essa classe.\n","    *   **Aumentar o Suporte Artificialmente:** Se a coleta de dados for inviável, considere técnicas de aumento de dados, como gerar séries temporais sintéticas que representem essa classe. Métodos como SMOTE (Synthetic Minority Oversampling Technique) podem ser adaptados para séries temporais.\n","    *   **Reavaliar a Necessidade da Classe:** Se a classe for muito rara e/ou difícil de distinguir das outras, considere combiná-la com outra classe mais genérica ou removê-la.\n","\n","2.  **Reduzir a Confusão entre 'Pessoa' e 'Obstaculo Estatico':**\n","    *   **Engenharia de Features:** Explorar a criação de novas características que ajudem a diferenciar essas classes. Por exemplo, a taxa de variação da velocidade de aproximação ou padrões temporais específicos de cada classe.\n","    *   **Análise de Erro:** Analisar os casos em que o modelo confunde essas classes para identificar os padrões que levam ao erro e tentar criar características que capturem essas diferenças.\n","    *   **Modelos Mais Complexos:** Experimentar modelos mais complexos que consigam capturar as nuances das séries temporais, como redes neurais recorrentes (RNNs) ou transformers.\n","\n","3.  **Tratar o Desbalanceamento dos Dados (se houver):**\n","    *   **Oversampling:** Aumentar o número de amostras das classes minoritárias (se houver um desbalanceamento entre as classes 'Pessoa' e 'Obstaculo Estatico') por meio de técnicas como SMOTE.\n","    *   **Undersampling:** Reduzir o número de amostras das classes majoritárias.\n","    *   **Cost-Sensitive Learning:** Atribuir pesos diferentes às classes durante o treinamento, penalizando mais os erros de classificação das classes minoritárias.\n","\n","4.  **Melhorar a Qualidade dos Dados:**\n","    *   **Limpeza de Dados:** Remover ruídos, outliers e tratar dados faltantes nas séries temporais.\n","    *   **Normalização/Padronização:** Normalizar ou padronizar as características para garantir que elas tenham a mesma escala.\n","\n","5.  **Otimização do Modelo:**\n","    *   **Seleção de Modelo:** Experimentar diferentes algoritmos de classificação de séries temporais, como Random Forests, Gradient Boosting Machines, Hidden Markov Models (HMMs) ou redes neurais.\n","    *   **Ajuste de Hiperparâmetros:** Otimizar os hiperparâmetros do modelo usando técnicas como grid search ou random search.\n","    *   **Regularização:** Aplicar técnicas de regularização para evitar overfitting.\n","    *   **Validação Cruzada:** Utilizar validação cruzada para garantir que o modelo generalize bem para dados não vistos.\n","\n","**Conclusão:**\n","\n","O modelo apresenta um bom ponto de partida, mas precisa de melhorias para lidar com a falta de dados para a classe 'Obstaculos pequenos e medios' e reduzir a confusão entre 'Pessoa' e 'Obstaculo Estatico'. Implementar as sugestões acima pode levar a um modelo mais robusto e preciso. Lembre-se de monitorar continuamente o desempenho do modelo e reavaliar as estratégias à medida que novos dados se tornam disponíveis. A análise de erro contínua é fundamental para identificar padrões de erro e direcionar os esforços de melhoria.\n","\n"]}],"source":["# Formatar prompt para análise global\n","prompt_metrics = f\"\"\"\n","Analisando resultados de um modelo de classificação multivariada de séries temporais com {len(feature_columns)} características do sensor: {feature_columns}.\n","Métricas globais:\n","Accuracy: {metrics['accuracy']}\n","\n","Classification Report:\n","{json.dumps(metrics['classification_report'], indent=2, ensure_ascii=False)}\n","\n","Matriz de confusão:\n","{metrics['confusion_matrix']}\n","\n","Com base nesses resultados, forneça uma análise textual dos pontos fortes e fracos do modelo, possíveis causas de erro e sugestões para melhoria.\n","\"\"\"\n","\n","response = chat2.send_message(prompt_metrics)\n","print('Gemini:', response.text)"]},{"cell_type":"markdown","id":"7173446f","metadata":{"id":"7173446f"},"source":["## Interação 2: Análise de Erros Específicos com Gemini\n","Para cada erro, envie a sequência multi-feature, rótulo verdadeiro e predito para análise textual."]},{"cell_type":"code","execution_count":60,"id":"a2130fef","metadata":{"id":"a2130fef","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1747530520137,"user_tz":180,"elapsed":29945,"user":{"displayName":"Marcelo Miranda","userId":"09216797134349448703"}},"outputId":"d3c7cbf4-ac91-4abb-9831-ced78894fbd1"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Análise do erro 1 ---\n","Gemini: Analisando os dados fornecidos e considerando que o modelo errou ao classificar essa sequência como \"Obstaculo Estatico\" em vez de \"Pessoa\", podemos especular sobre os possíveis padrões e relações entre as características que podem ter levado a essa confusão. É importante ressaltar que esta é uma análise exploratória baseada em dados limitados.\n","\n","**Padrões e Relações Observadas:**\n","\n","1.  **Distância:** A distância varia significativamente ao longo da sequência, com valores tanto positivos quanto negativos. O sinal negativo pode indicar que a distância está diminuindo, ou seja, o objeto está se aproximando. A presença de tanto valores baixos quanto altos pode ser confusa.\n","\n","2.  **Variação da Distância:** A variação da distância também apresenta flutuações consideráveis, com valores positivos e negativos. Isso indica que o objeto se aproxima e se afasta em diferentes momentos. Essas mudanças podem ocorrer devido a movimentos da pessoa ou a variações na leitura do sensor.\n","\n","3.  **Tamanho Percebido:** O tamanho percebido varia ao longo do tempo, mas não apresenta uma tendência clara de aumento ou diminuição constante. Isso pode indicar que a pessoa está se movendo em relação ao sensor ou que há variações na forma como o sensor percebe o objeto.\n","\n","4.  **Velocidade de Aproximação:** A velocidade de aproximação também apresenta variações, com valores positivos e negativos. Isso indica que a pessoa se aproxima e se afasta do sensor em diferentes momentos. A magnitude da velocidade de aproximação também varia, sugerindo que a pessoa pode estar acelerando ou desacelerando.\n","\n","5.  **Frequência de Detecção:** A frequência de detecção parece ser mais consistente, com valores relativamente altos em comparação com as outras características. No entanto, também apresenta algumas flutuações.\n","\n","**Possíveis Razões para a Confusão:**\n","\n","1.  **Movimentos Irregulares:** As variações na distância, variação da distância e velocidade de aproximação sugerem que a pessoa está se movendo de forma irregular. Esses movimentos podem ser semelhantes aos de um objeto estático que está sendo afetado por fatores externos, como o vento ou vibrações. Por exemplo, um objeto estático que balança levemente no vento pode ter um padrão similar.\n","\n","2.  **Semelhança com Padrões de Objetos Estáticos:** Em algumas situações, objetos estáticos podem gerar padrões de dados similares. Por exemplo, um reflexo em uma superfície lisa pode gerar um padrão de variação na distância e tamanho percebido.\n","\n","3.  **Curto Período de Tempo:** O período de tempo da sequência pode ser insuficiente para capturar os padrões característicos de uma pessoa. Se a sequência fosse mais longa, o modelo poderia ter mais informações para diferenciar a pessoa de um objeto estático.\n","\n","4.  **Falhas no Modelo:** O modelo pode ter dificuldade em lidar com a variabilidade nos movimentos de pessoas. O modelo pode não ter sido treinado com dados suficientes que representem essa variabilidade, ou a arquitetura do modelo pode não ser adequada para capturar os padrões complexos envolvidos.\n","\n","5. **Ausência de Informação Contextual:** O modelo está tomando uma decisão com base apenas nos dados dos sensores. A falta de informações contextuais, como o ambiente ou outros sensores, pode levar à confusão. Por exemplo, se o sensor estivesse em um local onde é comum encontrar objetos estáticos, o modelo poderia ser mais propenso a classificar a sequência como \"Obstaculo Estatico\".\n","\n","**Especulações Adicionais:**\n","\n","*   A pessoa pode estar se aproximando e se afastando do sensor em um padrão específico que o modelo associa a objetos estáticos.\n","*   O tamanho percebido da pessoa pode estar variando devido a fatores como mudanças na iluminação ou obstruções parciais.\n","*   A velocidade de aproximação pode ser baixa em alguns momentos, o que pode levar o modelo a pensar que o objeto está parado.\n","\n","**Em resumo:**\n","\n","A combinação de movimentos irregulares, a possível semelhança com padrões de objetos estáticos e a falta de informação contextual podem ter levado o modelo a classificar incorretamente a sequência como \"Obstaculo Estatico\" em vez de \"Pessoa\". Para melhorar o desempenho do modelo, seria necessário coletar mais dados, criar novas características, experimentar modelos mais complexos e adicionar informações contextuais.\n","\n","\n","--- Análise do erro 2 ---\n","Gemini: Analisando os dados fornecidos e o erro de classificação (previsão de \"Obstaculo Estatico\" quando o correto é \"Pessoa\"), vamos identificar os possíveis padrões e relações entre as características que podem ter causado a confusão para o modelo.\n","\n","**Padrões e Relações Observadas:**\n","\n","1.  **Distância:** A distância apresenta uma variação significativa, com valores negativos que indicam uma aproximação do objeto em relação ao sensor. A sequência começa com uma distância relativamente alta (-0.58), chega a um ponto mais próximo, e depois volta a variar.\n","\n","2.  **Variação da Distância:** A variação da distância apresenta valores predominantemente negativos, indicando que a distância está diminuindo na maioria dos pontos. No entanto, há algumas mudanças de sinal ao longo da sequência. Os valores iniciais são bastante negativos, sugerindo um rápido fechamento de distância.\n","\n","3.  **Tamanho Percebido:** O tamanho percebido também varia, mas não há uma tendência clara de aumento ou diminuição constante. Há flutuações ao longo da sequência.\n","\n","4.  **Velocidade de Aproximação:** A velocidade de aproximação apresenta tanto valores positivos quanto negativos, indicando que o objeto se aproxima e se afasta do sensor. Há alguns valores relativamente altos, indicando momentos de aproximação ou afastamento rápidos.\n","\n","5.  **Frequência de Detecção:** A frequência de detecção também varia, com valores tanto positivos quanto negativos.\n","\n","**Possíveis Razões para a Confusão:**\n","\n","1.  **Aproximação e Estabilização:** O padrão geral parece ser uma aproximação inicial rápida (valores negativos altos em \"Variação da Distância\"), seguida por uma fase onde a distância se estabiliza (valores menores em \"Variação da Distância\"). Essa combinação pode ser confundida com um objeto que é colocado em um local e permanece ali. Um objeto estático que se aproxima rapidamente e depois para.\n","\n","2.  **Variações Imprevisíveis:** As flutuações nas características podem ser interpretadas como um sinal de falta de consistência. Uma pessoa geralmente mantém uma certa continuidade em seus movimentos, enquanto um objeto estático pode ter variações aleatórias causadas por fatores externos (ex: vento em uma planta).\n","\n","3.  **Padrão de Movimento Atípico:** O padrão de movimento pode não corresponder ao que o modelo aprendeu como típico para uma pessoa. O modelo pode ter sido treinado com exemplos de pessoas se movendo de forma mais suave ou constante, em vez de se aproximando rapidamente e depois parando.\n","\n","4.  **Curta Duração da Sequência:** A sequência pode ser muito curta para que o modelo capture padrões mais complexos que diferenciariam a pessoa de um objeto estático. Uma sequência mais longa pode revelar características mais claras de um movimento humano.\n","\n","5.  **Peso das Características:** O modelo pode estar dando mais peso a certas características que são mais comuns em objetos estáticos do que em pessoas. Por exemplo, se a estabilidade na distância (baixa variação da distância) for um forte indicador de objetos estáticos, o modelo pode ter sido influenciado por essa característica.\n","\n","**Especulações Adicionais:**\n","\n","*   A pessoa pode estar se aproximando rapidamente de um ponto e depois ficando parada por um tempo, o que simula um objeto sendo colocado ali.\n","*   As variações nas características podem ser causadas por ruído no sensor ou por fatores ambientais, como obstruções parciais ou mudanças na iluminação.\n","*   O modelo pode ter sido treinado com um conjunto de dados que não representa adequadamente a diversidade de movimentos humanos, levando a uma generalização inadequada.\n","\n","**Em resumo:**\n","\n","A combinação de uma aproximação inicial rápida, uma estabilização subsequente e a presença de variações imprevisíveis pode ter levado o modelo a classificar incorretamente a sequência como \"Obstaculo Estatico\". Para melhorar o desempenho do modelo, seria necessário coletar mais dados, experimentar diferentes pesos para as características e considerar a utilização de modelos que sejam mais robustos a variações e ruídos nos dados. Avaliar a sensibilidade do modelo a diferentes durações de sequências também é importante.\n","\n","\n","--- Análise do erro 3 ---\n","Gemini: Analisando os dados fornecidos e o erro de classificação (previsão de \"Pessoa\" quando o correto é \"Obstaculo Estatico\"), vamos identificar os possíveis padrões e relações entre as características que podem ter causado a confusão para o modelo.\n","\n","**Padrões e Relações Observadas:**\n","\n","1.  **Distância:** A distância apresenta valores positivos relativamente altos e variados, o que sugere que o objeto está a uma distância considerável do sensor e que sua posição não é estática. Embora não haja uma tendência clara de aumento ou diminuição, a distância geralmente permanece maior que 0.\n","\n","2.  **Variação da Distância:** A variação da distância apresenta valores positivos predominantes, indicando que a distância entre o objeto e o sensor está geralmente aumentando. No entanto, a magnitude dessas variações é relativamente grande em alguns pontos, o que sugere que o objeto não está se movendo de forma suave e constante.\n","\n","3.  **Tamanho Percebido:** O tamanho percebido também apresenta valores positivos variados, sem uma tendência clara de aumento ou diminuição. Em alguns momentos, o tamanho percebido atinge valores relativamente altos, como 2.97 no quarto instante.\n","\n","4.  **Velocidade de Aproximação:** A velocidade de aproximação apresenta valores positivos e negativos, indicando que o objeto se aproxima e se afasta do sensor. A magnitude da velocidade de aproximação também varia, o que sugere que o objeto pode estar acelerando ou desacelerando.\n","\n","5.  **Frequência de Detecção:** A frequência de detecção apresenta valores negativos, o que poderia indicar uma diminuição na frequência com que o sensor está detectando o objeto.\n","\n","**Possíveis Razões para a Confusão:**\n","\n","1.  **Movimentos Variáveis:** A variação na distância e velocidade de aproximação sugere que o objeto está se movendo, o que pode ter levado o modelo a inferir que se trata de uma pessoa.\n","\n","2.  **Tamanho Percebido Variável:** O tamanho percebido apresenta variações, o que poderia ser interpretado como uma pessoa se movendo em relação ao sensor, mudando de orientação ou se aproximando e afastando.\n","\n","3.  **Distância Relativamente Grande:** A distância média entre o objeto e o sensor é relativamente grande, o que pode ter levado o modelo a pensar que se trata de uma pessoa, já que objetos estáticos tendem a estar mais próximos do sensor.\n","\n","4.  **Frequência de Detecção:** A frequência de detecção está baixa e negativa, o que provavelmente não ajudou o modelo a tomar uma decisão correta.\n","\n","5.  **Ruído:** Ruídos nos sensores podem ter causado variações nas medidas que o modelo interpretou como movimento característico de pessoas.\n","\n","**Especulações Adicionais:**\n","\n","*   O objeto estático pode estar em uma superfície vibratória.\n","*   O objeto pode estar sendo afetado por correntes de ar.\n","\n","**Em resumo:**\n","\n","Os valores das features \"Distância\", \"Variação da Distância\", \"Tamanho Percebido\" e \"Velocidade de Aproximação\" estão sugerindo um certo grau de movimento e variação, características que podem levar o modelo a identificar o objeto como \"Pessoa\". Por outro lado, a feature \"Frequência de Detecção\" sugere o contrário.\n","\n","Para melhorar o desempenho do modelo, seria necessário coletar mais dados, analisar os padrões temporais das características, experimentar diferentes combinações de características e investigar as causas das variações observadas.\n","\n","\n","--- Análise do erro 4 ---\n","Gemini: Analisando os dados fornecidos e o erro de classificação (previsão de \"Pessoa\" quando o correto é \"Obstaculo Estatico\"), podemos tentar identificar os padrões e relações entre as características que podem ter causado a confusão para o modelo.\n","\n","**Padrões e Relações Observadas:**\n","\n","1.  **Distância:** A distância varia significativamente ao longo da sequência, com valores tanto positivos quanto negativos. Ela começa positiva, fica negativa, e depois volta a ser positiva. Essa variação pode indicar que o objeto está se movendo em relação ao sensor. A presença de valores próximos de zero pode indicar que o objeto se aproximou bastante do sensor em algum momento.\n","\n","2.  **Variação da Distância:** A variação da distância também apresenta flutuações consideráveis, com valores positivos e negativos. Isso indica que a distância entre o objeto e o sensor está mudando de direção ao longo do tempo. Há alguns valores relativamente altos, indicando mudanças rápidas na distância.\n","\n","3.  **Tamanho Percebido:** O tamanho percebido apresenta uma variação significativa, com valores positivos e negativos. Isso pode indicar que o tamanho do objeto está mudando ao longo do tempo.\n","\n","4.  **Velocidade de Aproximação:** A velocidade de aproximação também apresenta variações, com valores positivos e negativos. Isso indica que o objeto se aproxima e se afasta do sensor em diferentes momentos.\n","\n","5.  **Frequência de Detecção:** A frequência de detecção apresenta valores tanto positivos quanto negativos.\n","\n","**Possíveis Razões para a Confusão:**\n","\n","1.  **Movimento Complexo:** A combinação de variações na distância, variação da distância, tamanho percebido e velocidade de aproximação pode sugerir que o objeto está se movendo de forma complexa, o que pode ter levado o modelo a inferir que se trata de uma pessoa. O modelo pode estar interpretando as flutuações como indicativas de um agente intencional em vez de um objeto inanimado.\n","\n","2.  **Curta Duração da Sequência:** A sequência pode ser muito curta para que o modelo capture padrões mais complexos que diferenciariam o objeto estático de uma pessoa. Uma sequência mais longa pode revelar características mais claras de um movimento humano.\n","\n","3.  **Peso Incorreto das Características:** O modelo pode estar dando peso excessivo a certas características que são mais comuns em pessoas do que em objetos estáticos.\n","\n","4.  **Ausência de Padrões Estáticos:** A falta de padrões característicos de objetos estáticos na sequência pode ter confundido o modelo. Se não há momentos de estabilidade na distância, por exemplo, o modelo pode descartar a possibilidade de se tratar de um objeto estático.\n","\n","5.  **Ruído:** Ruídos nos sensores podem ter causado variações nas medidas que o modelo interpretou como movimento característico de pessoas.\n","\n","**Especulações Adicionais:**\n","\n","*   O objeto estático pode estar sendo movido por alguma força externa, como o vento ou vibrações.\n","*   O objeto pode estar sendo parcialmente obstruído, causando variações no tamanho percebido.\n","\n","**Em resumo:**\n","\n","A combinação de movimento complexo e a ausência de padrões estáticos na sequência pode ter levado o modelo a classificar incorretamente o objeto como \"Pessoa\". Para melhorar o desempenho do modelo, seria necessário coletar mais dados, analisar os padrões temporais das características, experimentar diferentes combinações de características e investigar as causas das variações observadas. Analisar a resposta do modelo a sequências de diferentes durações também pode ser útil.\n","\n","\n","--- Análise do erro 5 ---\n","Gemini: Analisando os dados fornecidos e o erro de classificação (previsão de \"Obstaculo Estatico\" quando o correto é \"Pessoa\"), vamos investigar os padrões e relações entre as características que podem ter levado a essa confusão.\n","\n","**Padrões e Relações Observadas:**\n","\n","1.  **Distância:** A distância apresenta valores negativos predominantes, o que indica que o objeto está se aproximando do sensor. Há alguma variação, mas a maioria dos valores permanece abaixo de zero, sugerindo que o objeto está relativamente perto.\n","\n","2.  **Variação da Distância:** A variação da distância apresenta tanto valores positivos quanto negativos. A característica mais notável é a alta magnitude dos valores positivos, que indica que a distância está aumentando rapidamente em alguns momentos. Isso contrasta com a tendência geral de aproximação indicada pela distância.\n","\n","3.  **Tamanho Percebido:** O tamanho percebido também apresenta variações, com valores positivos e negativos. Não há uma tendência clara de aumento ou diminuição ao longo da sequência.\n","\n","4.  **Velocidade de Aproximação:** A velocidade de aproximação apresenta valores negativos predominantes, o que indica que o objeto está se aproximando do sensor na maior parte do tempo. No entanto, a magnitude dos valores é geralmente baixa, o que sugere que o objeto não está se movendo muito rapidamente.\n","\n","5.  **Frequência de Detecção:** A frequência de detecção apresenta variações, com valores positivos e negativos, mas não há uma tendência clara.\n","\n","**Possíveis Razões para a Confusão:**\n","\n","1.  **Combinação Incomum de Aproximação e Aumento da Distância:** A presença de uma distância negativa (objeto perto) combinada com uma variação da distância predominantemente positiva (distância aumentando) é um padrão incomum. Normalmente, esperaríamos que a distância diminuísse se a variação da distância fosse negativa e vice-versa. Essa inconsistência pode ter confundido o modelo. Isso pode sugerir um padrão de \"vai e vem\" ou que o objeto está se afastando, mas ainda relativamente próximo.\n","\n","2.  **Baixa Velocidade de Aproximação:** Apesar de estar se aproximando, a velocidade de aproximação é relativamente baixa, o que pode ter levado o modelo a pensar que o objeto não está se movendo ativamente como uma pessoa faria.\n","\n","3.  **Ausência de Padrões Característicos de Movimento Humano:** O modelo pode não estar encontrando os padrões típicos de movimento que espera ver em uma pessoa. A falta de uma aceleração consistente, paradas repentinas ou mudanças de direção podem ter contribuído para a classificação incorreta.\n","\n","4.  **Peso Incorreto das Características:** O modelo pode estar dando mais peso a certas características que são mais comuns em objetos estáticos, como a consistência da distância ou a falta de movimentos abruptos.\n","\n","**Especulações Adicionais:**\n","\n","*   O objeto pode estar preso a algo que o puxa para trás, resultando em um aumento da distância, apesar da tendência geral de aproximação.\n","*   Pode haver interferência nos sensores que causa medições imprecisas.\n","\n","**Em resumo:**\n","\n","A inconsistência entre a aproximação geral (distância negativa) e os momentos de aumento da distância (variação da distância positiva), combinada com uma baixa velocidade de aproximação, pode ter levado o modelo a classificar incorretamente o objeto como \"Obstaculo Estatico\". Para melhorar o desempenho do modelo, seria necessário investigar as causas dessas inconsistências e ajustar o modelo para lidar melhor com padrões de movimento incomuns.\n","\n"]}],"source":["# Limite de exemplos para evitar excesso de prompts\n","max_errors_to_analyze = 5\n","\n","for idx, row in errors_df.head(max_errors_to_analyze).iterrows():\n","    error_index = int(row['error_index'])\n","    true_label_str = row['true_label_str']\n","    pred_label_str = row['pred_label_str']\n","    error_sequence_data = X_test[error_index]\n","\n","    # Formatar sequência para string\n","    sequence_str = json.dumps(error_sequence_data.tolist(), ensure_ascii=False)\n","\n","    prompt_error_case = f\"\"\"\n","O modelo errou ao classificar uma sequência de sensor.\n","Características: {feature_columns}\n","Dados da sequência (tempo por linha): {sequence_str}\n","Rótulo correto: {true_label_str}\n","Predição do modelo: {pred_label_str}\n","\n","Analisando apenas estes dados numéricos multi-feature, quais padrões ou relações entre as características você observa que poderiam ter tornado esta classificação ambígua ou difícil para o modelo? Especule sobre possíveis razões.\n","\"\"\"\n","\n","    print(f'\\n--- Análise do erro {idx+1} ---')\n","    response = chat2.send_message(prompt_error_case)\n","    print('Gemini:', response.text)\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}